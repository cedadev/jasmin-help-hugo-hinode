/*!
  * Bootstrap v5.3.3 (https://getbootstrap.com/)
  * Copyright 2011-2024 The Bootstrap Authors (https://github.com/twbs/bootstrap/graphs/contributors)
  * Licensed under MIT (https://github.com/twbs/bootstrap/blob/main/LICENSE)
  */const alert=document.getElementById("page-alert"),closeBtn=document.getElementById("page-alert-btn-close");if(alert!==null&&closeBtn!==null){const e=alert.getAttribute("data-page-alert-version")||"unknown",t=sessionStorage.getItem(`page-alert-${e}`)!==null;t&&alert.classList.add("d-none"),closeBtn.addEventListener("click",()=>{sessionStorage.setItem(`page-alert-${e}`,"seen"),alert.classList.add("d-none")})}var dnt,index,doNotTrack=!1;if(!1&&(dnt=navigator.doNotTrack||window.doNotTrack||navigator.msDoNotTrack,doNotTrack=dnt=="1"||dnt=="yes"),!doNotTrack){window.dataLayer=window.dataLayer||[];function gtag(){dataLayer.push(arguments)}gtag("js",new Date),gtag("config","G-JJZZ5F2KN4")}function reveal(){const e=document.querySelectorAll(".reveal");for(let t=0;t<e.length;t++){const n=window.innerHeight,s=e[t].getBoundingClientRect().top,o=150;s<n-o?(e[t].classList.add("active"),e[t].classList.remove("reveal")):e[t].classList.remove("active")}}window.addEventListener("scroll",reveal);const svgCopy='<svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" width="16" height="16" fill="currentColor" class="bi bi-clipboard" viewBox="0 0 16 16"><path d="M4 1.5H3a2 2 0 0 0-2 2V14a2 2 0 0 0 2 2h10a2 2 0 0 0 2-2V3.5a2 2 0 0 0-2-2h-1v1h1a1 1 0 0 1 1 1V14a1 1 0 0 1-1 1H3a1 1 0 0 1-1-1V3.5a1 1 0 0 1 1-1h1v-1z"/><path d="M9.5 1a.5.5 0 0 1 .5.5v1a.5.5 0 0 1-.5.5h-3a.5.5 0 0 1-.5-.5v-1a.5.5 0 0 1 .5-.5h3zm-3-1A1.5 1.5 0 0 0 5 1.5v1A1.5 1.5 0 0 0 6.5 4h3A1.5 1.5 0 0 0 11 2.5v-1A1.5 1.5 0 0 0 9.5 0h-3z"/></svg>',svgCheck='<svg aria-hidden="true" height="16" viewBox="0 0 16 16" version="1.1" width="16" data-view-component="true"><path fill-rule="evenodd" fill="rgb(63, 185, 80)" d="M13.78 4.22a.75.75 0 010 1.06l-7.25 7.25a.75.75 0 01-1.06 0L2.22 9.28a.75.75 0 011.06-1.06L6 10.94l6.72-6.72a.75.75 0 011.06 0z"></path></svg>',addCopyButtons=e=>{document.querySelectorAll("pre > code").forEach(t=>{const n=document.createElement("button");n.className="clipboard-button",n.setAttribute("data-toast-target","toast-copied-code-message"),n.setAttribute("aria-label","copy to clipboard"),n.type="button",n.innerHTML=svgCopy,n.addEventListener("click",()=>{const s=t.innerText.split(`
`).filter(Boolean).join(`
`);e.writeText(s).then(()=>{n.blur(),n.innerHTML=svgCheck,setTimeout(()=>n.innerHTML=svgCopy,2e3)},e=>n.innerHTML="Error")});const s=t.parentNode;s.parentNode.insertBefore(n,s)})};navigator&&navigator.clipboard&&addCopyButtons(navigator.clipboard),document.querySelectorAll("[data-clipboard]").forEach(e=>{const t=e.getAttribute("data-clipboard");e.addEventListener("click",()=>{navigator.clipboard.writeText(t)})});const url=new URL(window.location.href),menu=url.searchParams.get("menu"),child=url.searchParams.get("child"),menuItems=document.querySelectorAll('[data-nav="main"]');if(menu!==null){menuItems.forEach(e=>{e.classList.remove("active")});const e=document.querySelectorAll(`[data-nav-main="${menu}"]:not([data-nav-child])`);e.forEach(e=>{e.classList.add("active")});const t=document.querySelectorAll(`[data-nav-main="${menu}"][data-nav-child="${child}"]`);t.forEach(e=>{e.classList.add("active")})}(function(e,t){typeof exports=="object"&&typeof module!="undefined"?module.exports=t():typeof define=="function"&&define.amd?define(t):(e=typeof globalThis!="undefined"?globalThis:e||self,e.bootstrap=t())})(this,function(){"use strict";const C=new Map,pt={set(e,t,n){C.has(e)||C.set(e,new Map);const s=C.get(e);if(!s.has(t)&&s.size!==0){console.error(`Bootstrap doesn't allow more than one instance per element. Bound instance: ${Array.from(s.keys())[0]}.`);return}s.set(t,n)},get(e,t){return C.has(e)?C.get(e).get(t)||null:null},remove(e,t){if(!C.has(e))return;const n=C.get(e);n.delete(t),n.size===0&&C.delete(e)}},Jr=1e6,Xr=1e3,lt="transitionend",is=e=>(e&&window.CSS&&window.CSS.escape&&(e=e.replace(/#([^\s"#']+)/g,(e,t)=>`#${CSS.escape(t)}`)),e),Gr=e=>e==null?`${e}`:Object.prototype.toString.call(e).match(/\s([a-z]+)/i)[1].toLowerCase(),Yr=e=>{do e+=Math.floor(Math.random()*Jr);while(document.getElementById(e))return e},Pr=e=>{if(!e)return 0;let{transitionDuration:t,transitionDelay:n}=window.getComputedStyle(e);const s=Number.parseFloat(t),o=Number.parseFloat(n);return!s&&!o?0:(t=t.split(",")[0],n=n.split(",")[0],(Number.parseFloat(t)+Number.parseFloat(n))*Xr)},ns=e=>{e.dispatchEvent(new Event(lt))},g=e=>!!e&&typeof e=="object"&&(typeof e.jquery!="undefined"&&(e=e[0]),typeof e.nodeType!="undefined"),w=e=>g(e)?e.jquery?e[0]:e:typeof e=="string"&&e.length>0?document.querySelector(is(e)):null,R=e=>{if(!g(e)||e.getClientRects().length===0)return!1;const n=getComputedStyle(e).getPropertyValue("visibility")==="visible",t=e.closest("details:not([open])");if(!t)return n;if(t!==e){const n=e.closest("summary");if(n&&n.parentNode!==t)return!1;if(n===null)return!1}return n},y=e=>!e||e.nodeType!==Node.ELEMENT_NODE||!!e.classList.contains("disabled")||(typeof e.disabled!="undefined"?e.disabled:e.hasAttribute("disabled")&&e.getAttribute("disabled")!=="false"),es=e=>{if(!document.documentElement.attachShadow)return null;if(typeof e.getRootNode=="function"){const t=e.getRootNode();return t instanceof ShadowRoot?t:null}return e instanceof ShadowRoot?e:e.parentNode?es(e.parentNode):null},le=()=>{},oe=e=>{e.offsetHeight},Jn=()=>window.jQuery&&!document.body.hasAttribute("data-bs-no-jquery")?window.jQuery:null,Ue=[],Nr=e=>{document.readyState==="loading"?(Ue.length||document.addEventListener("DOMContentLoaded",()=>{for(const e of Ue)e()}),Ue.push(e)):e()},c=()=>document.documentElement.dir==="rtl",u=e=>{Nr(()=>{const t=Jn();if(t){const n=e.NAME,s=t.fn[n];t.fn[n]=e.jQueryInterface,t.fn[n].Constructor=e,t.fn[n].noConflict=()=>(t.fn[n]=s,e.jQueryInterface)}})},o=(e,t=[],n=e)=>typeof e=="function"?e(...t):n,Zn=(e,t,n=!0)=>{if(!n){o(e);return}const a=5,r=Pr(t)+a;let s=!1;const i=({target:n})=>{if(n!==t)return;s=!0,t.removeEventListener(lt,i),o(e)};t.addEventListener(lt,i),setTimeout(()=>{s||ns(t)},r)},$e=(e,t,n,s)=>{const i=e.length;let o=e.indexOf(t);return o===-1?!n&&s?e[i-1]:e[0]:(o+=n?1:-1,s&&(o=(o+i)%i),e[Math.max(0,Math.min(o,i-1))])},zr=/[^.]*(?=\..*)\.|.*/,Tr=/\..*/,Ar=/::\d+$/,De={};let qn=1;const Un={mouseenter:"mouseover",mouseleave:"mouseout"},Er=new Set(["click","dblclick","mouseup","mousedown","contextmenu","mousewheel","DOMMouseScroll","mouseover","mouseout","mousemove","selectstart","selectend","keydown","keypress","keyup","orientationchange","touchstart","touchmove","touchend","touchcancel","pointerdown","pointermove","pointerup","pointerleave","pointercancel","gesturestart","gesturechange","gestureend","focus","blur","change","reset","select","submit","focusin","focusout","load","unload","beforeunload","resize","move","DOMContentLoaded","readystatechange","error","abort","scroll"]);function Hn(e,t){return t&&`${t}::${qn++}`||e.uidEvent||qn++}function Fn(e){const t=Hn(e);return e.uidEvent=t,De[t]=De[t]||{},De[t]}function xr(t,n){return function s(o){return ht(o,{delegateTarget:t}),s.oneOff&&e.off(t,o.type,n),n.apply(t,[o])}}function Or(t,n,s){return function o(i){const a=t.querySelectorAll(n);for(let{target:r}=i;r&&r!==this;r=r.parentNode)for(const c of a){if(c!==r)continue;return ht(i,{delegateTarget:r}),o.oneOff&&e.off(t,i.type,n,s),s.apply(r,[i])}}}function Sn(e,t,n=null){return Object.values(e).find(e=>e.callable===t&&e.delegationSelector===n)}function An(e,t,n){const o=typeof t=="string",i=o?n:t||n;let s=xn(e);return Er.has(s)||(s=e),[o,i,s]}function Cn(e,t,n,s,o){if(typeof t!="string"||!e)return;let[r,i,c]=An(t,n,s);if(t in Un){const e=e=>function(t){if(!t.relatedTarget||t.relatedTarget!==t.delegateTarget&&!t.delegateTarget.contains(t.relatedTarget))return e.call(this,t)};i=e(i)}const d=Fn(e),u=d[c]||(d[c]={}),l=Sn(u,i,r?n:null);if(l){l.oneOff=l.oneOff&&o;return}const h=Hn(i,t.replace(zr,"")),a=r?Or(e,n,i):xr(e,i);a.delegationSelector=r?n:null,a.callable=i,a.oneOff=o,a.uidEvent=h,u[h]=a,e.addEventListener(c,a,r)}function dt(e,t,n,s,o){const i=Sn(t[n],s,o);if(!i)return;e.removeEventListener(n,i,Boolean(o)),delete t[n][i.uidEvent]}function wr(e,t,n,s){const o=t[n]||{};for(const[a,i]of Object.entries(o))a.includes(s)&&dt(e,t,n,i.callable,i.delegationSelector)}function xn(e){return e=e.replace(Tr,""),Un[e]||e}const e={on(e,t,n,s){Cn(e,t,n,s,!1)},one(e,t,n,s){Cn(e,t,n,s,!0)},off(e,t,n,s){if(typeof t!="string"||!e)return;const[c,a,i]=An(t,n,s),l=i!==t,o=Fn(e),r=o[i]||{},d=t.startsWith(".");if(typeof a!="undefined"){if(!Object.keys(r).length)return;dt(e,o,i,a,c?n:null);return}if(d)for(const n of Object.keys(o))wr(e,o,n,t.slice(1));for(const[s,n]of Object.entries(r)){const a=s.replace(Ar,"");(!l||t.includes(a))&&dt(e,o,i,n.callable,n.delegationSelector)}},trigger(e,t,n){if(typeof t!="string"||!e)return null;const i=Jn(),l=xn(t),d=t!==l;let s=null,a=!0,r=!0,c=!1;d&&i&&(s=i.Event(t,n),i(e).trigger(s),a=!s.isPropagationStopped(),r=!s.isImmediatePropagationStopped(),c=s.isDefaultPrevented());const o=ht(new Event(t,{bubbles:a,cancelable:!0}),n);return c&&o.preventDefault(),r&&e.dispatchEvent(o),o.defaultPrevented&&s&&s.preventDefault(),o}};function ht(e,t={}){for(const[n,s]of Object.entries(t))try{e[n]=s}catch{Object.defineProperty(e,n,{configurable:!0,get(){return s}})}return e}function On(e){if(e==="true")return!0;if(e==="false")return!1;if(e===Number(e).toString())return Number(e);if(e===""||e==="null")return null;if(typeof e!="string")return e;try{return JSON.parse(decodeURIComponent(e))}catch{return e}}function Le(e){return e.replace(/[A-Z]/g,e=>`-${e.toLowerCase()}`)}const v={setDataAttribute(e,t,n){e.setAttribute(`data-bs-${Le(t)}`,n)},removeDataAttribute(e,t){e.removeAttribute(`data-bs-${Le(t)}`)},getDataAttributes(e){if(!e)return{};const t={},n=Object.keys(e.dataset).filter(e=>e.startsWith("bs")&&!e.startsWith("bsConfig"));for(const o of n){let s=o.replace(/^bs/,"");s=s.charAt(0).toLowerCase()+s.slice(1,s.length),t[s]=On(e.dataset[o])}return t},getDataAttribute(e,t){return On(e.getAttribute(`data-bs-${Le(t)}`))}};class se{static get Default(){return{}}static get DefaultType(){return{}}static get NAME(){throw new Error('You have to implement the static method "NAME", for each component!')}_getConfig(e){return e=this._mergeConfigObj(e),e=this._configAfterMerge(e),this._typeCheckConfig(e),e}_configAfterMerge(e){return e}_mergeConfigObj(e,t){const n=g(t)?v.getDataAttribute(t,"config"):{};return{...this.constructor.Default,...typeof n=="object"?n:{},...g(t)?v.getDataAttributes(t):{},...typeof e=="object"?e:{}}}_typeCheckConfig(e,t=this.constructor.DefaultType){for(const[n,s]of Object.entries(t)){const o=e[n],i=g(o)?"element":Gr(o);if(!new RegExp(s).test(i))throw new TypeError(`${this.constructor.NAME.toUpperCase()}: Option "${n}" provided type "${i}" but expected type "${s}".`)}}}const _r="5.3.3";class h extends se{constructor(e,t){if(super(),e=w(e),!e)return;this._element=e,this._config=this._getConfig(t),pt.set(this._element,this.constructor.DATA_KEY,this)}dispose(){pt.remove(this._element,this.constructor.DATA_KEY),e.off(this._element,this.constructor.EVENT_KEY);for(const e of Object.getOwnPropertyNames(this))this[e]=null}_queueCallback(e,t,n=!0){Zn(e,t,n)}_getConfig(e){return e=this._mergeConfigObj(e,this._element),e=this._configAfterMerge(e),this._typeCheckConfig(e),e}static getInstance(e){return pt.get(w(e),this.DATA_KEY)}static getOrCreateInstance(e,t={}){return this.getInstance(e)||new this(e,typeof t=="object"?t:null)}static get VERSION(){return _r}static get DATA_KEY(){return`bs.${this.NAME}`}static get EVENT_KEY(){return`.${this.DATA_KEY}`}static eventName(e){return`${e}${this.EVENT_KEY}`}}const tt=e=>{let t=e.getAttribute("data-bs-target");if(!t||t==="#"){let n=e.getAttribute("href");if(!n||!n.includes("#")&&!n.startsWith("."))return null;n.includes("#")&&!n.startsWith("#")&&(n=`#${n.split("#")[1]}`),t=n&&n!=="#"?n.trim():null}return t?t.split(",").map(e=>is(e)).join(","):null},t={find(e,t=document.documentElement){return[].concat(...Element.prototype.querySelectorAll.call(t,e))},findOne(e,t=document.documentElement){return Element.prototype.querySelector.call(t,e)},children(e,t){return[].concat(...e.children).filter(e=>e.matches(t))},parents(e,t){const s=[];let n=e.parentNode.closest(t);for(;n;)s.push(n),n=n.parentNode.closest(t);return s},prev(e,t){let n=e.previousElementSibling;for(;n;){if(n.matches(t))return[n];n=n.previousElementSibling}return[]},next(e,t){let n=e.nextElementSibling;for(;n;){if(n.matches(t))return[n];n=n.nextElementSibling}return[]},focusableChildren(e){const t=["a","button","input","textarea","select","details","[tabindex]",'[contenteditable="true"]'].map(e=>`${e}:not([tabindex^="-"])`).join(",");return this.find(t,e).filter(e=>!y(e)&&R(e))},getSelectorFromElement(e){const n=tt(e);return n?t.findOne(n)?n:null:null},getElementFromSelector(e){const n=tt(e);return n?t.findOne(n):null},getMultipleElementsFromSelector(e){const n=tt(e);return n?t.find(n):[]}},_e=(n,s="hide")=>{const i=`click.dismiss${n.EVENT_KEY}`,o=n.NAME;e.on(document,i,`[data-bs-dismiss="${o}"]`,function(e){if(["A","AREA"].includes(this.tagName)&&e.preventDefault(),y(this))return;const i=t.getElementFromSelector(this)||this.closest(`.${o}`),a=n.getOrCreateInstance(i);a[s]()})},yr="alert",jr="bs.alert",jn=`.${jr}`,vr=`close${jn}`,cr=`closed${jn}`,ir="fade",Qa="show";class de extends h{static get NAME(){return yr}close(){const t=e.trigger(this._element,vr);if(t.defaultPrevented)return;this._element.classList.remove(Qa);const n=this._element.classList.contains(ir);this._queueCallback(()=>this._destroyElement(),this._element,n)}_destroyElement(){this._element.remove(),e.trigger(this._element,cr),this.dispose()}static jQueryInterface(e){return this.each(function(){const t=de.getOrCreateInstance(this);if(typeof e!="string")return;if(t[e]===void 0||e.startsWith("_")||e==="constructor")throw new TypeError(`No method named "${e}"`);t[e](this)})}}_e(de,"close"),u(de);const Ga="button",qa="bs.button",Wa=`.${qa}`,Ba=".data-api",Pa="active",fn='[data-bs-toggle="button"]',Ta=`click${Wa}${Ba}`;class fe extends h{static get NAME(){return Ga}toggle(){this._element.setAttribute("aria-pressed",this._element.classList.toggle(Pa))}static jQueryInterface(e){return this.each(function(){const t=fe.getOrCreateInstance(this);e==="toggle"&&t[e]()})}}e.on(document,Ta,fn,e=>{e.preventDefault();const t=e.target.closest(fn),n=fe.getOrCreateInstance(t);n.toggle()}),u(fe);const ga="swipe",P=".bs.swipe",pa=`touchstart${P}`,fa=`touchmove${P}`,ma=`touchend${P}`,ua=`pointerdown${P}`,la=`pointerup${P}`,Qi="touch",Gi="pen",Vi="pointer-event",Bi=40,Ri={endCallback:null,leftCallback:null,rightCallback:null},Ni={endCallback:"(function|null)",leftCallback:"(function|null)",rightCallback:"(function|null)"};class Re extends se{constructor(e,t){if(super(),this._element=e,!e||!Re.isSupported())return;this._config=this._getConfig(t),this._deltaX=0,this._supportPointerEvents=Boolean(window.PointerEvent),this._initEvents()}static get Default(){return Ri}static get DefaultType(){return Ni}static get NAME(){return ga}dispose(){e.off(this._element,P)}_start(e){if(!this._supportPointerEvents){this._deltaX=e.touches[0].clientX;return}this._eventIsPointerPenTouch(e)&&(this._deltaX=e.clientX)}_end(e){this._eventIsPointerPenTouch(e)&&(this._deltaX=e.clientX-this._deltaX),this._handleSwipe(),o(this._config.endCallback)}_move(e){this._deltaX=e.touches&&e.touches.length>1?0:e.touches[0].clientX-this._deltaX}_handleSwipe(){const e=Math.abs(this._deltaX);if(e<=Bi)return;const t=e/this._deltaX;if(this._deltaX=0,!t)return;o(t>0?this._config.rightCallback:this._config.leftCallback)}_initEvents(){this._supportPointerEvents?(e.on(this._element,ua,e=>this._start(e)),e.on(this._element,la,e=>this._end(e)),this._element.classList.add(Vi)):(e.on(this._element,pa,e=>this._start(e)),e.on(this._element,fa,e=>this._move(e)),e.on(this._element,ma,e=>this._end(e)))}_eventIsPointerPenTouch(e){return this._supportPointerEvents&&(e.pointerType===Gi||e.pointerType===Qi)}static isSupported(){return"ontouchstart"in document.documentElement||navigator.maxTouchPoints>0}}const Di="carousel",zi="bs.carousel",_=`.${zi}`,Kt=".data-api",Mi="ArrowLeft",Si="ArrowRight",Ei=500,ie="next",U="prev",K="left",ke="right",ji=`slide${_}`,Be=`slid${_}`,bi=`keydown${_}`,gi=`mouseenter${_}`,li=`mouseleave${_}`,ci=`dragstart${_}`,si=`load${_}${Kt}`,ei=`click${_}${Kt}`,Pt="carousel",Ce="active",Jo="slide",Zo="carousel-item-end",Qo="carousel-item-start",Xo="carousel-item-next",Go="carousel-item-prev",zt=".active",gt=".carousel-item",Ko=zt+gt,Bo=".carousel-item img",Po=".carousel-indicators",No="[data-bs-slide], [data-bs-slide-to]",Do='[data-bs-ride="carousel"]',To={[Mi]:ke,[Si]:K},Fo={interval:5e3,keyboard:!0,pause:"hover",ride:!1,touch:!0,wrap:!0},vo={interval:"(number|boolean)",keyboard:"boolean",pause:"(string|boolean)",ride:"(boolean|string)",touch:"boolean",wrap:"boolean"};class ee extends h{constructor(e,n){super(e,n),this._interval=null,this._activeElement=null,this._isSliding=!1,this.touchTimeout=null,this._swipeHelper=null,this._indicatorsElement=t.findOne(Po,this._element),this._addEventListeners(),this._config.ride===Pt&&this.cycle()}static get Default(){return Fo}static get DefaultType(){return vo}static get NAME(){return Di}next(){this._slide(ie)}nextWhenVisible(){!document.hidden&&R(this._element)&&this.next()}prev(){this._slide(U)}pause(){this._isSliding&&ns(this._element),this._clearInterval()}cycle(){this._clearInterval(),this._updateInterval(),this._interval=setInterval(()=>this.nextWhenVisible(),this._config.interval)}_maybeEnableCycle(){if(!this._config.ride)return;if(this._isSliding){e.one(this._element,Be,()=>this.cycle());return}this.cycle()}to(t){const n=this._getItems();if(t>n.length-1||t<0)return;if(this._isSliding){e.one(this._element,Be,()=>this.to(t));return}const s=this._getItemIndex(this._getActive());if(s===t)return;const o=t>s?ie:U;this._slide(o,n[t])}dispose(){this._swipeHelper&&this._swipeHelper.dispose(),super.dispose()}_configAfterMerge(e){return e.defaultInterval=e.interval,e}_addEventListeners(){this._config.keyboard&&e.on(this._element,bi,e=>this._keydown(e)),this._config.pause==="hover"&&(e.on(this._element,gi,()=>this.pause()),e.on(this._element,li,()=>this._maybeEnableCycle())),this._config.touch&&Re.isSupported()&&this._addTouchEventListeners()}_addTouchEventListeners(){for(const n of t.find(Bo,this._element))e.on(n,ci,e=>e.preventDefault());const n=()=>{if(this._config.pause!=="hover")return;this.pause(),this.touchTimeout&&clearTimeout(this.touchTimeout),this.touchTimeout=setTimeout(()=>this._maybeEnableCycle(),Ei+this._config.interval)},s={leftCallback:()=>this._slide(this._directionToOrder(K)),rightCallback:()=>this._slide(this._directionToOrder(ke)),endCallback:n};this._swipeHelper=new Re(this._element,s)}_keydown(e){if(/input|textarea/i.test(e.target.tagName))return;const t=To[e.key];t&&(e.preventDefault(),this._slide(this._directionToOrder(t)))}_getItemIndex(e){return this._getItems().indexOf(e)}_setActiveIndicatorElement(e){if(!this._indicatorsElement)return;const s=t.findOne(zt,this._indicatorsElement);s.classList.remove(Ce),s.removeAttribute("aria-current");const n=t.findOne(`[data-bs-slide-to="${e}"]`,this._indicatorsElement);n&&(n.classList.add(Ce),n.setAttribute("aria-current","true"))}_updateInterval(){const e=this._activeElement||this._getActive();if(!e)return;const t=Number.parseInt(e.getAttribute("data-bs-interval"),10);this._config.interval=t||this._config.defaultInterval}_slide(t,n=null){if(this._isSliding)return;const o=this._getActive(),a=t===ie,s=n||$e(this._getItems(),o,a,this._config.wrap);if(s===o)return;const c=this._getItemIndex(s),l=n=>e.trigger(this._element,n,{relatedTarget:s,direction:this._orderToDirection(t),from:this._getItemIndex(o),to:c}),d=l(ji);if(d.defaultPrevented)return;if(!o||!s)return;const u=Boolean(this._interval);this.pause(),this._isSliding=!0,this._setActiveIndicatorElement(c),this._activeElement=s;const i=a?Qo:Zo,r=a?Xo:Go;s.classList.add(r),oe(s),o.classList.add(i),s.classList.add(i);const h=()=>{s.classList.remove(i,r),s.classList.add(Ce),o.classList.remove(Ce,r,i),this._isSliding=!1,l(Be)};this._queueCallback(h,o,this._isAnimated()),u&&this.cycle()}_isAnimated(){return this._element.classList.contains(Jo)}_getActive(){return t.findOne(Ko,this._element)}_getItems(){return t.find(gt,this._element)}_clearInterval(){this._interval&&(clearInterval(this._interval),this._interval=null)}_directionToOrder(e){return c()?e===K?U:ie:e===K?ie:U}_orderToDirection(e){return c()?e===U?K:ke:e===U?ke:K}static jQueryInterface(e){return this.each(function(){const t=ee.getOrCreateInstance(this,e);if(typeof e=="number"){t.to(e);return}if(typeof e=="string"){if(t[e]===void 0||e.startsWith("_")||e==="constructor")throw new TypeError(`No method named "${e}"`);t[e]()}})}}e.on(document,ei,No,function(e){const s=t.getElementFromSelector(this);if(!s||!s.classList.contains(Pt))return;e.preventDefault();const n=ee.getOrCreateInstance(s),o=this.getAttribute("data-bs-slide-to");if(o){n.to(o),n._maybeEnableCycle();return}if(v.getDataAttribute(this,"slide")==="next"){n.next(),n._maybeEnableCycle();return}n.prev(),n._maybeEnableCycle()}),e.on(window,si,()=>{const e=t.find(Do);for(const t of e)ee.getOrCreateInstance(t)}),u(ee);const rs="collapse",po="bs.collapse",J=`.${po}`,co=".data-api",ao=`show${J}`,io=`shown${J}`,Js=`hide${J}`,Qs=`hidden${J}`,Gs=`click${J}${co}`,ct="show",L="collapse",pe="collapsing",Ys="collapsed",Ks=`:scope .${L} .${L}`,Us="collapse-horizontal",Ws="width",$s="height",Vs=".collapse.show, .collapse.collapsing",nt='[data-bs-toggle="collapse"]',Bs={parent:null,toggle:!0},Is={parent:"(null|element)",toggle:"boolean"};class te extends h{constructor(e,n){super(e,n),this._isTransitioning=!1,this._triggerArray=[];const s=t.find(nt);for(const e of s){const n=t.getSelectorFromElement(e),o=t.find(n).filter(e=>e===this._element);n!==null&&o.length&&this._triggerArray.push(e)}this._initializeChildren(),this._config.parent||this._addAriaAndCollapsedClass(this._triggerArray,this._isShown()),this._config.toggle&&this.toggle()}static get Default(){return Bs}static get DefaultType(){return Is}static get NAME(){return rs}toggle(){this._isShown()?this.hide():this.show()}show(){if(this._isTransitioning||this._isShown())return;let n=[];if(this._config.parent&&(n=this._getFirstLevelChildren(Vs).filter(e=>e!==this._element).map(e=>te.getOrCreateInstance(e,{toggle:!1}))),n.length&&n[0]._isTransitioning)return;const s=e.trigger(this._element,ao);if(s.defaultPrevented)return;for(const e of n)e.hide();const t=this._getDimension();this._element.classList.remove(L),this._element.classList.add(pe),this._element.style[t]=0,this._addAriaAndCollapsedClass(this._triggerArray,!0),this._isTransitioning=!0;const o=()=>{this._isTransitioning=!1,this._element.classList.remove(pe),this._element.classList.add(L,ct),this._element.style[t]="",e.trigger(this._element,io)},i=t[0].toUpperCase()+t.slice(1),a=`scroll${i}`;this._queueCallback(o,this._element,!0),this._element.style[t]=`${this._element[a]}px`}hide(){if(this._isTransitioning||!this._isShown())return;const s=e.trigger(this._element,Js);if(s.defaultPrevented)return;const n=this._getDimension();this._element.style[n]=`${this._element.getBoundingClientRect()[n]}px`,oe(this._element),this._element.classList.add(pe),this._element.classList.remove(L,ct);for(const e of this._triggerArray){const n=t.getElementFromSelector(e);n&&!this._isShown(n)&&this._addAriaAndCollapsedClass([e],!1)}this._isTransitioning=!0;const o=()=>{this._isTransitioning=!1,this._element.classList.remove(pe),this._element.classList.add(L),e.trigger(this._element,Qs)};this._element.style[n]="",this._queueCallback(o,this._element,!0)}_isShown(e=this._element){return e.classList.contains(ct)}_configAfterMerge(e){return e.toggle=Boolean(e.toggle),e.parent=w(e.parent),e}_getDimension(){return this._element.classList.contains(Us)?Ws:$s}_initializeChildren(){if(!this._config.parent)return;const e=this._getFirstLevelChildren(nt);for(const n of e){const s=t.getElementFromSelector(n);s&&this._addAriaAndCollapsedClass([n],this._isShown(s))}}_getFirstLevelChildren(e){const n=t.find(Ks,this._config.parent);return t.find(e,this._config.parent).filter(e=>!n.includes(e))}_addAriaAndCollapsedClass(e,t){if(!e.length)return;for(const n of e)n.classList.toggle(Ys,!t),n.setAttribute("aria-expanded",t)}static jQueryInterface(e){const t={};return typeof e=="string"&&/show|hide/.test(e)&&(t.toggle=!1),this.each(function(){const n=te.getOrCreateInstance(this,t);if(typeof e=="string"){if(typeof n[e]=="undefined")throw new TypeError(`No method named "${e}"`);n[e]()}})}}e.on(document,Gs,nt,function(e){(e.target.tagName==="A"||e.delegateTarget&&e.delegateTarget.tagName==="A")&&e.preventDefault();for(const e of t.getMultipleElementsFromSelector(this))te.getOrCreateInstance(e,{toggle:!1}).toggle()}),u(te);var k,A,Q,Nn,In,ae,Yn,Xn,ot,Tt,Ft,St,At,je,s="top",a="bottom",i="right",n="left",Ee="auto",Y=[s,a,i,n],T="start",q="end",Vt="clippingParents",Ve="viewport",I="popper",Ut="reference",Te=Y.reduce(function(e,t){return e.concat([t+"-"+T,t+"-"+q])},[]),Xe=[].concat(Y,[Ee]).reduce(function(e,t){return e.concat([t,t+"-"+T,t+"-"+q])},[]),Yt="beforeRead",Gt="read",Xt="afterRead",Qt="beforeMain",Zt="main",Jt="afterMain",en="beforeWrite",tn="write",nn="afterWrite",sn=[Yt,Gt,Xt,Qt,Zt,Jt,en,tn,nn];function f(e){return e?(e.nodeName||"").toLowerCase():null}function r(e){if(e==null)return window;if(e.toString()!=="[object Window]"){var t=e.ownerDocument;return t?t.defaultView||window:window}return e}function D(e){var t=r(e).Element;return e instanceof t||e instanceof Element}function l(e){var t=r(e).HTMLElement;return e instanceof t||e instanceof HTMLElement}function Me(e){if(typeof ShadowRoot=="undefined")return!1;var t=r(e).ShadowRoot;return e instanceof t||e instanceof ShadowRoot}function Hs(e){var t=e.state;Object.keys(t.elements).forEach(function(e){var o=t.styles[e]||{},s=t.attributes[e]||{},n=t.elements[e];if(!l(n)||!f(n))return;Object.assign(n.style,o),Object.keys(s).forEach(function(e){var t=s[e];t===!1?n.removeAttribute(e):n.setAttribute(e,t===!0?"":t)})})}function Ps(e){var t=e.state,n={popper:{position:t.options.strategy,left:"0",top:"0",margin:"0"},arrow:{position:"absolute"},reference:{}};return Object.assign(t.elements.popper.style,n.popper),t.styles=n,t.elements.arrow&&Object.assign(t.elements.arrow.style,n.arrow),function(){Object.keys(t.elements).forEach(function(e){var s=t.elements[e],o=t.attributes[e]||{},i=Object.keys(t.styles.hasOwnProperty(e)?t.styles[e]:n[e]),a=i.reduce(function(e,t){return e[t]="",e},{});if(!l(s)||!f(s))return;Object.assign(s.style,a),Object.keys(o).forEach(function(e){s.removeAttribute(e)})})}}const st={name:"applyStyles",enabled:!0,phase:"write",fn:Hs,effect:Ps,requires:["computeStyles"]};function p(e){return e.split("-")[0]}k=Math.max,Q=Math.min,A=Math.round;function et(){var e=navigator.userAgentData;return e!=null&&e.brands&&Array.isArray(e.brands)?e.brands.map(function(e){return e.brand+"/"+e.version}).join(" "):navigator.userAgent}function bn(){return!/^((?!chrome|android).)*safari/i.test(et())}function X(e,t,n){t===void 0&&(t=!1),n===void 0&&(n=!1),s=e.getBoundingClientRect(),o=1,i=1,t&&l(e)&&(o=e.offsetWidth>0?A(s.width)/e.offsetWidth||1:1,i=e.offsetHeight>0?A(s.height)/e.offsetHeight||1:1);var s,o,i,f=D(e)?r(e):window,a=f.visualViewport,u=!bn()&&n,c=(s.left+(u&&a?a.offsetLeft:0))/o,d=(s.top+(u&&a?a.offsetTop:0))/i,h=s.width/o,m=s.height/i;return{width:h,height:m,top:d,right:c+h,bottom:d+m,left:c,x:c,y:d}}function ut(e){var t=X(e),n=e.offsetWidth,s=e.offsetHeight;return Math.abs(t.width-n)<=1&&(n=t.width),Math.abs(t.height-s)<=1&&(s=t.height),{x:e.offsetLeft,y:e.offsetTop,width:n,height:s}}function _n(e,t){var n,s=t.getRootNode&&t.getRootNode();if(e.contains(t))return!0;if(s&&Me(s)){n=t;do{if(n&&e.isSameNode(n))return!0;n=n.parentNode||n.host}while(n)}return!1}function j(e){return r(e).getComputedStyle(e)}function Rs(e){return["table","td","th"].indexOf(f(e))>=0}function E(e){return((D(e)?e.ownerDocument:e.document)||window.document).documentElement}function ge(e){return f(e)==="html"?e:e.assignedSlot||e.parentNode||(Me(e)?e.host:null)||E(e)}function En(e){return!l(e)||j(e).position==="fixed"?null:e.offsetParent}function As(e){var t,n,o,s=/firefox/i.test(et()),i=/Trident/i.test(et());if(i&&l(e)&&(o=j(e),o.position==="fixed"))return null;for(t=ge(e),Me(t)&&(t=t.host);l(t)&&["html","body"].indexOf(f(t))<0;){if(n=j(t),n.transform!=="none"||n.perspective!=="none"||n.contain==="paint"||["transform","perspective"].indexOf(n.willChange)!==-1||s&&n.willChange==="filter"||s&&n.filter&&n.filter!=="none")return t;t=t.parentNode}return null}function ce(e){for(var n=r(e),t=En(e);t&&Rs(t)&&j(t).position==="static";)t=En(t);return t&&(f(t)==="html"||f(t)==="body"&&j(t).position==="static")?n:t||As(e)||n}function Qe(e){return["top","bottom"].indexOf(e)>=0?"x":"y"}function re(e,t,n){return k(e,Q(t,n))}function Cs(e,t,n){var s=re(e,t,n);return s>n?n:s}function Tn(){return{top:0,right:0,bottom:0,left:0}}function zn(e){return Object.assign({},Tn(),e)}function Dn(e,t){return t.reduce(function(t,n){return t[n]=e,t},{})}Nn=function(t,n){return t=typeof t=="function"?t(Object.assign({},n.rects,{placement:n.placement})):t,zn(typeof t!="number"?t:Dn(t,Y))};function Os(e){var r,c,d,u,f,g,v,b,j,y,_,O,x,C,E,t=e.state,S=e.name,A=e.options,h=t.elements.arrow,m=t.modifiersData.popperOffsets,w=p(t.placement),o=Qe(w),k=[n,i].indexOf(w)>=0,l=k?"height":"width";if(!h||!m)return;g=Nn(A.padding,t),v=ut(h),b=o==="y"?s:n,j=o==="y"?a:i,y=t.rects.reference[l]+t.rects.reference[o]-m[o]-t.rects.popper[l],_=m[o]-t.rects.reference[o],c=ce(h),f=c?o==="y"?c.clientHeight||0:c.clientWidth||0:0,O=y/2-_/2,x=g[b],C=f-v[l]-g[j],u=f/2-v[l]/2+O,d=re(x,u,C),E=o,t.modifiersData[S]=(r={},r[E]=d,r.centerOffset=d-u,r)}function ys(e){var n=e.state,o=e.options,s=o.element,t=s===void 0?"[data-popper-arrow]":s;if(t==null)return;if(typeof t=="string"&&(t=n.elements.popper.querySelector(t),!t))return;if(!_n(n.elements.popper,t))return;n.elements.arrow=t}const Pn={name:"arrow",enabled:!0,phase:"main",fn:Os,effect:ys,requires:["popperOffsets"],requiresIfExists:["preventOverflow"]};function V(e){return e.split("-")[1]}In={top:"auto",right:"auto",bottom:"auto",left:"auto"};function bs(e,t){var s=e.x,o=e.y,n=t.devicePixelRatio||1;return{x:A(s*n)/n||0,y:A(o*n)/n||0}}function Vn(e){var c,u,h,p,g,b,y,T,z,f=e.popper,N=e.popperRect,d=e.placement,A=e.variation,m=e.offsets,x=e.position,v=e.gpuAcceleration,S=e.adaptive,_=e.roundOffsets,M=e.isFixed,L=m.x,t=L===void 0?0:L,D=m.y,o=D===void 0?0:D,C=typeof _=="function"?_({x:t,y:o}):{x:t,y:o},t=C.x,o=C.y,F=m.hasOwnProperty("x"),k=m.hasOwnProperty("y"),w=n,O=s,l=window;return S&&(c=ce(f),g="clientHeight",y="clientWidth",c===r(f)&&(c=E(f),j(c).position!=="static"&&x==="absolute"&&(g="scrollHeight",y="scrollWidth")),c=c,(d===s||(d===n||d===i)&&A===q)&&(O=a,T=M&&c===l&&l.visualViewport?l.visualViewport.height:c[g],o-=T-N.height,o*=v?1:-1),(d===n||(d===s||d===a)&&A===q)&&(w=i,z=M&&c===l&&l.visualViewport?l.visualViewport.width:c[y],t-=z-N.width,t*=v?1:-1)),p=Object.assign({position:x},S&&In),b=_===!0?bs({x:t,y:o},r(f)):{x:t,y:o},t=b.x,o=b.y,v?Object.assign({},p,(h={},h[O]=k?"0":"",h[w]=F?"0":"",h.transform=(l.devicePixelRatio||1)<=1?"translate("+t+"px, "+o+"px)":"translate3d("+t+"px, "+o+"px, 0)",h)):Object.assign({},p,(u={},u[O]=k?o+"px":"",u[w]=F?t+"px":"",u.transform="",u))}function vs(e){var t=e.state,n=e.options,s=n.gpuAcceleration,c=s===void 0||s,o=n.adaptive,l=o===void 0||o,i=n.roundOffsets,a=i===void 0||i,r={placement:p(t.placement),variation:V(t.placement),popper:t.elements.popper,popperRect:t.rects.popper,gpuAcceleration:c,isFixed:t.options.strategy==="fixed"};t.modifiersData.popperOffsets!=null&&(t.styles.popper=Object.assign({},t.styles.popper,Vn(Object.assign({},r,{offsets:t.modifiersData.popperOffsets,position:t.options.strategy,adaptive:l,roundOffsets:a})))),t.modifiersData.arrow!=null&&(t.styles.arrow=Object.assign({},t.styles.arrow,Vn(Object.assign({},r,{offsets:t.modifiersData.arrow,position:"absolute",adaptive:!1,roundOffsets:a})))),t.attributes.popper=Object.assign({},t.attributes.popper,{"data-popper-placement":t.placement})}const Fe={name:"computeStyles",enabled:!0,phase:"beforeWrite",fn:vs,data:{}};ae={passive:!0};function gs(e){var n=e.state,t=e.instance,s=e.options,o=s.scroll,i=o===void 0||o,a=s.resize,c=a===void 0||a,l=r(n.elements.popper),d=[].concat(n.scrollParents.reference,n.scrollParents.popper);return i&&d.forEach(function(e){e.addEventListener("scroll",t.update,ae)}),c&&l.addEventListener("resize",t.update,ae),function(){i&&d.forEach(function(e){e.removeEventListener("scroll",t.update,ae)}),c&&l.removeEventListener("resize",t.update,ae)}}const ze={name:"eventListeners",enabled:!0,phase:"write",fn:function(){},effect:gs,data:{}};Yn={left:"right",right:"left",bottom:"top",top:"bottom"};function Ae(e){return e.replace(/left|right|bottom|top/g,function(e){return Yn[e]})}Xn={start:"end",end:"start"};function Qn(e){return e.replace(/start|end/g,function(e){return Xn[e]})}function We(e){var t=r(e),n=t.pageXOffset,s=t.pageYOffset;return{scrollLeft:n,scrollTop:s}}function Ke(e){return X(E(e)).left+We(e).scrollLeft}function hs(e,t){var s,d=r(e),o=E(e),n=d.visualViewport,i=o.clientWidth,a=o.clientHeight,c=0,l=0;return n&&(i=n.width,a=n.height,s=bn(),(s||!s&&t==="fixed")&&(c=n.offsetLeft,l=n.offsetTop)),{width:i,height:a,x:c+Ke(e),y:l}}function us(e){var s,n=E(e),o=We(e),t=(s=e.ownerDocument)==null?void 0:s.body,i=k(n.scrollWidth,n.clientWidth,t?t.scrollWidth:0,t?t.clientWidth:0),r=k(n.scrollHeight,n.clientHeight,t?t.scrollHeight:0,t?t.clientHeight:0),a=-o.scrollLeft+Ke(e),c=-o.scrollTop;return j(t||n).direction==="rtl"&&(a+=k(n.clientWidth,t?t.clientWidth:0)-i),{width:i,height:r,x:a,y:c}}function Je(e){var t=j(e),n=t.overflow,s=t.overflowX,o=t.overflowY;return/auto|scroll|overlay|hidden/.test(n+o+s)}function ss(e){return["html","body","#document"].indexOf(f(e))>=0?e.ownerDocument.body:l(e)&&Je(e)?e:ss(ge(e))}function ne(e,t){t===void 0&&(t=[]);var s,n=ss(e),o=n===((s=e.ownerDocument)==null?void 0:s.body),i=r(n),a=o?[i].concat(i.visualViewport||[],Je(n)?n:[]):n,c=t.concat(a);return o?c:c.concat(ne(ge(a)))}function rt(e){return Object.assign({},e,{left:e.x,top:e.y,right:e.x+e.width,bottom:e.y+e.height})}function Fi(e,t){var n=X(e,!1,t==="fixed");return n.top=n.top+e.clientTop,n.left=n.left+e.clientLeft,n.bottom=n.top+e.clientHeight,n.right=n.left+e.clientWidth,n.width=e.clientWidth,n.height=e.clientHeight,n.x=n.left,n.y=n.top,n}function Mt(e,t,n){return t===Ve?rt(hs(e,n)):D(t)?Fi(t,n):rt(us(E(e)))}function ls(e){var n=ne(ge(e)),s=["absolute","fixed"].indexOf(j(e).position)>=0,t=s&&l(e)?ce(e):e;return D(t)?n.filter(function(e){return D(e)&&_n(e,t)&&f(e)!=="body"}):[]}function ds(e,t,n,s){var a=t==="clippingParents"?ls(e):[].concat(t),i=[].concat(a,[n]),r=i[0],o=i.reduce(function(t,n){var o=Mt(e,n,s);return t.top=k(o.top,t.top),t.right=Q(o.right,t.right),t.bottom=Q(o.bottom,t.bottom),t.left=k(o.left,t.left),t},Mt(e,r,s));return o.width=o.right-o.left,o.height=o.bottom-o.top,o.x=o.left,o.y=o.top,o}function ts(e){var o,r,l,t=e.reference,c=e.element,d=e.placement,u=d?p(d):null,f=d?V(d):null,h=t.x+t.width/2-c.width/2,m=t.y+t.height/2-c.height/2;switch(u){case s:o={x:h,y:t.y-c.height};break;case a:o={x:h,y:t.y+t.height};break;case i:o={x:t.x+t.width,y:m};break;case n:o={x:t.x-c.width,y:m};break;default:o={x:t.x,y:t.y}}if(r=u?Qe(u):null,r!=null)switch(l=r==="y"?"height":"width",f){case T:o[r]=o[r]-(t[l]/2-c[l]/2);break;case q:o[r]=o[r]+(t[l]/2-c[l]/2);break}return o}function N(e,t){t===void 0&&(t={});var _,n=t,v=n.placement,j=v===void 0?e.placement:v,f=n.strategy,T=f===void 0?e.strategy:f,p=n.boundary,C=p===void 0?Vt:p,O=n.rootBoundary,F=O===void 0?Ve:O,x=n.elementContext,c=x===void 0?I:x,m=n.altBoundary,M=m!==void 0&&m,b=n.padding,d=b===void 0?0:b,o=zn(typeof d!="number"?d:Dn(d,Y)),S=c===I?Ut:I,w=e.rects.popper,h=e.elements[M?S:c],r=ds(D(h)?h:h.contextElement||E(e.elements.popper),C,F,T),y=X(e.elements.reference),k=ts({reference:y,element:w,strategy:"absolute",placement:j}),A=rt(Object.assign({},w,k)),l=c===I?A:y,u={top:r.top-l.top+o.top,bottom:l.bottom-r.bottom+o.bottom,left:r.left-l.left+o.left,right:l.right-r.right+o.right},g=e.modifiersData.offset;return c===I&&g&&(_=g[j],Object.keys(u).forEach(function(e){var t=[i,a].indexOf(e)>=0?1:-1,n=[s,a].indexOf(e)>=0?"y":"x";u[e]+=_[n]*t})),u}function ms(e,t){t===void 0&&(t={});var s,n=t,c=n.placement,l=n.boundary,d=n.rootBoundary,u=n.padding,h=n.flipVariations,i=n.allowedAutoPlacements,m=i===void 0?Xe:i,a=V(c),r=a?h?Te:Te.filter(function(e){return V(e)===a}):Y,o=r.filter(function(e){return m.indexOf(e)>=0});return o.length===0&&(o=r),s=o.reduce(function(t,n){return t[n]=N(e,{placement:n,boundary:l,rootBoundary:d,padding:u})[p(n)],t},{}),Object.keys(s).sort(function(e,t){return s[e]-s[t]})}function fs(e){if(p(e)===Ee)return[];var t=Ae(e);return[Qn(e),t,Qn(t)]}function ps(e){var t=e.state,o=e.options,C=e.name;if(t.modifiersData[C]._skip)return;for(var r,c,l,u,h,g,v,y,_,x,E,k,z,M=o.mainAxis,I=M===void 0||M,D=o.altAxis,P=D===void 0||D,R=o.fallbackPlacements,L=o.padding,w=o.boundary,O=o.rootBoundary,B=o.altBoundary,F=o.flipVariations,j=F===void 0||F,$=o.allowedAutoPlacements,d=t.options.placement,K=p(d),H=K===d,q=R||(H||!j?[Ae(d)]:fs(d)),f=[d].concat(q).reduce(function(e,n){return e.concat(p(n)===Ee?ms(t,{placement:n,boundary:w,rootBoundary:O,padding:L,flipVariations:j,allowedAutoPlacements:$}):n)},[]),U=t.rects.reference,W=t.rects.popper,A=new Map,S=!0,m=f[0],b=0;b<f.length;b++){if(r=f[b],v=p(r),g=V(r)===T,y=[s,a].indexOf(v)>=0,_=y?"width":"height",h=N(t,{placement:r,boundary:w,rootBoundary:O,altBoundary:B,padding:L}),l=y?g?i:n:g?a:s,U[_]>W[_]&&(l=Ae(l)),z=Ae(l),c=[],I&&c.push(h[v]<=0),P&&c.push(h[l]<=0,h[z]<=0),c.every(function(e){return e})){m=r,S=!1;break}A.set(r,c)}if(S)for(k=j?3:1,E=function(t){var n=f.find(function(e){var n=A.get(e);if(n)return n.slice(0,t).every(function(e){return e})});if(n)return m=n,"break"},u=k;u>0;u--)if(x=E(u),x==="break")break;t.placement!==m&&(t.modifiersData[C]._skip=!0,t.placement=m,t.reset=!0)}const Kn={name:"flip",enabled:!0,phase:"main",fn:ps,requiresIfExists:["offset"],data:{_skip:!1}};function $n(e,t,n){return n===void 0&&(n={x:0,y:0}),{top:e.top-t.height-n.y,right:e.right-t.width+n.x,bottom:e.bottom-t.height+n.y,left:e.left-t.width-n.x}}function Bn(e){return[s,i,a,n].some(function(t){return e[t]>=0})}function js(e){var t=e.state,a=e.name,r=t.rects.reference,c=t.rects.popper,l=t.modifiersData.preventOverflow,d=N(t,{elementContext:"reference"}),u=N(t,{altBoundary:!0}),n=$n(d,r),s=$n(u,c,l),o=Bn(n),i=Bn(s);t.modifiersData[a]={referenceClippingOffsets:n,popperEscapeOffsets:s,isReferenceHidden:o,hasPopperEscaped:i},t.attributes.popper=Object.assign({},t.attributes.popper,{"data-popper-reference-hidden":o,"data-popper-escaped":i})}const Rn={name:"hide",enabled:!0,phase:"main",requiresIfExists:["preventOverflow"],fn:js};function _s(e,t,o){var c=p(e),d=[n,s].indexOf(c)>=0?-1:1,l=typeof o=="function"?o(Object.assign({},t,{placement:e})):o,a=l[0],r=l[1],a=a||0,r=(r||0)*d;return[n,i].indexOf(c)>=0?{x:r,y:a}:{x:a,y:r}}function ws(e){var t=e.state,i=e.options,a=e.name,n=i.offset,r=n===void 0?[0,0]:n,s=Xe.reduce(function(e,n){return e[n]=_s(n,t.rects,r),e},{}),o=s[t.placement],c=o.x,l=o.y;t.modifiersData.popperOffsets!=null&&(t.modifiersData.popperOffsets.x+=c,t.modifiersData.popperOffsets.y+=l),t.modifiersData[a]=s}const Ln={name:"offset",enabled:!0,phase:"main",requires:["popperOffsets"],fn:ws};function xs(e){var t=e.state,n=e.name;t.modifiersData[n]=ts({reference:t.rects.reference,element:t.rects.popper,strategy:"absolute",placement:t.placement})}const He={name:"popperOffsets",enabled:!0,phase:"read",fn:xs,data:{}};function Es(e){return e==="x"?"y":"x"}function ks(e){var fe,r,h,P,H,$,W,U,Y,Z,J,ue,v,E,K,q,te,ne,x,oe,B,ae,le,G,me,c,f,w,A,M,F,z,D,R,I,X,t=e.state,l=e.options,be=e.name,pe=l.mainAxis,ge=pe===void 0||pe,se=l.altAxis,we=se!==void 0&&se,_e=l.boundary,ye=l.rootBoundary,ve=l.altBoundary,je=l.padding,de=l.tether,d=de===void 0||de,ie=l.tetherOffset,S=ie===void 0?0:ie,O=N(t,{boundary:_e,rootBoundary:ye,padding:je,altBoundary:ve}),ee=p(t.placement),C=V(t.placement),he=!C,o=Qe(ee),j=Es(o),b=t.modifiersData.popperOffsets,u=t.rects.reference,g=t.rects.popper,_=typeof S=="function"?S(Object.assign({},t.rects,{placement:t.placement})):S,m=typeof _=="number"?{mainAxis:_,altAxis:_}:Object.assign({mainAxis:0,altAxis:0},_),y=t.modifiersData.offset?t.modifiersData.offset[t.placement]:null,L={x:0,y:0};if(!b)return;ge&&(P=o==="y"?s:n,H=o==="y"?a:i,r=o==="y"?"height":"width",h=b[o],$=h+O[P],W=h-O[H],U=d?-g[r]/2:0,J=C===T?u[r]:g[r],Z=C===T?-g[r]:-u[r],Y=t.elements.arrow,ue=d&&Y?ut(Y):{width:0,height:0},E=t.modifiersData["arrow#persistent"]?t.modifiersData["arrow#persistent"].padding:Tn(),q=E[P],K=E[H],v=re(0,u[r],ue[r]),te=he?u[r]/2-U-v-q-m.mainAxis:J-v-q-m.mainAxis,ne=he?-u[r]/2+U+v+K+m.mainAxis:Z+v+K+m.mainAxis,x=t.elements.arrow&&ce(t.elements.arrow),oe=x?o==="y"?x.clientTop||0:x.clientLeft||0:0,B=(fe=y?.[o])!=null?fe:0,ae=h+te-B-oe,le=h+ne-B,I=re(d?Q($,ae):$,h,d?k(W,le):W),b[o]=I,L[o]=I-h),we&&(G=o==="x"?s:n,me=o==="x"?a:i,c=b[j],f=j==="y"?"height":"width",R=c+O[G],D=c-O[me],w=[s,n].indexOf(ee)!==-1,z=(X=y?.[j])!=null?X:0,F=w?R:c-u[f]-g[f]-z+m.altAxis,M=w?c+u[f]+g[f]-z-m.altAxis:D,A=d&&w?Cs(F,c,M):re(d?F:R,c,d?M:D),b[j]=A,L[j]=A-c),t.modifiersData[be]=L}const kn={name:"preventOverflow",enabled:!0,phase:"main",fn:ks,requiresIfExists:["offset"]};function Ss(e){return{scrollLeft:e.scrollLeft,scrollTop:e.scrollTop}}function Ms(e){return e===r(e)||!l(e)?We(e):Ss(e)}function Fs(e){var t=e.getBoundingClientRect(),n=A(t.width)/e.offsetWidth||1,s=A(t.height)/e.offsetHeight||1;return n!==1||s!==1}function Ts(e,t,n){n===void 0&&(n=!1);var r=l(t),c=l(t)&&Fs(t),i=E(t),o=X(e,c,n),a={scrollLeft:0,scrollTop:0},s={x:0,y:0};return(r||!r&&!n)&&((f(t)!=="body"||Je(i))&&(a=Ms(t)),l(t)?(s=X(t,!0),s.x+=t.clientLeft,s.y+=t.clientTop):i&&(s.x=Ke(i))),{x:o.left+a.scrollLeft-s.x,y:o.top+a.scrollTop-s.y,width:o.width,height:o.height}}function zs(e){var n=new Map,t=new Set,s=[];e.forEach(function(e){n.set(e.name,e)});function o(e){t.add(e.name);var i=[].concat(e.requires||[],e.requiresIfExists||[]);i.forEach(function(e){if(!t.has(e)){var s=n.get(e);s&&o(s)}}),s.push(e)}return e.forEach(function(e){t.has(e.name)||o(e)}),s}function Ds(e){var t=zs(e);return sn.reduce(function(e,n){return e.concat(t.filter(function(e){return e.phase===n}))},[])}function Ns(e){var t;return function(){return t||(t=new Promise(function(n){Promise.resolve().then(function(){t=void 0,n(e())})})),t}}function Ls(e){var t=e.reduce(function(e,t){var n=e[t.name];return e[t.name]=n?Object.assign({},n,t,{options:Object.assign({},n.options,t.options),data:Object.assign({},n.data,t.data)}):t,e},{});return Object.keys(t).map(function(e){return t[e]})}ot={placement:"bottom",modifiers:[],strategy:"absolute"};function un(){for(var t=arguments.length,n=new Array(t),e=0;e<t;e++)n[e]=arguments[e];return!n.some(function(e){return!e||typeof e.getBoundingClientRect!="function"})}function we(e){e===void 0&&(e={});var n=e,s=n.defaultModifiers,i=s===void 0?[]:s,o=n.defaultOptions,t=o===void 0?ot:o;return function(n,s,o){o===void 0&&(o=t);var a={placement:"bottom",orderedModifiers:[],options:Object.assign({},ot,t),modifiersData:{},elements:{reference:n,popper:s},attributes:{},styles:{}},c=[],l=!1,r={state:a,setOptions:function(o){var c,l=typeof o=="function"?o(a.options):o;return d(),a.options=Object.assign({},t,a.options,l),a.scrollParents={reference:D(n)?ne(n):n.contextElement?ne(n.contextElement):[],popper:ne(s)},c=Ds(Ls([].concat(i,a.options.modifiers))),a.orderedModifiers=c.filter(function(e){return e.enabled}),u(),r.update()},forceUpdate:function(){if(l)return;var o=a.elements,i=o.reference,n=o.popper;if(!un(i,n))return;a.rects={reference:Ts(i,ce(n),a.options.strategy==="fixed"),popper:ut(n)},a.reset=!1,a.placement=a.options.placement,a.orderedModifiers.forEach(function(e){return a.modifiersData[e.name]=Object.assign({},e.data)});for(t=0;t<a.orderedModifiers.length;t++){if(a.reset===!0){a.reset=!1,t=-1;continue}var t,s=a.orderedModifiers[t],c=s.fn,d=s.options,u=d===void 0?{}:d,h=s.name;typeof c=="function"&&(a=c({state:a,options:u,name:h,instance:r})||a)}},update:Ns(function(){return new Promise(function(e){r.forceUpdate(),e(a)})}),destroy:function(){d(),l=!0}};if(!un(n,s))return r;r.setOptions(o).then(function(e){!l&&o.onFirstUpdate&&o.onFirstUpdate(e)});function u(){a.orderedModifiers.forEach(function(e){var s,o,i=e.name,t=e.options,l=t===void 0?{}:t,n=e.effect;typeof n=="function"&&(s=n({state:a,name:i,instance:r,options:l}),o=function(){},c.push(s||o))})}function d(){c.forEach(function(e){return e()}),c=[]}return r}}Tt=we(),Ft=[ze,He,Fe,st],St=we({defaultModifiers:Ft}),At=[ze,He,Fe,st,Ln,Kn,kn,Pn,Rn],je=we({defaultModifiers:At});const Et=Object.freeze(Object.defineProperty({__proto__:null,afterMain:Jt,afterRead:Xt,afterWrite:nn,applyStyles:st,arrow:Pn,auto:Ee,basePlacements:Y,beforeMain:Qt,beforeRead:Yt,beforeWrite:en,bottom:a,clippingParents:Vt,computeStyles:Fe,createPopper:je,createPopperBase:Tt,createPopperLite:St,detectOverflow:N,end:q,eventListeners:ze,flip:Kn,hide:Rn,left:n,main:Zt,modifierPhases:sn,offset:Ln,placements:Xe,popper:I,popperGenerator:we,popperOffsets:He,preventOverflow:kn,read:Gt,reference:Ut,right:i,start:T,top:s,variationPlacements:Te,viewport:Ve,write:tn},Symbol.toStringTag,{value:"Module"})),Ct="dropdown",qs="bs.dropdown",F=`.${qs}`,it=".data-api",Xs="Escape",jt="Tab",Zs="ArrowUp",bt="ArrowDown",eo=2,to=`hide${F}`,no=`hidden${F}`,so=`show${F}`,oo=`shown${F}`,vt=`click${F}${it}`,yt=`keydown${F}${it}`,ro=`keyup${F}${it}`,G="show",lo="dropup",uo="dropend",ho="dropstart",mo="dropup-center",fo="dropdown-center",z='[data-bs-toggle="dropdown"]:not(.disabled):not(:disabled)',go=`${z}.${G}`,me=".dropdown-menu",bo=".navbar",jo=".navbar-nav",yo=".dropdown-menu .dropdown-item:not(.disabled):not(:disabled)",_o=c()?"top-end":"top-start",wo=c()?"top-start":"top-end",Oo=c()?"bottom-end":"bottom-start",xo=c()?"bottom-start":"bottom-end",Co=c()?"left-start":"right-start",Eo=c()?"right-start":"left-start",ko="top",Ao="bottom",So={autoClose:!0,boundary:"clippingParents",display:"dynamic",offset:[0,2],popperConfig:null,reference:"toggle"},Mo={autoClose:"(boolean|string)",boundary:"(string|element)",display:"string",offset:"(array|string|function)",popperConfig:"(null|object|function)",reference:"(string|element|object)"};class m extends h{constructor(e,n){super(e,n),this._popper=null,this._parent=this._element.parentNode,this._menu=t.next(this._element,me)[0]||t.prev(this._element,me)[0]||t.findOne(me,this._parent),this._inNavbar=this._detectNavbar()}static get Default(){return So}static get DefaultType(){return Mo}static get NAME(){return Ct}toggle(){return this._isShown()?this.hide():this.show()}show(){if(y(this._element)||this._isShown())return;const t={relatedTarget:this._element},n=e.trigger(this._element,so,t);if(n.defaultPrevented)return;if(this._createPopper(),"ontouchstart"in document.documentElement&&!this._parent.closest(jo))for(const t of[].concat(...document.body.children))e.on(t,"mouseover",le);this._element.focus(),this._element.setAttribute("aria-expanded",!0),this._menu.classList.add(G),this._element.classList.add(G),e.trigger(this._element,oo,t)}hide(){if(y(this._element)||!this._isShown())return;const e={relatedTarget:this._element};this._completeHide(e)}dispose(){this._popper&&this._popper.destroy(),super.dispose()}update(){this._inNavbar=this._detectNavbar(),this._popper&&this._popper.update()}_completeHide(t){const n=e.trigger(this._element,to,t);if(n.defaultPrevented)return;if("ontouchstart"in document.documentElement)for(const t of[].concat(...document.body.children))e.off(t,"mouseover",le);this._popper&&this._popper.destroy(),this._menu.classList.remove(G),this._element.classList.remove(G),this._element.setAttribute("aria-expanded","false"),v.removeDataAttribute(this._menu,"popper"),e.trigger(this._element,no,t)}_getConfig(e){if(e=super._getConfig(e),typeof e.reference=="object"&&!g(e.reference)&&typeof e.reference.getBoundingClientRect!="function")throw new TypeError(`${Ct.toUpperCase()}: Option "reference" provided type "object" without a required "getBoundingClientRect" method.`);return e}_createPopper(){if(typeof Et=="undefined")throw new TypeError("Bootstrap's dropdowns require Popper (https://popper.js.org)");let e=this._element;this._config.reference==="parent"?e=this._parent:g(this._config.reference)?e=w(this._config.reference):typeof this._config.reference=="object"&&(e=this._config.reference);const t=this._getPopperConfig();this._popper=je(e,this._menu,t)}_isShown(){return this._menu.classList.contains(G)}_getPlacement(){const e=this._parent;if(e.classList.contains(uo))return Co;if(e.classList.contains(ho))return Eo;if(e.classList.contains(mo))return ko;if(e.classList.contains(fo))return Ao;const t=getComputedStyle(this._menu).getPropertyValue("--bs-position").trim()==="end";return e.classList.contains(lo)?t?wo:_o:t?xo:Oo}_detectNavbar(){return this._element.closest(bo)!==null}_getOffset(){const{offset:e}=this._config;return typeof e=="string"?e.split(",").map(e=>Number.parseInt(e,10)):typeof e=="function"?t=>e(t,this._element):e}_getPopperConfig(){const e={placement:this._getPlacement(),modifiers:[{name:"preventOverflow",options:{boundary:this._config.boundary}},{name:"offset",options:{offset:this._getOffset()}}]};return(this._inNavbar||this._config.display==="static")&&(v.setDataAttribute(this._menu,"popper","static"),e.modifiers=[{name:"applyStyles",enabled:!1}]),{...e,...o(this._config.popperConfig,[e])}}_selectMenuItem({key:e,target:n}){const s=t.find(yo,this._menu).filter(e=>R(e));if(!s.length)return;$e(s,n,e===bt,!s.includes(n)).focus()}static jQueryInterface(e){return this.each(function(){const t=m.getOrCreateInstance(this,e);if(typeof e!="string")return;if(typeof t[e]=="undefined")throw new TypeError(`No method named "${e}"`);t[e]()})}static clearMenus(e){if(e.button===eo||e.type==="keyup"&&e.key!==jt)return;const n=t.find(go);for(const a of n){const t=m.getInstance(a);if(!t||t._config.autoClose===!1)continue;const s=e.composedPath(),o=s.includes(t._menu);if(s.includes(t._element)||t._config.autoClose==="inside"&&!o||t._config.autoClose==="outside"&&o)continue;if(t._menu.contains(e.target)&&(e.type==="keyup"&&e.key===jt||/input|select|option|textarea|form/i.test(e.target.tagName)))continue;const i={relatedTarget:t._element};e.type==="click"&&(i.clickEvent=e),t._completeHide(i)}}static dataApiKeydownHandler(e){const a=/input|textarea/i.test(e.target.tagName),s=e.key===Xs,o=[Zs,bt].includes(e.key);if(!o&&!s)return;if(a&&!s)return;e.preventDefault();const i=this.matches(z)?this:t.prev(this,z)[0]||t.next(this,z)[0]||t.findOne(z,e.delegateTarget.parentNode),n=m.getOrCreateInstance(i);if(o){e.stopPropagation(),n.show(),n._selectMenuItem(e);return}n._isShown()&&(e.stopPropagation(),n.hide(),i.focus())}}e.on(document,yt,z,m.dataApiKeydownHandler),e.on(document,yt,me,m.dataApiKeydownHandler),e.on(document,vt,m.clearMenus),e.on(document,ro,m.clearMenus),e.on(document,vt,z,function(e){e.preventDefault(),m.getOrCreateInstance(this).toggle()}),u(m);const _t="backdrop",zo="fade",wt="show",Ot=`mousedown.bs.${_t}`,Lo={className:"modal-backdrop",clickCallback:null,isAnimated:!1,isVisible:!0,rootElement:"body"},Ro={className:"string",clickCallback:"(function|null)",isAnimated:"boolean",isVisible:"boolean",rootElement:"(element|string)"};class xt extends se{constructor(e){super(),this._config=this._getConfig(e),this._isAppended=!1,this._element=null}static get Default(){return Lo}static get DefaultType(){return Ro}static get NAME(){return _t}show(e){if(!this._config.isVisible){o(e);return}this._append();const t=this._getElement();this._config.isAnimated&&oe(t),t.classList.add(wt),this._emulateAnimation(()=>{o(e)})}hide(e){if(!this._config.isVisible){o(e);return}this._getElement().classList.remove(wt),this._emulateAnimation(()=>{this.dispose(),o(e)})}dispose(){if(!this._isAppended)return;e.off(this._element,Ot),this._element.remove(),this._isAppended=!1}_getElement(){if(!this._element){const e=document.createElement("div");e.className=this._config.className,this._config.isAnimated&&e.classList.add(zo),this._element=e}return this._element}_configAfterMerge(e){return e.rootElement=w(e.rootElement),e}_append(){if(this._isAppended)return;const t=this._getElement();this._config.rootElement.append(t),e.on(t,Ot,()=>{o(this._config.clickCallback)}),this._isAppended=!0}_emulateAnimation(e){Zn(e,this._getElement(),this._config.isAnimated)}}const Ho="focustrap",Io="bs.focustrap",be=`.${Io}`,Vo=`focusin${be}`,$o=`keydown.tab${be}`,Wo="Tab",Uo="forward",kt="backward",qo={autofocus:!0,trapElement:null},Yo={autofocus:"boolean",trapElement:"element"};class Dt extends se{constructor(e){super(),this._config=this._getConfig(e),this._isActive=!1,this._lastTabNavDirection=null}static get Default(){return qo}static get DefaultType(){return Yo}static get NAME(){return Ho}activate(){if(this._isActive)return;this._config.autofocus&&this._config.trapElement.focus(),e.off(document,be),e.on(document,Vo,e=>this._handleFocusin(e)),e.on(document,$o,e=>this._handleKeydown(e)),this._isActive=!0}deactivate(){if(!this._isActive)return;this._isActive=!1,e.off(document,be)}_handleFocusin(e){const{trapElement:n}=this._config;if(e.target===document||e.target===n||n.contains(e.target))return;const s=t.focusableChildren(n);s.length===0?n.focus():this._lastTabNavDirection===kt?s[s.length-1].focus():s[0].focus()}_handleKeydown(e){if(e.key!==Wo)return;this._lastTabNavDirection=e.shiftKey?kt:Uo}}const Nt=".fixed-top, .fixed-bottom, .is-fixed, .sticky-top",Lt=".sticky-top",Oe="padding-right",Rt="margin-right";class qe{constructor(){this._element=document.body}getWidth(){const e=document.documentElement.clientWidth;return Math.abs(window.innerWidth-e)}hide(){const e=this.getWidth();this._disableOverFlow(),this._setElementAttributes(this._element,Oe,t=>t+e),this._setElementAttributes(Nt,Oe,t=>t+e),this._setElementAttributes(Lt,Rt,t=>t-e)}reset(){this._resetElementAttributes(this._element,"overflow"),this._resetElementAttributes(this._element,Oe),this._resetElementAttributes(Nt,Oe),this._resetElementAttributes(Lt,Rt)}isOverflowing(){return this.getWidth()>0}_disableOverFlow(){this._saveInitialAttribute(this._element,"overflow"),this._element.style.overflow="hidden"}_setElementAttributes(e,t,n){const s=this.getWidth(),o=e=>{if(e!==this._element&&window.innerWidth>e.clientWidth+s)return;this._saveInitialAttribute(e,t);const o=window.getComputedStyle(e).getPropertyValue(t);e.style.setProperty(t,`${n(Number.parseFloat(o))}px`)};this._applyManipulationCallback(e,o)}_saveInitialAttribute(e,t){const n=e.style.getPropertyValue(t);n&&v.setDataAttribute(e,t,n)}_resetElementAttributes(e,t){const n=e=>{const n=v.getDataAttribute(e,t);if(n===null){e.style.removeProperty(t);return}v.removeDataAttribute(e,t),e.style.setProperty(t,n)};this._applyManipulationCallback(e,n)}_applyManipulationCallback(e,n){if(g(e)){n(e);return}for(const s of t.find(e,this._element))n(s)}}const ti="modal",ni="bs.modal",d=`.${ni}`,oi=".data-api",ii="Escape",ai=`hide${d}`,ri=`hidePrevented${d}`,Ht=`hidden${d}`,It=`show${d}`,di=`shown${d}`,ui=`resize${d}`,hi=`click.dismiss${d}`,mi=`mousedown.dismiss${d}`,fi=`keydown.dismiss${d}`,pi=`click${d}${oi}`,Bt="modal-open",vi="fade",$t="show",Se="modal-static",yi=".modal.show",_i=".modal-dialog",wi=".modal-body",Oi='[data-bs-toggle="modal"]',xi={backdrop:!0,focus:!0,keyboard:!0},Ci={backdrop:"(boolean|string)",focus:"boolean",keyboard:"boolean"};class $ extends h{constructor(e,n){super(e,n),this._dialog=t.findOne(_i,this._element),this._backdrop=this._initializeBackDrop(),this._focustrap=this._initializeFocusTrap(),this._isShown=!1,this._isTransitioning=!1,this._scrollBar=new qe,this._addEventListeners()}static get Default(){return xi}static get DefaultType(){return Ci}static get NAME(){return ti}toggle(e){return this._isShown?this.hide():this.show(e)}show(t){if(this._isShown||this._isTransitioning)return;const n=e.trigger(this._element,It,{relatedTarget:t});if(n.defaultPrevented)return;this._isShown=!0,this._isTransitioning=!0,this._scrollBar.hide(),document.body.classList.add(Bt),this._adjustDialog(),this._backdrop.show(()=>this._showElement(t))}hide(){if(!this._isShown||this._isTransitioning)return;const t=e.trigger(this._element,ai);if(t.defaultPrevented)return;this._isShown=!1,this._isTransitioning=!0,this._focustrap.deactivate(),this._element.classList.remove($t),this._queueCallback(()=>this._hideModal(),this._element,this._isAnimated())}dispose(){e.off(window,d),e.off(this._dialog,d),this._backdrop.dispose(),this._focustrap.deactivate(),super.dispose()}handleUpdate(){this._adjustDialog()}_initializeBackDrop(){return new xt({isVisible:Boolean(this._config.backdrop),isAnimated:this._isAnimated()})}_initializeFocusTrap(){return new Dt({trapElement:this._element})}_showElement(n){document.body.contains(this._element)||document.body.append(this._element),this._element.style.display="block",this._element.removeAttribute("aria-hidden"),this._element.setAttribute("aria-modal",!0),this._element.setAttribute("role","dialog"),this._element.scrollTop=0;const s=t.findOne(wi,this._dialog);s&&(s.scrollTop=0),oe(this._element),this._element.classList.add($t);const o=()=>{this._config.focus&&this._focustrap.activate(),this._isTransitioning=!1,e.trigger(this._element,di,{relatedTarget:n})};this._queueCallback(o,this._dialog,this._isAnimated())}_addEventListeners(){e.on(this._element,fi,e=>{if(e.key!==ii)return;if(this._config.keyboard){this.hide();return}this._triggerBackdropTransition()}),e.on(window,ui,()=>{this._isShown&&!this._isTransitioning&&this._adjustDialog()}),e.on(this._element,mi,t=>{e.one(this._element,hi,e=>{if(this._element!==t.target||this._element!==e.target)return;if(this._config.backdrop==="static"){this._triggerBackdropTransition();return}this._config.backdrop&&this.hide()})})}_hideModal(){this._element.style.display="none",this._element.setAttribute("aria-hidden",!0),this._element.removeAttribute("aria-modal"),this._element.removeAttribute("role"),this._isTransitioning=!1,this._backdrop.hide(()=>{document.body.classList.remove(Bt),this._resetAdjustments(),this._scrollBar.reset(),e.trigger(this._element,Ht)})}_isAnimated(){return this._element.classList.contains(vi)}_triggerBackdropTransition(){const n=e.trigger(this._element,ri);if(n.defaultPrevented)return;const s=this._element.scrollHeight>document.documentElement.clientHeight,t=this._element.style.overflowY;if(t==="hidden"||this._element.classList.contains(Se))return;s||(this._element.style.overflowY="hidden"),this._element.classList.add(Se),this._queueCallback(()=>{this._element.classList.remove(Se),this._queueCallback(()=>{this._element.style.overflowY=t},this._dialog)},this._dialog),this._element.focus()}_adjustDialog(){const t=this._element.scrollHeight>document.documentElement.clientHeight,e=this._scrollBar.getWidth(),n=e>0;if(n&&!t){const t=c()?"paddingLeft":"paddingRight";this._element.style[t]=`${e}px`}if(!n&&t){const t=c()?"paddingRight":"paddingLeft";this._element.style[t]=`${e}px`}}_resetAdjustments(){this._element.style.paddingLeft="",this._element.style.paddingRight=""}static jQueryInterface(e,t){return this.each(function(){const n=$.getOrCreateInstance(this,e);if(typeof e!="string")return;if(typeof n[e]=="undefined")throw new TypeError(`No method named "${e}"`);n[e](t)})}}e.on(document,pi,Oi,function(n){const s=t.getElementFromSelector(this);["A","AREA"].includes(this.tagName)&&n.preventDefault(),e.one(s,It,t=>{if(t.defaultPrevented)return;e.one(s,Ht,()=>{R(this)&&this.focus()})});const o=t.findOne(yi);o&&$.getInstance(o).hide();const i=$.getOrCreateInstance(s);i.toggle(this)}),_e($),u($);const ki="offcanvas",Ai="bs.offcanvas",b=`.${Ai}`,Wt=".data-api",cs=`load${b}${Wt}`,Ti="Escape",qt="show",on="showing",an="hiding",Li="offcanvas-backdrop",rn=".offcanvas.show",Pi=`show${b}`,Hi=`shown${b}`,Ii=`hide${b}`,cn=`hidePrevented${b}`,ln=`hidden${b}`,$i=`resize${b}`,Wi=`click${b}${Wt}`,Ui=`keydown.dismiss${b}`,Ki='[data-bs-toggle="offcanvas"]',qi={backdrop:!0,keyboard:!0,scroll:!1},Yi={backdrop:"(boolean|string)",keyboard:"boolean",scroll:"boolean"};class O extends h{constructor(e,t){super(e,t),this._isShown=!1,this._backdrop=this._initializeBackDrop(),this._focustrap=this._initializeFocusTrap(),this._addEventListeners()}static get Default(){return qi}static get DefaultType(){return Yi}static get NAME(){return ki}toggle(e){return this._isShown?this.hide():this.show(e)}show(t){if(this._isShown)return;const n=e.trigger(this._element,Pi,{relatedTarget:t});if(n.defaultPrevented)return;this._isShown=!0,this._backdrop.show(),this._config.scroll||(new qe).hide(),this._element.setAttribute("aria-modal",!0),this._element.setAttribute("role","dialog"),this._element.classList.add(on);const s=()=>{(!this._config.scroll||this._config.backdrop)&&this._focustrap.activate(),this._element.classList.add(qt),this._element.classList.remove(on),e.trigger(this._element,Hi,{relatedTarget:t})};this._queueCallback(s,this._element,!0)}hide(){if(!this._isShown)return;const t=e.trigger(this._element,Ii);if(t.defaultPrevented)return;this._focustrap.deactivate(),this._element.blur(),this._isShown=!1,this._element.classList.add(an),this._backdrop.hide();const n=()=>{this._element.classList.remove(qt,an),this._element.removeAttribute("aria-modal"),this._element.removeAttribute("role"),this._config.scroll||(new qe).reset(),e.trigger(this._element,ln)};this._queueCallback(n,this._element,!0)}dispose(){this._backdrop.dispose(),this._focustrap.deactivate(),super.dispose()}_initializeBackDrop(){const n=()=>{if(this._config.backdrop==="static"){e.trigger(this._element,cn);return}this.hide()},t=Boolean(this._config.backdrop);return new xt({className:Li,isVisible:t,isAnimated:!0,rootElement:this._element.parentNode,clickCallback:t?n:null})}_initializeFocusTrap(){return new Dt({trapElement:this._element})}_addEventListeners(){e.on(this._element,Ui,t=>{if(t.key!==Ti)return;if(this._config.keyboard){this.hide();return}e.trigger(this._element,cn)})}static jQueryInterface(e){return this.each(function(){const t=O.getOrCreateInstance(this,e);if(typeof e!="string")return;if(t[e]===void 0||e.startsWith("_")||e==="constructor")throw new TypeError(`No method named "${e}"`);t[e](this)})}}e.on(document,Wi,Ki,function(n){const s=t.getElementFromSelector(this);if(["A","AREA"].includes(this.tagName)&&n.preventDefault(),y(this))return;e.one(s,ln,()=>{R(this)&&this.focus()});const o=t.findOne(rn);o&&o!==s&&O.getInstance(o).hide();const i=O.getOrCreateInstance(s);i.toggle(this)}),e.on(window,cs,()=>{for(const e of t.find(rn))O.getOrCreateInstance(e).show()}),e.on(window,$i,()=>{for(const e of t.find("[aria-modal][class*=show][class*=offcanvas-]"))getComputedStyle(e).position!=="fixed"&&O.getOrCreateInstance(e).hide()}),_e(O),u(O);const Xi=/^aria-[\w-]*$/i,dn={"*":["class","dir","id","lang","role",Xi],a:["target","href","title","rel"],area:[],b:[],br:[],col:[],code:[],dd:[],div:[],dl:[],dt:[],em:[],hr:[],h1:[],h2:[],h3:[],h4:[],h5:[],h6:[],i:[],img:["src","srcset","alt","title","width","height"],li:[],ol:[],p:[],pre:[],s:[],small:[],span:[],sub:[],sup:[],strong:[],u:[],ul:[]},Zi=new Set(["background","cite","href","itemtype","longdesc","poster","src","xlink:href"]),Ji=/^(?!javascript:)(?:[a-z0-9+.-]+:|[^&:/?#]*(?:[/?#]|$))/i,ea=(e,t)=>{const n=e.nodeName.toLowerCase();return t.includes(n)?!Zi.has(n)||Boolean(Ji.test(e.nodeValue)):t.filter(e=>e instanceof RegExp).some(e=>e.test(n))};function ta(e,t,n){if(!e.length)return e;if(n&&typeof n=="function")return n(e);const o=new window.DOMParser,s=o.parseFromString(e,"text/html"),i=[].concat(...s.body.querySelectorAll("*"));for(const e of i){const n=e.nodeName.toLowerCase();if(!Object.keys(t).includes(n)){e.remove();continue}const s=[].concat(...e.attributes),o=[].concat(t["*"]||[],t[n]||[]);for(const t of s)ea(t,o)||e.removeAttribute(t.nodeName)}return s.body.innerHTML}const na="TemplateFactory",sa={allowList:dn,content:{},extraClass:"",html:!1,sanitize:!0,sanitizeFn:null,template:"<div></div>"},oa={allowList:"object",content:"object",extraClass:"(string|function)",html:"boolean",sanitize:"boolean",sanitizeFn:"(null|function)",template:"string"},ia={entry:"(string|element|function|null)",selector:"(string|element)"};class aa extends se{constructor(e){super(),this._config=this._getConfig(e)}static get Default(){return sa}static get DefaultType(){return oa}static get NAME(){return na}getContent(){return Object.values(this._config.content).map(e=>this._resolvePossibleFunction(e)).filter(Boolean)}hasContent(){return this.getContent().length>0}changeContent(e){return this._checkContent(e),this._config.content={...this._config.content,...e},this}toHtml(){const e=document.createElement("div");e.innerHTML=this._maybeSanitize(this._config.template);for(const[t,n]of Object.entries(this._config.content))this._setContent(e,n,t);const t=e.children[0],n=this._resolvePossibleFunction(this._config.extraClass);return n&&t.classList.add(...n.split(" ")),t}_typeCheckConfig(e){super._typeCheckConfig(e),this._checkContent(e.content)}_checkContent(e){for(const[t,n]of Object.entries(e))super._typeCheckConfig({selector:t,entry:n},ia)}_setContent(e,n,s){const o=t.findOne(s,e);if(!o)return;if(n=this._resolvePossibleFunction(n),!n){o.remove();return}if(g(n)){this._putElementInTemplate(w(n),o);return}if(this._config.html){o.innerHTML=this._maybeSanitize(n);return}o.textContent=n}_maybeSanitize(e){return this._config.sanitize?ta(e,this._config.allowList,this._config.sanitizeFn):e}_resolvePossibleFunction(e){return o(e,[this])}_putElementInTemplate(e,t){if(this._config.html){t.innerHTML="",t.append(e);return}t.textContent=e.textContent}}const ra="tooltip",ca=new Set(["sanitize","allowList","sanitizeFn"]),Ze="fade",da="modal",ye="show",ha=".tooltip-inner",hn=`.${da}`,mn="hide.bs.modal",Z="hover",at="focus",va="click",ba="manual",ja="hide",ya="hidden",_a="show",wa="shown",Oa="inserted",xa="click",Ca="focusin",Ea="focusout",ka="mouseenter",Aa="mouseleave",Sa={AUTO:"auto",TOP:"top",RIGHT:c()?"left":"right",BOTTOM:"bottom",LEFT:c()?"right":"left"},Ma={allowList:dn,animation:!0,boundary:"clippingParents",container:!1,customClass:"",delay:0,fallbackPlacements:["top","right","bottom","left"],html:!1,offset:[0,6],placement:"top",popperConfig:null,sanitize:!0,sanitizeFn:null,selector:!1,template:'<div class="tooltip" role="tooltip"><div class="tooltip-arrow"></div><div class="tooltip-inner"></div></div>',title:"",trigger:"hover focus"},Fa={allowList:"object",animation:"boolean",boundary:"(string|element)",container:"(string|element|boolean)",customClass:"(string|function)",delay:"(number|object)",fallbackPlacements:"array",html:"boolean",offset:"(array|string|function)",placement:"(string|function)",popperConfig:"(null|object|function)",sanitize:"boolean",sanitizeFn:"(null|function)",selector:"(string|boolean)",template:"string",title:"(string|element|function)",trigger:"string"};class H extends h{constructor(e,t){if(typeof Et=="undefined")throw new TypeError("Bootstrap's tooltips require Popper (https://popper.js.org)");super(e,t),this._isEnabled=!0,this._timeout=0,this._isHovered=null,this._activeTrigger={},this._popper=null,this._templateFactory=null,this._newContent=null,this.tip=null,this._setListeners(),this._config.selector||this._fixTitle()}static get Default(){return Ma}static get DefaultType(){return Fa}static get NAME(){return ra}enable(){this._isEnabled=!0}disable(){this._isEnabled=!1}toggleEnabled(){this._isEnabled=!this._isEnabled}toggle(){if(!this._isEnabled)return;if(this._activeTrigger.click=!this._activeTrigger.click,this._isShown()){this._leave();return}this._enter()}dispose(){clearTimeout(this._timeout),e.off(this._element.closest(hn),mn,this._hideModalHandler),this._element.getAttribute("data-bs-original-title")&&this._element.setAttribute("title",this._element.getAttribute("data-bs-original-title")),this._disposePopper(),super.dispose()}show(){if(this._element.style.display==="none")throw new Error("Please use show on visible elements");if(!this._isWithContent()||!this._isEnabled)return;const n=e.trigger(this._element,this.constructor.eventName(_a)),s=es(this._element),o=(s||this._element.ownerDocument.documentElement).contains(this._element);if(n.defaultPrevented||!o)return;this._disposePopper();const t=this._getTipElement();this._element.setAttribute("aria-describedby",t.getAttribute("id"));const{container:i}=this._config;if(this._element.ownerDocument.documentElement.contains(this.tip)||(i.append(t),e.trigger(this._element,this.constructor.eventName(Oa))),this._popper=this._createPopper(t),t.classList.add(ye),"ontouchstart"in document.documentElement)for(const t of[].concat(...document.body.children))e.on(t,"mouseover",le);const a=()=>{e.trigger(this._element,this.constructor.eventName(wa)),this._isHovered===!1&&this._leave(),this._isHovered=!1};this._queueCallback(a,this.tip,this._isAnimated())}hide(){if(!this._isShown())return;const t=e.trigger(this._element,this.constructor.eventName(ja));if(t.defaultPrevented)return;const n=this._getTipElement();if(n.classList.remove(ye),"ontouchstart"in document.documentElement)for(const t of[].concat(...document.body.children))e.off(t,"mouseover",le);this._activeTrigger[va]=!1,this._activeTrigger[at]=!1,this._activeTrigger[Z]=!1,this._isHovered=null;const s=()=>{if(this._isWithActiveTrigger())return;this._isHovered||this._disposePopper(),this._element.removeAttribute("aria-describedby"),e.trigger(this._element,this.constructor.eventName(ya))};this._queueCallback(s,this.tip,this._isAnimated())}update(){this._popper&&this._popper.update()}_isWithContent(){return Boolean(this._getTitle())}_getTipElement(){return this.tip||(this.tip=this._createTipElement(this._newContent||this._getContentForTemplate())),this.tip}_createTipElement(e){const t=this._getTemplateFactory(e).toHtml();if(!t)return null;t.classList.remove(Ze,ye),t.classList.add(`bs-${this.constructor.NAME}-auto`);const n=Yr(this.constructor.NAME).toString();return t.setAttribute("id",n),this._isAnimated()&&t.classList.add(Ze),t}setContent(e){this._newContent=e,this._isShown()&&(this._disposePopper(),this.show())}_getTemplateFactory(e){return this._templateFactory?this._templateFactory.changeContent(e):this._templateFactory=new aa({...this._config,content:e,extraClass:this._resolvePossibleFunction(this._config.customClass)}),this._templateFactory}_getContentForTemplate(){return{[ha]:this._getTitle()}}_getTitle(){return this._resolvePossibleFunction(this._config.title)||this._element.getAttribute("data-bs-original-title")}_initializeOnDelegatedTarget(e){return this.constructor.getOrCreateInstance(e.delegateTarget,this._getDelegateConfig())}_isAnimated(){return this._config.animation||this.tip&&this.tip.classList.contains(Ze)}_isShown(){return this.tip&&this.tip.classList.contains(ye)}_createPopper(e){const t=o(this._config.placement,[this,e,this._element]),n=Sa[t.toUpperCase()];return je(this._element,e,this._getPopperConfig(n))}_getOffset(){const{offset:e}=this._config;return typeof e=="string"?e.split(",").map(e=>Number.parseInt(e,10)):typeof e=="function"?t=>e(t,this._element):e}_resolvePossibleFunction(e){return o(e,[this._element])}_getPopperConfig(e){const t={placement:e,modifiers:[{name:"flip",options:{fallbackPlacements:this._config.fallbackPlacements}},{name:"offset",options:{offset:this._getOffset()}},{name:"preventOverflow",options:{boundary:this._config.boundary}},{name:"arrow",options:{element:`.${this.constructor.NAME}-arrow`}},{name:"preSetPlacement",enabled:!0,phase:"beforeMain",fn:e=>{this._getTipElement().setAttribute("data-popper-placement",e.state.placement)}}]};return{...t,...o(this._config.popperConfig,[t])}}_setListeners(){const t=this._config.trigger.split(" ");for(const n of t)if(n==="click")e.on(this._element,this.constructor.eventName(xa),this._config.selector,e=>{const t=this._initializeOnDelegatedTarget(e);t.toggle()});else if(n!==ba){const t=n===Z?this.constructor.eventName(ka):this.constructor.eventName(Ca),s=n===Z?this.constructor.eventName(Aa):this.constructor.eventName(Ea);e.on(this._element,t,this._config.selector,e=>{const t=this._initializeOnDelegatedTarget(e);t._activeTrigger[e.type==="focusin"?at:Z]=!0,t._enter()}),e.on(this._element,s,this._config.selector,e=>{const t=this._initializeOnDelegatedTarget(e);t._activeTrigger[e.type==="focusout"?at:Z]=t._element.contains(e.relatedTarget),t._leave()})}this._hideModalHandler=()=>{this._element&&this.hide()},e.on(this._element.closest(hn),mn,this._hideModalHandler)}_fixTitle(){const e=this._element.getAttribute("title");if(!e)return;!this._element.getAttribute("aria-label")&&!this._element.textContent.trim()&&this._element.setAttribute("aria-label",e),this._element.setAttribute("data-bs-original-title",e),this._element.removeAttribute("title")}_enter(){if(this._isShown()||this._isHovered){this._isHovered=!0;return}this._isHovered=!0,this._setTimeout(()=>{this._isHovered&&this.show()},this._config.delay.show)}_leave(){if(this._isWithActiveTrigger())return;this._isHovered=!1,this._setTimeout(()=>{this._isHovered||this.hide()},this._config.delay.hide)}_setTimeout(e,t){clearTimeout(this._timeout),this._timeout=setTimeout(e,t)}_isWithActiveTrigger(){return Object.values(this._activeTrigger).includes(!0)}_getConfig(e){const t=v.getDataAttributes(this._element);for(const e of Object.keys(t))ca.has(e)&&delete t[e];return e={...t,...typeof e=="object"&&e?e:{}},e=this._mergeConfigObj(e),e=this._configAfterMerge(e),this._typeCheckConfig(e),e}_configAfterMerge(e){return e.container=e.container===!1?document.body:w(e.container),typeof e.delay=="number"&&(e.delay={show:e.delay,hide:e.delay}),typeof e.title=="number"&&(e.title=e.title.toString()),typeof e.content=="number"&&(e.content=e.content.toString()),e}_getDelegateConfig(){const e={};for(const[t,n]of Object.entries(this._config))this.constructor.Default[t]!==n&&(e[t]=n);return e.selector=!1,e.trigger="manual",e}_disposePopper(){this._popper&&(this._popper.destroy(),this._popper=null),this.tip&&(this.tip.remove(),this.tip=null)}static jQueryInterface(e){return this.each(function(){const t=H.getOrCreateInstance(this,e);if(typeof e!="string")return;if(typeof t[e]=="undefined")throw new TypeError(`No method named "${e}"`);t[e]()})}}u(H);const za="popover",Da=".popover-header",Na=".popover-body",La={...H.Default,content:"",offset:[0,8],placement:"right",template:'<div class="popover" role="tooltip"><div class="popover-arrow"></div><h3 class="popover-header"></h3><div class="popover-body"></div></div>',trigger:"click"},Ra={...H.DefaultType,content:"(null|string|element|function)"};class mt extends H{static get Default(){return La}static get DefaultType(){return Ra}static get NAME(){return za}_isWithContent(){return this._getTitle()||this._getContent()}_getContentForTemplate(){return{[Da]:this._getTitle(),[Na]:this._getContent()}}_getContent(){return this._resolvePossibleFunction(this._config.content)}static jQueryInterface(e){return this.each(function(){const t=mt.getOrCreateInstance(this,e);if(typeof e!="string")return;if(typeof t[e]=="undefined")throw new TypeError(`No method named "${e}"`);t[e]()})}}u(mt);const Ha="scrollspy",Ia="bs.scrollspy",Ie=`.${Ia}`,Va=".data-api",$a=`activate${Ie}`,pn=`click${Ie}`,Ua=`load${Ie}${Va}`,Ka="dropdown-item",W="active",Ya='[data-bs-spy="scroll"]',Ge="[href]",Xa=".nav, .list-group",gn=".nav-link",Za=".nav-item",Ja=".list-group-item",er=`${gn}, ${Za} > ${gn}, ${Ja}`,tr=".dropdown",nr=".dropdown-toggle",sr={offset:null,rootMargin:"0px 0px -25%",smoothScroll:!1,target:null,threshold:[.1,.5,1]},or={offset:"(number|null)",rootMargin:"string",smoothScroll:"boolean",target:"element",threshold:"array"};class xe extends h{constructor(e,t){super(e,t),this._targetLinks=new Map,this._observableSections=new Map,this._rootElement=getComputedStyle(this._element).overflowY==="visible"?null:this._element,this._activeTarget=null,this._observer=null,this._previousScrollData={visibleEntryTop:0,parentScrollTop:0},this.refresh()}static get Default(){return sr}static get DefaultType(){return or}static get NAME(){return Ha}refresh(){this._initializeTargetsAndObservables(),this._maybeEnableSmoothScroll(),this._observer?this._observer.disconnect():this._observer=this._getNewObserver();for(const e of this._observableSections.values())this._observer.observe(e)}dispose(){this._observer.disconnect(),super.dispose()}_configAfterMerge(e){return e.target=w(e.target)||document.body,e.rootMargin=e.offset?`${e.offset}px 0px -30%`:e.rootMargin,typeof e.threshold=="string"&&(e.threshold=e.threshold.split(",").map(e=>Number.parseFloat(e))),e}_maybeEnableSmoothScroll(){if(!this._config.smoothScroll)return;e.off(this._config.target,pn),e.on(this._config.target,pn,Ge,e=>{const t=this._observableSections.get(e.target.hash);if(t){e.preventDefault();const n=this._rootElement||window,s=t.offsetTop-this._element.offsetTop;if(n.scrollTo){n.scrollTo({top:s,behavior:"smooth"});return}n.scrollTop=s}})}_getNewObserver(){const e={root:this._rootElement,threshold:this._config.threshold,rootMargin:this._config.rootMargin};return new IntersectionObserver(e=>this._observerCallback(e),e)}_observerCallback(e){const n=e=>this._targetLinks.get(`#${e.target.id}`),s=e=>{this._previousScrollData.visibleEntryTop=e.target.offsetTop,this._process(n(e))},t=(this._rootElement||document.documentElement).scrollTop,o=t>=this._previousScrollData.parentScrollTop;this._previousScrollData.parentScrollTop=t;for(const i of e){if(!i.isIntersecting){this._activeTarget=null,this._clearActiveClass(n(i));continue}const a=i.target.offsetTop>=this._previousScrollData.visibleEntryTop;if(o&&a){if(s(i),!t)return;continue}!o&&!a&&s(i)}}_initializeTargetsAndObservables(){this._targetLinks=new Map,this._observableSections=new Map;const e=t.find(Ge,this._config.target);for(const n of e){if(!n.hash||y(n))continue;const s=t.findOne(decodeURI(n.hash),this._element);R(s)&&(this._targetLinks.set(decodeURI(n.hash),n),this._observableSections.set(n.hash,s))}}_process(t){if(this._activeTarget===t)return;this._clearActiveClass(this._config.target),this._activeTarget=t,t.classList.add(W),this._activateParents(t),e.trigger(this._element,$a,{relatedTarget:t})}_activateParents(e){if(e.classList.contains(Ka)){t.findOne(nr,e.closest(tr)).classList.add(W);return}for(const n of t.parents(e,Xa))for(const e of t.prev(n,er))e.classList.add(W)}_clearActiveClass(e){e.classList.remove(W);const n=t.find(`${Ge}.${W}`,e);for(const e of n)e.classList.remove(W)}static jQueryInterface(e){return this.each(function(){const t=xe.getOrCreateInstance(this,e);if(typeof e!="string")return;if(t[e]===void 0||e.startsWith("_")||e==="constructor")throw new TypeError(`No method named "${e}"`);t[e]()})}}e.on(window,Ua,()=>{for(const e of t.find(Ya))xe.getOrCreateInstance(e)}),u(xe);const ar="tab",rr="bs.tab",M=`.${rr}`,lr=`hide${M}`,dr=`hidden${M}`,ur=`show${M}`,hr=`shown${M}`,mr=`click${M}`,fr=`keydown${M}`,pr=`load${M}`,gr="ArrowLeft",vn="ArrowRight",br="ArrowUp",yn="ArrowDown",ft="Home",wn="End",S="active",Mn="fade",Ye="show",Cr="dropdown",Wn=".dropdown-toggle",kr=".dropdown-menu",Ne=`:not(${Wn})`,Sr='.list-group, .nav, [role="tablist"]',Mr=".nav-item, .list-group-item",Fr=`.nav-link${Ne}, .list-group-item${Ne}, [role="tab"]${Ne}`,Gn='[data-bs-toggle="tab"], [data-bs-toggle="pill"], [data-bs-toggle="list"]',Pe=`${Fr}, ${Gn}`,Dr=`.${S}[data-bs-toggle="tab"], .${S}[data-bs-toggle="pill"], .${S}[data-bs-toggle="list"]`;class B extends h{constructor(t){if(super(t),this._parent=this._element.closest(Sr),!this._parent)return;this._setInitialAttributes(this._parent,this._getChildren()),e.on(this._element,fr,e=>this._keydown(e))}static get NAME(){return ar}show(){const t=this._element;if(this._elemIsActive(t))return;const n=this._getActiveElem(),s=n?e.trigger(n,lr,{relatedTarget:t}):null,o=e.trigger(t,ur,{relatedTarget:n});if(o.defaultPrevented||s&&s.defaultPrevented)return;this._deactivate(n,t),this._activate(t,n)}_activate(n,s){if(!n)return;n.classList.add(S),this._activate(t.getElementFromSelector(n));const o=()=>{if(n.getAttribute("role")!=="tab"){n.classList.add(Ye);return}n.removeAttribute("tabindex"),n.setAttribute("aria-selected",!0),this._toggleDropDown(n,!0),e.trigger(n,hr,{relatedTarget:s})};this._queueCallback(o,n,n.classList.contains(Mn))}_deactivate(n,s){if(!n)return;n.classList.remove(S),n.blur(),this._deactivate(t.getElementFromSelector(n));const o=()=>{if(n.getAttribute("role")!=="tab"){n.classList.remove(Ye);return}n.setAttribute("aria-selected",!1),n.setAttribute("tabindex","-1"),this._toggleDropDown(n,!1),e.trigger(n,dr,{relatedTarget:s})};this._queueCallback(o,n,n.classList.contains(Mn))}_keydown(e){if(![gr,vn,br,yn,ft,wn].includes(e.key))return;e.stopPropagation(),e.preventDefault();const n=this._getChildren().filter(e=>!y(e));let t;if([ft,wn].includes(e.key))t=n[e.key===ft?0:n.length-1];else{const s=[vn,yn].includes(e.key);t=$e(n,e.target,s,!0)}t&&(t.focus({preventScroll:!0}),B.getOrCreateInstance(t).show())}_getChildren(){return t.find(Pe,this._parent)}_getActiveElem(){return this._getChildren().find(e=>this._elemIsActive(e))||null}_setInitialAttributes(e,t){this._setAttributeIfNotExists(e,"role","tablist");for(const e of t)this._setInitialAttributesOnChild(e)}_setInitialAttributesOnChild(e){e=this._getInnerElement(e);const t=this._elemIsActive(e),n=this._getOuterElement(e);e.setAttribute("aria-selected",t),n!==e&&this._setAttributeIfNotExists(n,"role","presentation"),t||e.setAttribute("tabindex","-1"),this._setAttributeIfNotExists(e,"role","tab"),this._setInitialAttributesOnTargetPanel(e)}_setInitialAttributesOnTargetPanel(e){const n=t.getElementFromSelector(e);if(!n)return;this._setAttributeIfNotExists(n,"role","tabpanel"),e.id&&this._setAttributeIfNotExists(n,"aria-labelledby",`${e.id}`)}_toggleDropDown(e,n){const s=this._getOuterElement(e);if(!s.classList.contains(Cr))return;const o=(e,o)=>{const i=t.findOne(e,s);i&&i.classList.toggle(o,n)};o(Wn,S),o(kr,Ye),s.setAttribute("aria-expanded",n)}_setAttributeIfNotExists(e,t,n){e.hasAttribute(t)||e.setAttribute(t,n)}_elemIsActive(e){return e.classList.contains(S)}_getInnerElement(e){return e.matches(Pe)?e:t.findOne(Pe,e)}_getOuterElement(e){return e.closest(Mr)||e}static jQueryInterface(e){return this.each(function(){const t=B.getOrCreateInstance(this);if(typeof e!="string")return;if(t[e]===void 0||e.startsWith("_")||e==="constructor")throw new TypeError(`No method named "${e}"`);t[e]()})}}e.on(document,mr,Gn,function(e){if(["A","AREA"].includes(this.tagName)&&e.preventDefault(),y(this))return;B.getOrCreateInstance(this).show()}),e.on(window,pr,()=>{for(const e of t.find(Dr))B.getOrCreateInstance(e)}),u(B);const Lr="toast",Rr="bs.toast",x=`.${Rr}`,Hr=`mouseover${x}`,Ir=`mouseout${x}`,Br=`focusin${x}`,Vr=`focusout${x}`,$r=`hide${x}`,Wr=`hidden${x}`,Ur=`show${x}`,Kr=`shown${x}`,qr="fade",os="hide",ve="show",he="showing",Qr={animation:"boolean",autohide:"boolean",delay:"number"},Zr={animation:!0,autohide:!0,delay:5e3};class ue extends h{constructor(e,t){super(e,t),this._timeout=null,this._hasMouseInteraction=!1,this._hasKeyboardInteraction=!1,this._setListeners()}static get Default(){return Zr}static get DefaultType(){return Qr}static get NAME(){return Lr}show(){const t=e.trigger(this._element,Ur);if(t.defaultPrevented)return;this._clearTimeout(),this._config.animation&&this._element.classList.add(qr);const n=()=>{this._element.classList.remove(he),e.trigger(this._element,Kr),this._maybeScheduleHide()};this._element.classList.remove(os),oe(this._element),this._element.classList.add(ve,he),this._queueCallback(n,this._element,this._config.animation)}hide(){if(!this.isShown())return;const t=e.trigger(this._element,$r);if(t.defaultPrevented)return;const n=()=>{this._element.classList.add(os),this._element.classList.remove(he,ve),e.trigger(this._element,Wr)};this._element.classList.add(he),this._queueCallback(n,this._element,this._config.animation)}dispose(){this._clearTimeout(),this.isShown()&&this._element.classList.remove(ve),super.dispose()}isShown(){return this._element.classList.contains(ve)}_maybeScheduleHide(){if(!this._config.autohide)return;if(this._hasMouseInteraction||this._hasKeyboardInteraction)return;this._timeout=setTimeout(()=>{this.hide()},this._config.delay)}_onInteraction(e,t){switch(e.type){case"mouseover":case"mouseout":{this._hasMouseInteraction=t;break}case"focusin":case"focusout":{this._hasKeyboardInteraction=t;break}}if(t){this._clearTimeout();return}const n=e.relatedTarget;if(this._element===n||this._element.contains(n))return;this._maybeScheduleHide()}_setListeners(){e.on(this._element,Hr,e=>this._onInteraction(e,!0)),e.on(this._element,Ir,e=>this._onInteraction(e,!1)),e.on(this._element,Br,e=>this._onInteraction(e,!0)),e.on(this._element,Vr,e=>this._onInteraction(e,!1))}_clearTimeout(){clearTimeout(this._timeout),this._timeout=null}static jQueryInterface(e){return this.each(function(){const t=ue.getOrCreateInstance(this,e);if(typeof e=="string"){if(typeof t[e]=="undefined")throw new TypeError(`No method named "${e}"`);t[e](this)}})}}_e(ue),u(ue);const ec={Alert:de,Button:fe,Carousel:ee,Collapse:te,Dropdown:m,Modal:$,Offcanvas:O,Popover:mt,ScrollSpy:xe,Tab:B,Toast:ue,Tooltip:H};return ec}),function e(t){"use strict";try{module&&(t=module)}catch{}t._factory=e;function g(e){return"undefined"==typeof e||e}function M(e){const t=Array(e);for(let s=0;s<e;s++)t[s]=n();return t}function n(){return Object.create(null)}function re(e,t){return t.length-e.length}function i(e){return"string"==typeof e}function a(e){return"object"==typeof e}function x(e){return"function"==typeof e}function U(e,t){var n=Q;if(e&&(t&&(e=f(e,t)),this.H&&(e=f(e,this.H)),this.J&&1<e.length&&(e=f(e,this.J)),n||""===n)){if(t=e.split(n),this.filter){e=this.filter,n=t.length;const s=[];for(let o=0,a=0;o<n;o++){const i=t[o];i&&!e[i]&&(s[a++]=i)}e=s}else e=t;return e}return e}const Q=/[\p{Z}\p{S}\p{P}\p{C}]+/u,J=/[\u0300-\u036f]/g;function V(e,t){const a=Object.keys(e),r=a.length,n=[];let s="",i=0;for(let l=0,c,d;l<r;l++)c=a[l],(d=e[c])?(n[i++]=o(t?"(?!\\b)"+c+"(\\b|_)":c),n[i++]=d):s+=(s?"|":"")+c;return s&&(n[i++]=o(t?"(?!\\b)("+s+")(\\b|_)":"("+s+")"),n[i]=""),n}function f(e,t){for(let n=0,s=t.length;n<s&&(e=e.replace(t[n],t[n+1]),e);n+=2);return e}function o(e){return new RegExp(e,"g")}function B(e){let t="",n="";for(let s=0,i=e.length,o;s<i;s++)(o=e[s])!==n&&(t+=n=o);return t}var s,L,I,W,Y,ie={encode:P,F:!1,G:""};function P(e){return U.call(this,(""+e).toLowerCase(),!1)}const N={},r={};function T(e){m(e,"add"),m(e,"append"),m(e,"search"),m(e,"update"),m(e,"remove")}function m(e,t){e[t+"Async"]=function(){const s=this,e=arguments;var n=e[e.length-1];let o;return x(n)&&(o=n,delete e[e.length-1]),n=new Promise(function(n){setTimeout(function(){s.async=!0;const o=s[t].apply(s,e);s.async=!1,n(o)})}),o?(n.then(o),this):n}}function F(e,t,s,o){const l=e.length;let a=[],i,c,r=0;o&&(o=[]);for(let d=l-1;0<=d;d--){const h=e[d],f=h.length,u=n();let m=!i;for(let e=0;e<f;e++){const n=h[e],p=n.length;if(p)for(let f=0,h,e;f<p;f++)if(e=n[f],i){{if(i[e]){if(!d)if(s)s--;else if(a[r++]=e,r===t)return a;(d||o)&&(u[e]=1),m=!0}if(o&&(h=(c[e]||0)+1,c[e]=h,h<l)){const t=o[h-2]||(o[h-2]=[]);t[t.length]=e}}}else u[e]=1}if(o)i||(c=u);else if(!m)return[];i=u}if(o)for(let e=o.length-1,n,c;0<=e;e--){n=o[e],c=n.length;for(let o=0,e;o<c;o++)if(e=n[o],!i[e]){if(s)s--;else if(a[r++]=e,r===t)return a;i[e]=1}}return a}function ce(e,t){const o=n(),i=n(),s=[];for(let t=0;t<e.length;t++)o[e[t]]=1;for(let e=0,n;e<t.length;e++){n=t[e];for(let t=0,e;t<n.length;t++)e=n[t],o[e]&&!i[e]&&(i[e]=1,s[s.length]=e)}return s}function j(e){this.l=!0!==e&&e,this.cache=n(),this.h=[]}function S(e,t,n){a(e)&&(e=e.query);let s=this.cache.get(e);return s||(s=this.search(e,t,n),this.cache.set(e,s)),s}j.prototype.set=function(e,t){if(!this.cache[e]){var n=this.h.length;n===this.l?delete this.cache[this.h[n-1]]:n++;for(--n;0<n;n--)this.h[n]=this.h[n-1];this.h[0]=e}this.cache[e]=t},j.prototype.get=function(e){const t=this.cache[e];if(this.l&&t&&(e=this.h.indexOf(e))){const t=this.h[e-1];this.h[e-1]=this.h[e],this.h[e]=t}return t};const ee={memory:{charset:"latin:extra",D:3,B:4,m:!1},performance:{D:3,B:3,s:!1,context:{depth:2,D:1}},match:{charset:"latin:extra",G:"reverse"},score:{charset:"latin:advanced",D:20,B:3,context:{depth:3,D:9}},default:{}};function A(e,t,n,s,o,i,a,r){setTimeout(function(){const c=e(n?n+"."+s:s,JSON.stringify(a));c&&c.then?c.then(function(){t.export(e,t,n,o,i+1,r)}):t.export(e,t,n,o,i+1,r)})}function c(e,t){if(!(this instanceof c))return new c(e);if(e){i(e)?e=ee[e]:(s=e.preset)&&(e=Object.assign({},s[s],e)),s=e.charset;var s,o=e.lang;i(s)&&(-1===s.indexOf(":")&&(s+=":default"),s=r[s]),i(o)&&(o=N[o])}else e={};let a,l,d=e.context||{};if(this.encode=e.encode||s&&s.encode||P,this.register=t||n(),this.D=a=e.resolution||9,this.G=t=s&&s.G||e.tokenize||"strict",this.depth="strict"===t&&d.depth,this.l=g(d.bidirectional),this.s=l=g(e.optimize),this.m=g(e.fastupdate),this.B=e.minlength||1,this.C=e.boost,this.map=l?M(a):n(),this.A=a=d.resolution||1,this.h=l?M(a):n(),this.F=s&&s.F||e.rtl,this.H=(t=e.matcher||o&&o.H)&&V(t,!1),this.J=(t=e.stemmer||o&&o.J)&&V(t,!0),s=t=e.filter||o&&o.filter){s=t,o=n();for(let e=0,t=s.length;e<t;e++)o[s[e]]=1;s=o}this.filter=s,this.cache=(t=e.cache)&&new j(t)}s=c.prototype,s.append=function(e,t){return this.add(e,t,!0)},s.add=function(e,t,s,o){if(t&&(e||0===e)){if(!o&&!s&&this.register[e])return this.update(e,t);if(t=this.encode(t),o=t.length){const f=n(),d=n(),m=this.depth,u=this.D;for(let g=0;g<o;g++){let p=t[this.F?o-1-g:g];if(r=p.length,p&&r>=this.B&&(m||!d[p])){var i,r,l,a=b(u,o,g),c="";switch(this.G){case"full":if(2<r){for(a=0;a<r;a++)for(i=r;i>a;i--)i-a>=this.B&&(l=b(u,o,g,r,a),c=p.substring(a,i),h(this,d,c,l,e,s));break}case"reverse":if(1<r){for(i=r-1;0<i;i--)c=p[i]+c,c.length>=this.B&&h(this,d,c,b(u,o,g,r,i),e,s);c=""}case"forward":if(1<r){for(i=0;i<r;i++)c+=p[i],c.length>=this.B&&h(this,d,c,a,e,s);break}default:if(this.C&&(a=Math.min(a/this.C(t,p,g)|0,u-1)),h(this,d,p,a,e,s),m&&1<o&&g<o-1)for(r=n(),c=this.A,a=p,i=Math.min(m+1,o-g),r[a]=1,l=1;l<i;l++)if((p=t[this.F?o-1-g-l:g+l])&&p.length>=this.B&&!r[p]){r[p]=1;const t=this.l&&p>a;h(this,f,t?a:p,b(c+(o/2>c?0:1),o,g,i-1,l-1),e,s,t?p:a)}}}}this.m||(this.register[e]=1)}}return this};function b(e,t,n,s,o){return n&&1<e?t+(s||0)<=e?n+(o||0):(e-1)/(t+(s||0))*(n+(o||0))+1|0:0}function h(e,t,s,o,i,a,r){let c=r?e.h:e.map;(!t[s]||r&&!t[s][r])&&(e.s&&(c=c[o]),r?(t=t[s]||(t[s]=n()),t[r]=1,c=c[r]||(c[r]=n())):t[s]=1,c=c[s]||(c[s]=[]),e.s||(c=c[o]||(c[o]=[])),a&&c.includes(i)||(c[c.length]=i,e.m&&(e=e.register[i]||(e.register[i]=[]),e[e.length]=c)))}s.search=function(e,t,s){s||(!t&&a(e)?(s=e,e=s.query):a(t)&&(s=t));let i=[],o,r,d=0;if(s){e=s.query||e,t=s.limit,d=s.offset||0;var l,c=s.context;r=s.suggest}if(e&&(e=this.encode(""+e),o=e.length,1<o)){s=n(),l=[];for(let n=0,a=0,t;n<o;n++)if((t=e[n])&&t.length>=this.B&&!s[t])if(this.s||r||this.map[t])l[a++]=t,s[t]=1;else return i;e=l,o=e.length}if(!o)return i;t||(t=100),c=this.depth&&1<o&&!1!==c,s=0;let u;c?(u=e[0],s=1):1<o&&e.sort(re);for(let n,a;s<o;s++){if(a=e[s],c?(n=E(this,i,r,t,d,2===o,a,u),r&&!1===n&&i.length||(u=a)):n=E(this,i,r,t,d,1===o,a),n)return n;if(r&&s===o-1){if(l=i.length,!l){if(c){c=0,s=-1;continue}return i}if(1===l)return z(i[0],t,d)}}return F(i,t,d,r)};function E(e,t,n,s,o,i,a,r){let l=[],c=r?e.h:e.map;if(e.s||(c=D(c,a,r,e.l)),c){let n=0;const d=Math.min(c.length,r?e.A:e.D);for(let u=0,m=0,t,h;u<d;u++)if((t=c[u])&&(e.s&&(t=D(t,a,r,e.l)),o&&t&&i&&(h=t.length,h<=o?(o-=h,t=null):(t=t.slice(o),o=0)),t&&(l[n++]=t,i&&(m+=t.length,m>=s))))break;if(n){if(i)return z(l,s,0);t[t.length]=l;return}}return!n&&l}function z(e,t,n){return e=1===e.length?e[0]:[].concat.apply([],e),n||e.length>t?e.slice(n,n+t):e}function D(e,t,n,s){return n?(s=s&&t>n,e=(e=e[s?t:n])&&e[s?n:t]):e=e[t],e}s.contain=function(e){return!!this.register[e]},s.update=function(e,t){return this.remove(e).add(e,t)},s.remove=function(e,t){const n=this.register[e];if(n){if(this.m)for(let t=0,s;t<n.length;t++)s=n[t],s.splice(s.indexOf(e),1);else p(this.map,e,this.D,this.s),this.depth&&p(this.h,e,this.A,this.s);if(t||delete this.register[e],this.cache){t=this.cache;for(let n=0,o,s;n<t.h.length;n++)s=t.h[n],o=t.cache[s],o.includes(e)&&(t.h.splice(n--,1),delete t.cache[s])}}return this};function p(e,t,n,s,o){let i=0;if(e.constructor===Array)if(o)t=e.indexOf(t),-1!==t?1<e.length&&(e.splice(t,1),i++):i++;else{o=Math.min(e.length,n);for(let a=0,r;a<o;a++)(r=e[a])&&(i=p(r,t,n,s,o),s||i||delete e[a])}else for(let a in e)(i=p(e[a],t,n,s,o))||delete e[a];return i}s.searchCache=S,s.export=function(e,t,s,o,i,a){let l=!0;"undefined"==typeof a&&(l=new Promise(e=>{a=e}));let c,r;switch(i||(i=0)){case 0:if(c="reg",this.m){r=n();for(let e in this.register)r[e]=1}else r=this.register;break;case 1:c="cfg",r={doc:0,opt:this.s?1:0};break;case 2:c="map",r=this.map;break;case 3:c="ctx",r=this.h;break;default:"undefined"==typeof s&&a&&a();return}return A(e,t||this,s,c,o,i,r,a),l},s.import=function(e,t){if(t)switch(i(t)&&(t=JSON.parse(t)),e){case"cfg":this.s=!!t.opt;break;case"reg":this.m=!1,this.register=t;break;case"map":this.map=t;break;case"ctx":this.h=t}},T(c.prototype);function oe(e){e=e.data;var n,s=t._index;const o=e.args;switch(n=e.task,n){case"init":n=e.options||{},e=e.factory,s=n.encode,n.cache=!1,s&&0===s.indexOf("function")&&(n.encode=Function("return "+s)()),e?(Function("return "+e)()(t),t._index=new t.FlexSearch.Index(n),delete t.FlexSearch):t._index=new c(n);break;default:e=e.id,s=s[n].apply(s,o),postMessage("search"===n?{id:e,msg:s}:{id:e})}}let R=0;function l(e){if(!(this instanceof l))return new l(e);var s;e?x(s=e.encode)&&(e.encode=s.toString()):e={},(s=(t||window)._factory)&&(s=s.toString());const i="undefined"==typeof window&&t.exports,o=this;this.o=G(s,i,e.worker),this.h=n(),this.o&&(i?this.o.on("message",function(e){o.h[e.id](e.msg),delete o.h[e.id]}):this.o.onmessage=function(e){e=e.data,o.h[e.id](e.msg),delete o.h[e.id]},this.o.postMessage({task:"init",factory:s,options:e}))}u("add"),u("append"),u("search"),u("update"),u("remove");function u(e){l.prototype[e]=l.prototype[e+"Async"]=function(){const o=this,t=[].slice.call(arguments);var n=t[t.length-1];let s;return x(n)&&(s=n,t.splice(t.length-1,1)),n=new Promise(function(n){setTimeout(function(){o.h[++R]=n,o.o.postMessage({task:e,id:R,args:t})})}),s?(n.then(s),this):n}}function G(e,t,n){let s;try{s=t?new(require("worker_threads").Worker)(__dirname+"/node/node.js"):e?new Worker(URL.createObjectURL(new Blob(["onmessage="+oe.toString()],{type:"text/javascript"}))):new Worker(i(n)?n:"worker/worker.js",{type:"module"})}catch{}return s}function d(e){if(!(this instanceof d))return new d(e);var t,s=e.document||e.doc||e;this.K=[],this.h=[],this.A=[],this.register=n(),this.key=(t=s.key||s.id)&&v(t,this.A)||"id",this.m=g(e.fastupdate),this.C=(t=s.store)&&!0!==t&&[],this.store=t&&n(),this.I=(t=s.tag)&&v(t,this.A),this.l=t&&n(),this.cache=(t=e.cache)&&new j(t),e.cache=!1,this.o=e.worker,this.async=!1,t=n();let o=s.index||s.field||s;i(o)&&(o=[o]);for(let r=0,n,s;r<o.length;r++)n=o[r],i(n)||(s=n,n=n.field),s=a(s)?Object.assign({},e,s):e,this.o&&(t[n]=new l(s),t[n].o||(this.o=!1)),this.o||(t[n]=new c(s,this.register)),this.K[r]=v(n,this.A),this.h[r]=n;if(this.C)for(e=s.store,i(e)&&(e=[e]),s=0;s<e.length;s++)this.C[s]=v(e[s],this.A);this.index=t}function v(e,t){const n=e.split(":");let s=0;for(let o=0;o<n.length;o++)e=n[o],0<=e.indexOf("[]")&&(e=e.substring(0,e.length-2))&&(t[s]=!0),e&&(n[s++]=e);return s<n.length&&(n.length=s),1<s?n:n[0]}function C(e,t){if(i(t))e=e[t];else for(let n=0;e&&n<t.length;n++)e=e[t[n]];return e}function w(e,t,s,o,i){if(e=e[i],o===s.length-1)t[i]=e;else if(e)if(e.constructor===Array)for(t=t[i]=Array(e.length),i=0;i<e.length;i++)w(e,t,s,o,i);else t=t[i]||(t[i]=n()),i=s[++o],w(e,t,s,o,i)}function O(e,t,n,s,o,i,a,r){if(e=e[a])if(s===t.length-1){if(e.constructor===Array){if(n[s]){for(t=0;t<e.length;t++)o.add(i,e[t],!0,!0);return}e=e.join(" ")}o.add(i,e,r,!0)}else if(e.constructor===Array)for(a=0;a<e.length;a++)O(e,t,n,s,o,i,a,r);else a=t[++s],O(e,t,n,s,o,i,a,r)}s=d.prototype,s.add=function(e,t,s){if(a(e)&&(t=e,e=C(t,this.key)),t&&(e||0===e)){if(!s&&this.register[e])return this.update(e,t);for(let o=0,n,a;o<this.h.length;o++)a=this.h[o],n=this.K[o],i(n)&&(n=[n]),O(t,n,this.A,0,this.index[a],e,n[0],s);if(this.I){let o=C(t,this.I),a=n();i(o)&&(o=[o]);for(let i=0,t,n;i<o.length;i++)if(t=o[i],!a[t]&&(a[t]=1,n=this.l[t]||(this.l[t]=[]),!s||!n.includes(e))&&(n[n.length]=e,this.m)){const t=this.register[e]||(this.register[e]=[]);t[t.length]=n}}if(this.store&&(!s||!this.store[e])){let s;if(this.C){s=n();for(let n=0,e;n<this.C.length;n++)e=this.C[n],i(e)?s[e]=t[e]:w(t,s,e,0,e[0])}this.store[e]=s||t}}return this},s.append=function(e,t){return this.add(e,t,!0)},s.update=function(e,t){return this.remove(e).add(e,t)},s.remove=function(e){if(a(e)&&(e=C(e,this.key)),this.register[e]){for(var t=0;t<this.h.length&&(this.index[this.h[t]].remove(e,!this.o),!this.m);t++);if(this.I&&!this.m)for(let n in this.l){t=this.l[n];const s=t.indexOf(e);-1!==s&&(1<t.length?t.splice(s,1):delete this.l[n])}this.store&&delete this.store[e],delete this.register[e]}return this},s.search=function(e,t,n,s){n||(!t&&a(e)?(n=e,e=""):a(t)&&(n=t,t=0));let c=[],m=[],f,d,r,o,l,p,u=0;if(n)if(n.constructor===Array)r=n,n=null;else{if(e=n.query||e,r=(f=n.pluck)||n.index||n.field,o=n.tag,d=this.store&&n.enrich,l="and"===n.bool,t=n.limit||t||100,p=n.offset||0,o&&(i(o)&&(o=[o]),!e)){for(let e=0,n;e<o.length;e++)(n=te.call(this,o[e],t,p,d))&&(c[c.length]=n,u++);return u?c:[]}i(r)&&(r=[r])}r||(r=this.h),l=l&&(1<r.length||o&&1<o.length);const h=!s&&(this.o||this.async)&&[];for(let v=0,a,f,b;v<r.length;v++){let g;if(f=r[v],i(f)||(g=f,f=g.field,e=g.query||e,t=g.limit||t,d=g.enrich||d),h)h[v]=this.index[f].searchAsync(e,t,g||n);else{if(s?a=s[v]:a=this.index[f].search(e,t,g||n),b=a&&a.length,o&&b){const e=[];let n=0;l&&(e[0]=[a]);for(let s=0,i,t;s<o.length;s++)(i=o[s],b=(t=this.l[i])&&t.length)&&(n++,e[e.length]=l?[t]:t);n&&(a=l?F(e,t||100,p||0):ce(a,e),b=a.length)}if(b)m[u]=f,c[u++]=a;else if(l)return[]}}if(h){const s=this;return new Promise(function(o){Promise.all(h).then(function(i){o(s.search(e,t,n,i))})})}if(!u)return[];if(f&&(!d||!this.store))return c[0];for(let t=0,e;t<m.length;t++){if(e=c[t],e.length&&d&&(e=q.call(this,e)),f)return e;c[t]={field:m[t],result:e}}return c};function te(e,t,n,s){let o=this.l[e],i=o&&o.length-n;if(i&&0<i)return(i>t||n)&&(o=o.slice(n,n+t)),s&&(o=q.call(this,o)),{tag:e,result:o}}function q(e){const t=Array(e.length);for(let n=0,s;n<e.length;n++)s=e[n],t[n]={id:s,doc:this.store[s]};return t}s.contain=function(e){return!!this.register[e]},s.get=function(e){return this.store[e]},s.set=function(e,t){return this.store[e]=t,this},s.searchCache=S,s.export=function(e,t,n,s,o,i){let a;if("undefined"==typeof i&&(a=new Promise(e=>{i=e})),o||(o=0),s||(s=0),s<this.h.length){const n=this.h[s],a=this.index[n];t=this,setTimeout(function(){a.export(e,t,o?n:"",s,o++,i)||(s++,o=1,t.export(e,t,n,s,o,i))})}else{let t,a;switch(o){case 1:t="tag",a=this.l,n=null;break;case 2:t="store",a=this.store,n=null;break;default:i();return}A(e,this,n,t,s,o,a,i)}return a},s.import=function(e,t){if(t)switch(i(t)&&(t=JSON.parse(t)),e){case"tag":this.l=t;break;case"reg":this.m=!1,this.register=t;for(let e=0,n;e<this.h.length;e++)n=this.index[this.h[e]],n.register=t,n.m=!1;break;case"store":this.store=t;break;default:e=e.split(".");const n=e[0];e=e[1],n&&e&&this.index[n].import(e,t)}},T(d.prototype),Y={encode:K,F:!1,G:""};const X=[o("[àáâãäå]"),"a",o("[èéêë]"),"e",o("[ìíîï]"),"i",o("[òóôõöő]"),"o",o("[ùúûüű]"),"u",o("[ýŷÿ]"),"y",o("ñ"),"n",o("[çc]"),"k",o("ß"),"s",o(" & ")," and "];function K(e){var t=e=""+e;return t.normalize&&(t=t.normalize("NFD").replace(J,"")),U.call(this,t.toLowerCase(),!e.normalize&&X)}W={encode:k,F:!1,G:"strict"};const Z=/[^a-z0-9]+/,$={b:"p",v:"f",w:"f",z:"s",x:"s","ß":"s",d:"t",n:"m",c:"k",g:"k",j:"k",q:"k",i:"e",y:"e",u:"o"};function k(e){e=K.call(this,e).join(" ");const t=[];if(e){const n=e.split(Z),s=n.length;for(let i=0,o,a=0;i<s;i++)if((e=n[i])&&(!this.filter||!this.filter[e])){o=e[0];let n=$[o]||o,s=n;for(let i=1;i<e.length;i++){o=e[i];const t=$[o]||o;t&&t!==s&&(n+=t,s=t)}t[a++]=n}}return t}I={encode:H,F:!1,G:""};const ne=[o("ae"),"a",o("oe"),"o",o("sh"),"s",o("th"),"t",o("ph"),"f",o("pf"),"f",o("(?![aeo])h(?![aeo])"),"",o("(?!^[aeo])h(?!^[aeo])"),""];function H(e,t){return e&&(e=k.call(this,e).join(" "),2<e.length&&(e=f(e,ne)),t||(1<e.length&&(e=B(e)),e&&(e=e.split(" ")))),e||[]}L={encode:ae,F:!1,G:""};const se=o("(?!\\b)[aeo]");function ae(e){return e&&(e=H.call(this,e,!0),1<e.length&&(e=e.replace(se,"")),1<e.length&&(e=B(e)),e&&(e=e.split(" "))),e||[]}r["latin:default"]=ie,r["latin:simple"]=Y,r["latin:balance"]=W,r["latin:advanced"]=I,r["latin:extra"]=L;const _={Index:c,Document:d,Worker:l,registerCharset:function(e,t){r[e]=t},registerLanguage:function(e,t){N[e]=t}};let y;(y=t.define)&&y.amd?y([],function(){return _}):t.exports?t.exports=_:t.FlexSearch=_}(this);const search=document.querySelector(".search-input"),suggestions=document.querySelector(".search-suggestions"),background=document.querySelector(".search-background");index=new FlexSearch.Document({tokenize:"forward",cache:100,document:{id:"id",tag:"tag",store:["href","title","description"],index:["title","description","content"]}});function initIndex(){index.add({id:0,tag:"en",href:"/about/",title:"About",description:"About section",content:`JASMIN is the UK&rsquo;s data analysis facility for environmental science, architected and operated by the Science and Technology Facilities Council on behalf of the Natural Environment Research Council.
More information about JASMIN and its aims and user communities can be found on the JASMIN website&nbsp; JASMIN is operated by STFC on behalf of NERC.`}).add({id:1,tag:"en",href:"/docs/about-this-site/",title:"About this site",description:"Information about this documentation site itself.",content:`About this site &nbsp; We hope you like our new-look help docs which make use of richer formatting to make the articles easier to read, particularly those with code snippets or command-line instructions. We&rsquo;ve also changed the way we manage the source content so it&rsquo;s easier for us to maintain. There&rsquo;s still more to do, to re-organise some of the content and add new pages to reflect how JASMIN is evolving. This site should redirect you from any previous URLs you may have stored, but please use the following features to help you navigate around the site:
main navigation bar along the top of the site, including search tool breadcrumbs menu, to show you where you are in the site collapsible sidebar, left side panel (docs pages only) icons, to identify articles within the same section table of contents, right side panel hover over sub-headings to reveal a bookmark-able link to that heading &nbsp; tags to group together articles covering similar topics links between articles Issues with this site &nbsp; If you spot any broken links or incorrect information, please let us know by opening an issue in the GitHub repository for this site&rsquo;s source code:
Report issues with this site&nbsp; &nbsp; &nbsp; The date of update date and commit message for each page should be just above the footer of each page.
Other issues &nbsp; For all other reports of problems, or for any information you can&rsquo;t find (don&rsquo;t forget the other JASMIN sites linked in the footer!), please use the contact form via &ldquo;Ask&rdquo; in the JASMIN Help beacon (bottom right, orange button) and use the contact form to send a message to the helpdesk: this is the best method to get in touch. Note that the beacon no longer contains the links to the help docs themselves, but still provides the contact form. Hopefully the other navigation features described above should enable you to find what you need.`}).add({id:2,tag:"en",href:"/tags/access/",title:"Access",description:"",content:""}).add({id:3,tag:"en",href:"/docs/getting-started/storage/",title:"Access to storage",description:"Access to storage",content:`This article provides information about JASMIN storage. It covers:
IMPORTANT: Please see also Understanding new JASMIN storage which explains more about the different types of storage as of Phase 4 of JASMIN&rsquo;s history.
Home directory &nbsp; Every JASMIN user is allocated a HOME directory located at/home/users/&lt;user_id&gt;. This directory is available across most of the interactive and batch computing resources, including the JASMIN login and transfer servers.
Each home directory has a default quota of 100 GB. Although you can&rsquo;t directly check usage against your quota, you can find out the current size of your home directory as follows (the pdu command is a parallel variant of the du command, designed to work with the particular storage used for home directories on JASMIN).
pdu -sh /home/users/&lt;username&gt; &nbsp; You are only allowed to exceed the 100 GB quota for a very brief period of time. If you continue to exceed the limit, you will be unable to add any more files, which means that jobs may fail, and other things may stop working for you. You will need to reduce your usage below the 100GB quota to resolve this. Backups of your home directory &nbsp; Your home directory is backed up using a daily snapshot which provides a quick, self-service method for you to restore files or directories that have been accidentally deleted. Snapshot backups are kept for 1-2 weeks before being deleted.
Recovering snapshots of your home directory data &nbsp; Users can access snapshots to recover files/directories that have been accidentally deleted. These are stored in /home/users/.snapshot/homeusers.&lt;snapshotid&gt;/&lt;username&gt;
The most recent backup is the one with the highest snapshot id number.
Find the ones relevant to your username with a command line this: ( $USER is the environment variable containing your username, so can be copied in this case)
ls -ld /home/users/.snapshot/homeusers2.*/$USER There should be up to 14 directories like this:
drwx------ 113 joeblogs users 0 Jan 26 15:00 /home/users/.snapshot/homeusers2.2024_01_28_02_01/joebloggs drwx------ 113 joeblogs users 0 Jan 26 15:00 /home/users/.snapshot/homeusers2.2024_01_29_02_01/joebloggs drwx------ 113 joeblogs users 0 Jan 29 09:51 /home/users/.snapshot/homeusers2.2024_01_30_02_01/joebloggs drwx------ 113 joeblogs users 0 Jan 30 09:29 /home/users/.snapshot/homeusers2.2024_01_31_02_01/joebloggs drwx------ 113 joeblogs users 0 Jan 30 09:29 /home/users/.snapshot/homeusers2.2024_02_01_02_01/joebloggsEach of these snapshot directories effectively contains your home directory as it was on that date. You can copy files back from them (yourself) to their original location.
ls -l /home/users/.snapshot/homeusers2.45678/joebloggs/ total 1170964 -rw-r--r-- 1 joebloggs users 104857600 Jun 26 2017 100M.dat -rw-r--r-- 1 joebloggs users 1024000000 Feb 1 2017 1G.dat -rw-r--r-- 1 joebloggs users 0 Dec 18 12:09 6181791.err cp /home/users/.snapshot/homeusers2.45678/joebloggs/100M.dat ~/100M.dat A snapshot backup is also provided for /gws/smf volumes (similar allocations of SSD storage for GWS groups to share): snapshots in this case are made hourly and kept for 10 hours, then daily snapshots are kept for 2 weeks. These can be retrieved in a similar manner to that shown above. In this case the relevant directories should be found at
/gws/smf/jNN/&lt;gwsname&gt;/.snapshot (where NN = 04 or 07 depending on where the volume is located)
&nbsp; All other group workspace volumes are not backed up. The only exception to this is the snapshot backups for smf SSD volumes just described. Please also note the advice on inter-volume symlinks, below: these are to be avoided.
JASMIN disk mounts &nbsp; There is a common file system layout that underpins most of the JASMIN infrastructure. However, access to different parts of the file system will depend on where you are logged in. Table 1 outlines the key disk mounts, where they are accessible from and the type of access (read and/or write).
Table 1. List of common disk mounts, types of storage and their availability on JASMIN
Disk mount
location login sci transfer LOTUS Type Parallel-write /home/users R/W R/W R/W R/W SSD no /gws/pw/j07
/gws/nopw/j04 (see note 1 below)
/gws/smf/j0[4,7] no
no
no R/W
R/W
R/W R/W
R/W
R/W R/W
R/W
R/W PFS
SOF
SSD yes (hence &ldquo;pw&rdquo;)
no (hence &ldquo;nopw&rdquo;)
no /work/xfc/volX (see note 2 below) no
no R/W R/W R/W PFS yes /work/scratch-pw[2,3]
/work/scratch-nopw no
no R/W
R/W R/W
R/W R/W
R/W PFS
SSD yes
no /apps/contrib No RO No RO n/a n/a /badc, /neodc (archives) No RO RO RO n/a n/a login = login servers: login[1-4].jasmin.ac.uk
sci = scientific analysis servers: sci[1-6,8].jasmin.ac.uk
transfer = data transfer servers: xfer[1-2].jasmin.ac.uk
LOTUS = LOTUS batch processing cluster(all cluster nodes)
Disks are mounted read/write (&quot; R/W &ldquo;) or read-only (&rdquo; RO &ldquo;).
Note 1: Please refer to issues related to writing small files and NetCDF3 to SOF storage here
Note 2: For details of how to use the Transfer Cache (XFC) service please see here
Where to write data &nbsp; As indicated in table 1 there are three main disk mounts where data can be written. Please follow these general principles when deciding where to write your data:
HOME directories (/home/users) are relatively small (100GB) and should NOT be used for storing large data volumes or for sharing data with other users. 0 Group Workspaces (mostly /gws/nopw/*/&lt;project&gt; but some /gws/pw/*/&lt;project) are usually the correct place to write your data, although they are not backed up. Please refer to the Group Workspace documentation for details. /gws/pw/j07 volumes are parallel-write-capable storage from Phase 7 (onwards) of JASMIN /gws/nopw/j04 volumes are &ldquo;Scale out Filesystem&rdquo; (SOF) from Phase 4 (onwaards) of JASMIN: this storage is not parallel-write-capable The &ldquo;scratch&rdquo; areas (/work/scratch-pw2, /work/scratch-pw3 and /work/scratch-nopw) are available as a temporary file space for jobs running on LOTUS (see next section below). The (/tmp) directory is not usually an appropriate location to write your data (see next section below). How to use the temporary disk space &nbsp; Scratch &nbsp; The scratch areas /work/scratch-pw2, /work/scratch-pw3 and /work/scratch-nopw are a temporary file space shared across the entire LOTUS cluster and the scientific analysis servers.
These scratch areas are ideal for processes that generate intermediate data files that are consumed by other parts of the processing before being deleted. Please remember that these volumes are resources shared between all users, so consider other users and remember to clean up after your jobs. **** Any data that you wish to keep should be written to a Group Workspace (but remember to change the group-ownership of the data if you do).
There are 2 types of scratch storage available:
PFS scratch (lots of it, fast, less good for small files) as 2 x 1 PB volumes /work/scratch-pw[2,3] and particularly suitable for users with a need for storage capabale of shared-file writes with MPI-IO, but good for most purposes. SSD scratch (less of it, very fast, good for small files) /work/scratch-nopw2 as 1 x 220 TB volume. Do not use for operations that attempt to write to multiple parts of a file simultaneously. Please be aware of this if your code (perhaps inadvertently?) writes to a shared log file. When using the &ldquo;scratch&rdquo; areas, please create a sub-directory (e.g. /work/scratch-????/&lt;username&gt;) labelled with your username and write your data there.
/tmp &nbsp; In contrast to the &ldquo;scratch&rdquo; space, /tmp directories on LOTUS nodes and physical sci machines are all local to the machine. These can be used to store small volumes of temporary data for a job that only needs to be read by the local process. But /tmp on virtual sci machines, are not local and therefore should not usually be used by users.
Cleaning up the scratch and tmp directories &nbsp; Please make sure that your jobs delete any files under the /tmpand scratch directories when they are complete ( especially if jobs have not been completed normally!).
Please do this yourself so that you are not taken by surprise when automated deletion processes clear up any residual data:
&nbsp; Automated cleanup processes run daily and delete files that are older than 28 days from the last time of being accessed. This applies to /work/scratch-pw2, /work/scratch-pw3 and /work/scratch-nopw2
Please remember that shared temporary storage is for the use of all 2,000 users of JASMIN, not just you. If you persistently store large amounts (100s of TB) of data in scratch for long periods of tine, you deny use of that storage to other users (so expect action from the JASMIN team).
Please be a good JASMIN citizen!
Any important data for keeping should be written to a group workspace or to your home directory if appropriate.**
The /work/scratch-pw[2,3] and /work/scratch-nopwareas are not available on the xfer, login or nx-login servers.
Avoid inadvertently writing to /tmp &nbsp; Sometimes software is configured by default to write to /tmp. Where possible, you should over-ride this and use your group workspace or a username-labelled directory within the scratch space instead.
To do this, please add the following lines (or similar) to your $HOME/.bashrc file:
export TMPDIR=/&lt;path-to-your-GWS-or-scratch&gt;/&lt;your_username&gt;/tmp # create the directory if needed [ -d $TMPDIR ] || mkdir -p $TMPDIR&hellip;but please check that location regularly to clear it out!
Access to the CEDA archive &nbsp; The CEDA Archive is mounted read-only under paths refleting the NERC data centres which merged to form CEDA, i.e.
/badc (British Atmospheric Data Centre) /neodc (NERC Earth Observation Data Centre). (other data centre paths now also exist at that level: see CEDA Help docs&nbsp; for more info)
The Archive includes a range of data sets that are provided under varying licences. Access to these groups is managed through standard Unix groups. Information about the data and their access restrictions is available from the CEDA Catalogue&nbsp; .
&nbsp; As a JASMIN user, it is your responsibility to ensure that you have the correct permissions to access data any data in CEDA Archive from within JASMIN, even if file system permissions permit access. Tape access &nbsp; Group workspace managers also have access to a tape library (Elastic Tape service) for making secondary copies and managing storage between online and near-line storage.
Number of files in a single directory &nbsp; It is highly recommended that you do not exceed more than 100,000 files in a single directory on any type of storage on JASMIN. Large numbers of files place unnecessary load on components of the file system and can be the source of slow performance for you and other storage volumes in the system. To count the number of files, please note the advice in slow ls response below, or use an alternative command e.g. find.
Slow &rsquo;ls&rsquo; response &nbsp; This can be due to a number of reasons (see above advice regarding number of files in a single directory, and below regarding inter-volume symlinks). To speed up the response (useful if you want to count the number of files) it often helps to un-alias ls, e.g. by placing a backslash in front of the command: \\ls.
Advice on inter-volume symlinks in JASMIN storage &nbsp; We highly recommend users not to use symbolic links in their home directories to other parts of the JASMIN file systems, such as GWSs or scratch areas. There are a number of conditions when the petabyte-scale JASMIN storage can become unusable for all users due to these links. There is a more technical explanation below. We would advise path substitutions using environment variables instead.
Symlinks in users&rsquo; home directories that point to other volumes (for example group workspaces) make matters worse when there are problems on the sci*.jasmin.ac.uk servers and other shared machines, and/or when the metadata servers responsible for particular storage volumes themselves become overloaded. The simplest advice we can currently give is to avoid using symlinks.
In more detail:
This issue is particularly apparent when ls is aliassed to ls --color (as is the default on 99% of JASMIN systems) AND one of the colorisation options specified is for an orphaned link. The ls on symlinks causes the metadata servers at the end of the symlink to be called (to provided the stat filesystem metadata), in addition to the metadata server for the home directory. If those metadata servers at the far end are under load, or have some other problem, the ls to the home directory can hang, but this also hangs other users who may be trying to ls their own home directory (even if theirs contains no symlinks). The situation can then escalate out of control as more and more users try and fail.
This is happens especially where one or more of the volumes involved contains large numbers of small files.`}).add({id:4,tag:"en",href:"/tags/account/",title:"Account",description:"",content:""}).add({id:5,tag:"en",href:"/docs/uncategorized/acknowledging-jasmin/",title:"Acknowledging  JASMIN",description:"Acknowledging  JASMIN",content:`We strongly encourage users to acknowledge JASMIN in all research outputs that have used the JASMIN facility. The acknowledgement statement should be:
&ldquo;This work used JASMIN, the UK&rsquo;s collaborative data analysis environment (https://www.jasmin.ac.uk)&rdquo;
together with citation to this article:
Lawrence, B. N. , Bennett, V. L., Churchill, J., Juckes, M., Kershaw, P., Pascoe, S., Pepler, S., Pritchard, M. and Stephens, A. (2013) Storing and manipulating environmental big data with JASMIN. In: IEEE Big Data, October 6-9, 2013, San Francisco.`}).add({id:6,tag:"en",href:"/docs/for-cloud-tenants/adding-and-removing-ssh-keys-from-an-external-cloud-vm/",title:"Adding and removing SSH keys from an External Cloud VM",description:"Adding and removing SSH keys from an External Cloud VM",content:`When you create a machine in a JASMIN External Cloud tenancy, the SSH key associated with your JASMIN account is uploaded to the machine to grant you access to the machine as root:
ssh -A root@&lt;external ip&gt; However, this is a one-time operation when the machine is created. Updating your SSH key in the JASMIN Accounts Portal is not reflected in External Cloud VMs. Once initial access has been granted, you as the tenancy admin are responsible for all configuration of the machine, including the SSH keys allowed to access the machine. For example, you may choose to grant access to a user who does not have a JASMIN account by adding their SSH key to the machine.
IMPORTANT: When you change your SSH key in the JASMIN Accounts Portal, you must retain your old private key until you have added your new key to all External Cloud VMs that you administer. Failing to do so will result in you being locked out of those machines.
Adding and removing SSH keys &nbsp; The allowed SSH keys for a user can be found in $HOME/.ssh/authorized_keys for the user. For root, this is /root/.ssh/authorized_keys.
To grant access to a user, they must first generate an SSH key pair. Once they have done this, they should give you their public key. The private key should never leave the user&rsquo;s local machine. Once you have added this public key as a new line to the authorized_keys file for the target user on your External Cloud VM, the user will be able to SSH to the machine.
Similarly, to disable access for a user, just remove their public key from the authorized_keys file on the machine.
IMPORTANT: When replacing an old key with a new one, make sure that you add the new key before removing the old one or you may accidentally lock yourself out of your machine.`}).add({id:7,tag:"en",href:"/docs/software-on-jasmin/additional-software/",title:"Additional software",description:"Additional software packages (under: /apps/jasmin/)",content:`This article provides details of additional packages that exist under the /apps/jasmin/ directory which is available on all scientific analysis servers and on the LOTUS batch cluster on JASMIN.
The /apps/jasmin/ directory has been provided as a home for additional software packages that are not installed within either Jaspy or &ldquo;jasmin-sci&rdquo; environments. This page details which packages are available along with details of how they are managed and accessed.
Community packages under: /apps/jasmin/ &nbsp; Software installed as community packages are provided, and maintained, by developers outside the CEDA/JASMIN Team. If you have queries about using community packages on JASMIN then please contact the JASMIN Helpdesk and we will forward them to the team that supports that specific package on JASMIN.
ESMValTool &nbsp; The Earth System Model Evaluation Tool (ESMValTool) is a community diagnostics and performance metrics tool for the evaluation of Earth System Models (ESMs) that allows for routine comparison of single or multiple models, either against predecessor versions or against observations. See the ESMValTool on JASMIN page for more info.`}).add({id:8,tag:"en",href:"/training/advanced/",title:"Advanced",description:"Training exercises on advanced topics",content:""}).add({id:9,tag:"en",href:"/tags/amd/",title:"Amd",description:"",content:""}).add({id:10,tag:"en",href:"/tags/application/",title:"Application",description:"",content:""}).add({id:11,tag:"en",href:"/docs/short-term-project-storage/apply-for-access-to-a-gws/",title:"Apply for access to a GWS",description:"Apply for access to a GWS",content:`This article explains how to apply for access to a GWS from the JASMIN account portal.
Step 1 : Sign in into your JASMIN accounts portal. Navigate to the JASMIN services tab of the portal then select the group workspaces from &ldquo;Discover services&rdquo; menu. You can search or browse a list of available GWSs. For example here the search for GWS with name containing CEDA, resulted in two GWSs.
Discover services Step 2: Select the GWS you are interested in and provide supporting information. In the following example, the GWS cedaproc was selected.
Select GWS Step 3: Your request to join a GWS is pending for approval
Request pending Step 4 : You will receive a notification of the outcome of your application. For example, the request to join an existing GWS cedaproc was granted and details of this service such as status and expiry date are displayed below
Outcome notification Step 5: Every time a notification is acknowledged the counter is reset or decremented.
Notification count Finally, you can view all the services that you currently have access to or have requested access for under &lsquo;My Services&rsquo;
My services`}).add({id:12,tag:"en",href:"/tags/approvals/",title:"Approvals",description:"",content:""}).add({id:13,tag:"en",href:"/tags/approve/",title:"Approve",description:"",content:""}).add({id:14,tag:"en",href:"/docs/uncategorized/approving-requests-for-access/",title:"Approving requests for access roles",description:"Approving requests for access roles",content:"Managers of JASMIN resources will also be set up to approve applications from members of the JASMIN user community wishing to use particular resources. The following video tutorial explains the approval process using the JASMIN Accounts Portal."}).add({id:15,tag:"en",href:"/tags/arbiter/",title:"Arbiter",description:"",content:""}).add({id:16,tag:"en",href:"/docs/uncategorized/article-under-review/",title:"Article under review",description:"Article under review",content:`The article which you are trying to access has been removed, pending reorganisation of the JASMIN documentation and training materials.
Hopefully you can find what you&rsquo;re looking for in other articles using the search tool or sidebar navigation.`}).add({id:17,tag:"en",href:"/tags/automount/",title:"Automount",description:"",content:""}).add({id:18,tag:"en",href:"/tags/backup/",title:"Backup",description:"",content:""}).add({id:19,tag:"en",href:"/training/basic/",title:"Basic",description:"Training exercises on basic topics",content:""}).add({id:20,tag:"en",href:"/docs/batch-computing/",title:"Batch Computing",description:"How to use the LOTUS (cpu) and ORCHID (gpu) clusters for batch processing",content:""}).add({id:21,tag:"en",href:"/docs/data-transfer/bbcp/",title:"bbcp",description:"Data transfer tool bbcp",content:`This article provides information about the bbcp data transfer tool.
What is bbcp? &nbsp; bbcp is a simple command-line tool which can use your SSH connection to transfer data in and out of JASMIN efficiently. It works in a similar way to GridFTP over SSH in that it connects to the transfer server using your usual SSH credentials but then can set up parallel data streams for transferring data. One advantage of bbcp that it is provided as a single binary executable which is easy to download and use.
Using bbcp on JASMIN &nbsp; Check with your local administrator to see if it is installed centrally on your own system. If it isn&rsquo;t, you may need to download the correct binary from the bbcp download site and simply place it in your path on your local filesystem: this can be done as a regular/unprivileged user. At the JASMIN end, you can put the same executable in your home directory (somewhere in your $PATH e.g. in your ~/bin directory, and make sure you give the file execute permission). Once you have the bbcp command you can access any file which is readable by you when logged into JASMIN, or write to a Group Workspace that you have access to.
Configuring bbcp for JASMIN &nbsp; When contacting hpxfer[12].jasmin.ac.uk you will need to set a couple of important options for it to work. The exact options depend on whether you are moving data into or out of JASMIN, and from where the transfer is initiated.
The bbcp protocol, in common with most high-bandwidth transfer tools, requires a set of ports to be open at one or both ends in order to establish data connections. Due to firewall restrictions this range of ports needs to be agreed in advance. In the case of hpxfer[12].jasmin.ac.uk the range of ports is 50000:51000. Therefore all bbcp commands must contain the option --port 50000:51000.
Also, hpxfer[12] will only allow incoming connections on these ports, therefore hpxfer[12] must be the server which listens for data connections. By default bbcp will listen for data connections at the end receiving data and connect from the end sending data. Therefore, with the default options, bbcp will succeed when pushing data to hpxfer[12] but fail when pulling data from it. In order to pull data, with the transfer initiated on the remote server, you must include the -z flag. Therefore the recommended commands for transferring in either direction are:
Initiate on JASMIN: Pull Data from remote server &nbsp; bbcp -v -4 -P 5 -F --port 50000:51000 username@remote-server:&lt;PATH-TO-SOURCE-FILE&gt; &lt;PATH-TO-TARGET-FILE&gt; Initiate on JASMIN: Push Data &nbsp; bbcp -v -4 -P 5 --port 50000:51000 &lt;PATH-TO-SOURCE-FILE&gt; username@remote-server:&lt;PATH-TO-TARGET-FILE&gt; Initiate on remote server: Pull Data from JASMIN &nbsp; bbcp -v -z -4 -P 5 --port 50000:51000 username@hpxfer1.jasmin.ac.uk:&lt;PATH-TO-SOURCE-FILE&gt; &lt;PATH-TO-TARGET-FILE&gt; Initiate on remote server: Push Data to JASMIN &nbsp; bbcp -v -4 -P 5 -F --port 50000:51000 &lt;PATH-TO-SOURCE-FILE&gt; username@hpxfer1.jasmin.ac.uk:&lt;PATH-TO-TARGET-FILE&gt; In this case the -v flag produces verbose output .-V can be used for even more verbose output. The -4 option forces use of IP version 4 instead of IPv6 (essential for transfers to and from hpxfer1 or other JASMIN hosts. Note: this option may not be available in some older versions of bbcp), and the -P option reports the status of the transfer every n seconds. The default behaviour will print nothing. The -F option skips a check on the target host to check if there is enough disk space. This overcomes occasional problems where free space is not correctly reported to bbcp by the JASMIN file system.
For the full set of options, see: https://www.slac.stanford.edu/~abh/bbcp/
Note: the bbcp command must be in your $PATH on both the source and target machine.
Initiate on JASMIN: Pull Data from remote server, specifying SSH command to start bbcp &nbsp; bbcp -v -4 -P 5 -F --port 50000:51000 -S &#34;/usr/bin/ssh %I -l %U %H /path/to/bbcp&#34; username@remote-server:&lt;PATH-TO-SOURCE-FILE&gt; &lt;PATH-TO-TARGET-FILE&gt; The path /path/to/bbcp can be replaced by module load bbcp; bbcp (or whatever is the appropriate local requirement) in environments where bbcp is a module which needs to be loaded first.
bbcp -v -4 -P 5 -F --port 50000:51000 -S &#34;/usr/bin/ssh %I -l %U %H module load bbcp; bbcp&#34; username@remote-server:&lt;PATH-TO-SOURCE-FILE&gt; &lt;PATH-TO-TARGET-FILE&gt; For specifying the SSH command to start bbcp on the TARGET node, use the -T option.
The bbcp site has good documentation on further options, including the -r option for recursive transfers. A number of useful tutorials are also available elsewhere on the web.
Tuning Recommendations &nbsp; We recommend you tune your connection by trying various different options on a few GBs of data.
By default 4 streams are opened. Try 1 stream first, particularly on fast connections, it may be faster. This is achieved with the option -s 1. We ask users of JASMIN to tune up to a maximum of 16 streams (-s 16). If you believe you need to open more streams please contact the JASMIN Helpdesk. Do not tune the window size unless you continue to get very poor bandwidth after adjusting the number of streams. Most modern operating systems will auto-tune this parameter. bbcp is not ideal for large directory trees of small files. If you have thousands of small files you may be better off with rsync or possibly GridFTP/Globus, depending on the network. Another simpler option is tarring/zipping the data first before transferring. Troubleshooting &nbsp; bbcp uses SSH to establish the control connection so you need to set up your SSH key in the same way as you would to SSH into hpxfer[12].jasmin.ac.uk. If bbcp isn&rsquo;t working you should first check you can SSH to hpxfer[12].jasmin.ac.uk. If you can&rsquo;t, please review the steps in the Getting Started section before contacting the JASMIN Helpdesk. Make that you have logged in (via SSH) to both the JASMIN transfer server and the remote server with the -A option (agent-forwarding enabled), to ensure that your credentials are used by SSH as it invokes bbcp on the other server. Try adding the -Foption to disable bbcp&rsquo;s filesystem checking if you get the following error: bbcp: Insufficient space to copy all the files from &lt;hostname&gt;. If you see the following error message: Address family not supported by protocol creating inet socketthis is most likely because the -4 flag was not specified. This may happen with commands that once worked, as a previously installed version of bbcp on JASMIN defaulted to IPv4. Currently there is no support for IPv6 on JASMIN. If the version of bbcp you have available on your system is old and does not have the -4 option, consider downloading the appropriate (newer) version from the link above. It is also possible to compile the executable from source.`}).add({id:22,tag:"en",href:"/tags/beginner/",title:"Beginner",description:"",content:""}).add({id:23,tag:"en",href:"/docs/getting-started/beginners-training-workshop/",title:"beginners training workshop - materials",description:"Beginners training workshop - materials",content:`The CEDA team regularly run hands-on interactive training workshops for users of JASMIN. The workshop makes use of exercises and tutorials to help users to become familiar with the JASMIN environment.
There are two types of workshop activities; exercises (ex) and tutorials (t). Exercises are interactive task-based activities based on different common scenarios of using JASMIN. Whereas tutorials provide in-depth explanations and demonstrations (but are not interactive). All workshop resources are freely available on GitHub and have supporting videos on YouTube.
Anyone can complete the exercises in their own time with the resources linked, but joining an in-person workshop is a great chance for you to interact with the team, to discuss your research needs, and to provide feedback on the JASMIN service. Details about future workshops will be advertised on the CEDA events page - these are currently being run virtually due to the Covid-19 pandemic.
Most of the exercises are stand-alone and do not necessarily need to be completed in order - however, if you are a new user, then we recommend you follow the exercises in order as it will help to explain the general workflows that you may encounter on JASMIN.
Note: If you are using the materials individually (outside of an organised workshop event) then you will need to use your own JASMIN account and a group workspace which you already belong to, rather than the training accounts, and workshop group workspace, respectively. Instead of the workshop LOTUS queue, please use the test queue in this case.
Overall aims of the workshop: &nbsp; To engage novice to intermediate users in best practice for working on JASMIN via hands-on exercises To increase understanding about: which parts of JASMIN are suited for different tasks software available on JASMIN To provide a face-to-face environment where the JASMIN Team can offer support and feedback on a range of issues/problems To gather feedback on the gaps in current provision of documentation`}).add({id:24,tag:"en",href:"/docs/for-cloud-tenants/best-practice/",title:"Best practice",description:"Best practice",content:`External Cloud Tenancy additional notes
Best practice guides for “server hardening” of Linux machines facing the internet:
https://www.slideshare.net/myowntelco/centos-linux-server-hardening And particularly for web servers:
https://www.slideshare.net/akashm/securing-a-linux-web-server-in-10-steps-or-less Additional notes regarding JASMIN External Cloud environment:
The Shield NAT/Firewall device is the only isolation between Tenant VMs and the raw internet. We monitor network traffic at the gateway/router but Security is the responsibility of the tenant. Please follow suggested security hardening guidelines for all VMs with connections to 192.171.139.0/25 Access to other JASMIN hosts and services from the external cloud, is the same as access from internet to these services. The default CentOS public catalog template is configured to use DNS, NTP and yum repo network services from the internet, not from the RAL site. SMTP (mail) server/relay configuration is the responsibility/choice of the tenant. We recommend tenants choose a hosted email server with virus and SPAM filtering and not attempt to configure their own email pipelines. Reverse DNS (IP to hostname) for 192.171.129.0/25 is managed by NERC DNS servers along with ( shortly ) default forward A name records. Tenants may setup forward A or CNAME DNS records (hostname to IP) for any domainnames they own/control via their own DNS or institutional name servers`}).add({id:25,tag:"en",href:"/tags/best-practice/",title:"Best Practice",description:"",content:""}).add({id:26,tag:"en",href:"/docs/long-term-archive-storage/ceda-archive/",title:"CEDA Archive",description:"CEDA Archive",content:`This article describes accessing the CEDA Archive&nbsp; from JASMIN:
Overview &nbsp; The CEDA Archive provides direct access to thousands of atmospheric, climate change and earth observation datasets. The Archive is directly accessible as a file system from the shared science machines on JASMIN.
It is a separate service run by the CEDA team - it is not a JASMIN service. Therefore, many of the links in this document will take you to the CEDA Archive help documentation site (as the information relates to CEDA Archive services). This is separate from the JASMIN help documentation site (which is specifically about JASMIN services).
Register for a CEDA Account &nbsp; First, you need a CEDA Archive account. If you do not have a CEDA account, please follow the steps in this CEDA help document to register as a new CEDA user. It also explains how you can reset your password if you have forgotten it. When you have made a CEDA account, you will then need to use the CEDA portal to link it to your JASMIN account.
The JASMIN Account Portal deals with the management of access to JASMIN resources (e.g. compute and storage), whereas MyCEDA (the CEDA Accounts Portal) deals with access to CEDA resources (e.g. access to datasets in the archives). You will need both accounts linked in order to access CEDA Archive data from JASMIN - you can check whether your accounts are linked from within the CEDA Accounts Portal.
Accessing the CEDA Archive on JASMIN servers &nbsp; Once you have linked your CEDA and JASMIN accounts, you will have access to large parts of the archive straightaway.
The contents of the CEDA Archive are available on the file system under /badc and /neodc. Note: do not access data via any symlinks that point to /datacentre/archvol* - these are not permanent links and may change when data are migrated to new storage. Please use the archive path names under /badc and /neodc. Search the CEDA data catalogue for further details about data held in the archive.
Note: /badc is for atmospheric &amp; climate model data, /neodc is for earth observation data - they are named after CEDA&rsquo;s previous archive names (British Atmospheric Data Centre, and the NERC Earth Observation Data Centre).
Most data on the Archive is open access - however, some datasets are restricted. You can work this out by looking at the UNIX access groups the data are within (see below). If your required datasets are restricted, access to these can be obtained by applying for specific access via the data centre (see this article for more details). If direct access is not possible the data can be obtained via standard FTP and web-based access methods to the CEDA Archive and transferred to a suitable group workspace on JASMIN. As the data centres use the same JASMIN infrastructure the transfer rates are high.
The CEDA Data Catalogue is a useful tool to find and apply for access to datasets.
Archive access groups &nbsp; The UNIX access groups used within the CEDA Archive are listed below with links to example datasets in the CEDA data catalogue for those wishing to use them:
open Available to any logged in JASMIN user with a linked CEDA user account. See a full list of available datasets here. cmip5_research restricted CMIP3 and CMIP5 datasets esacat1 Satellite data including MERIS, MIPAS and SCIAMACHY. ecmwf Access to the ECMWF Operational Datasets. eurosat Satellite data including IASI, AVHRR-3 and GOME-2. ukmo_wx Met Office observational dataset collections including LIDARNET, MIDAS, MetDB and NIMROD ukmo_clim Climatology datasets from the Met Office, including Central England Temperature dataset collection, HadISST. byacl These data have specific restrictions on them meaning that they can&rsquo;t be accessed directly from JASMIN, but can be obtained via FTP and web access. Data Licensing &nbsp; All use of data accessed directly from the CEDA Archive must be used in line with the relevant data licence in place for the relevant dataset for the purposes stated in the access application. Data licence information can be found on the relevant CEDA Data Catalogue page, a link to which can be found in the 00README_catalogue_and_licence.txt files found in the archive. For specific data licences granted for restricted datasets, users should log into their MyCEDA page to view their granted licence and the associated usage purpose under which access was granted. Any required alternative use of the data beyond the original purpose stated in the original licence application can only be made with a freshly granted new licence application.
Accessing data in the archive &nbsp; In the example below, the logged-in user is listing the contents of the CRU data sets within the BADC archive. These are &ldquo;open&rdquo; so all logged-in users can access them:
ls -l /badc/cru/data total 320 -rw-r----- 1 badc open 396 Feb 18 2015 00README drwxr-x--- 8 badc open 4096 Mar 22 10:32 cru_cy drwxr-x--- 4 badc open 4096 Dec 6 2014 crutem drwxr-x--- 12 badc open 4096 May 9 14:11 cru_ts drwxr-x--- 3 badc open 4096 Feb 18 2015 PDSI The CEDA Archive Data Browser&nbsp; is a good place to start as it gives a web-based view of the data with additional metadata but enables copying &amp; pasting the directory path for use within the JASMIN environment:
ceda archive data browser`}).add({id:27,tag:"en",href:"/tags/centos7/",title:"Centos7",description:"",content:""}).add({id:28,tag:"en",href:"/docs/interactive-computing/check-network-details/",title:"Check network details",description:"Check network details",content:`This article explains how to:
check that your network domain is able to access JASMIN resources check that the particular host from which you are intending to connect to JASMIN has the required network configuration Check network domain (non .ac.uk users) &nbsp; In order to maintain a secure and reliable scientific infrastructure for its users, JASMIN restricts login access by maintaining an &ldquo;allow list&rdquo; of network domains that are allowed to make SSH connections to the JASMIN login gateways and data transfer servers.
All .ac.uk network domains (i.e. UK universities and &ldquo;academic&rdquo; institutions) are already registered.
If your institution&rsquo;s network domain is not .ac.uk, please request for it to be added to the allow list by contacting the JASMIN Helpdesk, after reading the information in the following section about forward and reverse DNS lookup.
Check IP address resolves to network domain (all users) &nbsp; In addition to being on the allowed IP list there is an additional requirement that the address of your local computer must have forward and reverse DNS lookup enabled. This means that the hostname must resolve to an IP address, and the IP address must resolve to the fully-qualified hostname.
One easy way to do this is to access the following URL from the machine which will be used to make the SSH connection to JASMIN :
https://accounts.jasmin.ac.uk/services/reverse_dns_check/
If you don&rsquo;t have a web browser on that machine, you can use the &lsquo;curl&rsquo; or &lsquo;wget&rsquo; Linux commands to make an HTTP request to that URL, and inspect the output. A successful response will look like this:
External IP address: 130.246.123.456 Resolved to host: vpn-3-167.rl.ac.ukWhereas an unsuccessful response will look like this:
External IP address: 130.246.123.456 Reverse DNS lookup failedIf your IP address does not resolve, please contact your local IT technical support desk and show them this article to help explain the context.
It is important that the network domain to which the IP address resolves is part of the network domain which has been allowed. If there is no obvious relationship between the network domain of the host and that of your institution (derived from your email address), you may be asked to provide additional justification or your connection may be denied. Some institutions prefer not to provide public DNS listings: in this case please ask the technical support representative to contact the JASMIN helpdesk on your behalf to see if a technical solution can be found.
This can be a problem if you attempt to connect directly from a commercial home or business internet service provider. Wherever possible, please connect to your institution (which is likely to be on the allow list already) before making an outgoing SSH connection to a JASMIN server.
As long as the IP address resolves to a fully-qualified hostname within the allowed domain, it does not matter whether the host has a static or dynamically-assigned (DHCP) IP address.
If you cannot obtain an IP address that resolves in this way, you may still be able to access (only) login2.jasmin.ac.uk, which has been configured to enable access without the reverse DNS restriction. However, this is likely to be the only entry point available to you and will limit what you can do on JASMIN. Doing so can be useful as a temporary solution, but to gain full use of JASMIN you will need to have an IP address that resolves to the domain of your institution. For access to graphical desktops, equivalent servers nx- login2.jasmin.ac.uk and nx-login3.jasmin.ac.uk have been provided and for transfer tasks, an additional transfer server xfer3.jasmin.ac.uk is available. See login servers and transfer servers, but note the additional access role required in the case of the transfer server.`}).add({id:29,tag:"en",href:"/tags/cloud/",title:"Cloud",description:"",content:""}).add({id:30,tag:"en",href:"/docs/for-cloud-tenants/cluster-as-a-service/",title:"Cluster-as-a-Service",description:"Cluster-as-a-Service",content:`Introduction &nbsp; JASMIN Cluster-as-a-Service (CaaS) is a service on the JASMIN Cloud that aims to make it easy to provision and maintain clusters of various types by providing a simple, intuitive interface via the JASMIN Cloud Portal.
CaaS is only available in the External Cloud, and machines provisioned by the CaaS system are subject to the usual constraints:
Root access &nbsp; The provisioning user gets root access to the hosts. Clusters can be customised, for example to add new packages. But be careful not to break the configuration of the clustering software! Note: If a tenants makes a change which breaks the cluster patching, the cluster will have to be rebuilt. Patching &nbsp; Users are responsible for applying patches. However, patching a cluster is a simple task triggered in the JASMIN Cloud Portal. Cluster admins to decide when to trigger a patch. Access to CEDA archive and JASMIN Group Workspaces &nbsp; No POSIX access to the CEDA archive or JASMIN Group Workspaces. Read-only access via HTTP/OPeNDAP is possible. Read-write access to the JASMIN Object Store is also possible. The CaaS system has cluster types that provide shared storage between clusters. User management &nbsp; Tenancies must manage their own users/groups. Users of services in a tenancy do not need a JASMIN account. However a JASMIN account is required to use the JASMIN Cloud Portal. Encourages a structure where admins provision and maintain clusters on behalf of their users. The CaaS system has an Identity Manager which provides identity services for a tenancy, i.e. users have a single identity across all clusters within in a single tenancy. However this identity is not linked to a JASMIN account. Available cluster types &nbsp; Cluster type Details Identity Manager Manages identity and permissions for other clusters using a combination of FreeIPA and Keycloak. NFS Shared storage for other clusters using a simple NFS server. Kubernetes A Kubernetes cluster deployed using Rancher Kubernetes Engine. Pangeo The Pangeo stack deployed on Kubernetes. Slurm (currently disabled) A batch cluster running the Slurm workload manager. Creating a cluster &nbsp; Clusters are created via the JASMIN Cloud Portal using a new Clusters tab alongside Overview , Machines , and Volumes. If you do not see this tab, then clusters are not enabled for your tenancy.
Select clusters tab if available Click on the tab and you will see a list of your existing clusters. To create a new cluster, click on the New cluster button - this will launch a dialogue where you can select a cluster type:
Select a cluster type Clicking on a cluster type will show a form collecting parameters for the cluster, which will be different for each cluster type (the options for each cluster type are discussed in more detail in other articles):
Specify parameters for new cluster Click Create cluster to start the cluster creation. The cluster may take several minutes to configure (especially as the initial configuration includes a full patch of operating system packages):
Create the cluster Once configuration is complete, the cluster status will become READY. The cluster is then ready to use:
Cluster in READY status More details of how to use each cluster type are given in other help articles on this site, linked in the table of available cluster types above.
Visit the Machines tab to see the machines that were created as part of the cluster:
List machines created as part of the cluster Updating a cluster &nbsp; Some cluster options, such the number of workers in a Kubernetes cluster, can be updated after a cluster has been created. To do this, select Update cluster options from the Actions&hellip; dropdown for the cluster:
Select update cluster options This will launch a dialogue similar to the one for creating a cluster, except some of the options will be greyed out as they cannot be changed:
Next dialogue After updating the options, click Update cluster to re-configure the cluster. As with cluster creation the cluster status will change to CONFIGURING , becoming READY once the re-configuration is complete. Where possible, the CaaS system makes an effort to re-configure the cluster with as little downtime as possible.
Patching a cluster &nbsp; &ldquo;Patching&rdquo; refers to the specific operation of updating the operating system packages on a machine. It is expected that tenants in the External Cloud will ensure that their machines are regularly patched as a security measure, as package updates often contain fixes for known vulnerabilities that can be exploited if left unpatched.
The CaaS system makes patching clusters easy - just select Patch cluster from the Actions&hellip; dropdown for the cluster and confirm the operation in the dialogue that appears:
Select patch cluster Patch cluster - confirmation As with creating and updating, the cluster status will first become CONFIGURING , becoming READY once the patching is complete. Where possible, the CaaS system will patch the cluster with as little downtime as possible.
Clusters that have not been patched recently will be flagged in the Cloud Portal:
Unpatched clusters Deleting a cluster &nbsp; To delete a cluster, just select Delete from the Actions&hellip; dropdown for the cluster and confirm the operation in the dialogue that appears:
Select delete cluster Delete confirmation The cluster status will become DELETING :
Deleting This will delete the machines associated with the cluster. Once the machines have been deleted, the cluster will be removed. A deleted cluster cannot be restored.`}).add({id:31,tag:"en",href:"/docs/for-cloud-tenants/cluster-as-a-service-identity-manager/",title:"Cluster-as-a-Service - Identity Manager",description:"Cluster-as-a-Service - Identity Manager",content:`This article describes how to deploy and use the JASMIN Cluster-as-a-Service (CaaS) Identity Manager.
Introduction &nbsp; The Identity Manager consists of a FreeIPA server, a Keycloak server and a gateway/proxy server that work together to provide a single identity across all cluster types, whether via a web-browser, SSH or custom CLI tools like kubectl.
FreeIPA is an open-source identity management system specifically designed to manage Linux hosts and the user accounts on those hosts. To do this, It integrates LDAP, Kerberos, NTP, DNS and a certificate authority into a single unit that is easy to install and configure.
Keycloak is an open-source product that provides single sign-on (SSO) using OpenID Connect and SAML, primarily aimed at web-based services.
FreeIPA and Keycloak are powerful systems, and a full discussion of their capabilities is beyond the scope of this article. This article focuses on their use within the CaaS system, and will be sufficient for the vast majority of users. Any usage that deviates from that described in the JASMIN CaaS documentation is not explicitly supported, should something go wrong.
All hosts deployed using CaaS are registered with the FreeIPA instance for your tenancy, and FreeIPA provides DNS, user/group management and access control policies for those hosts. FreeIPA is also the single source of truth for users and groups on your clusters. It is not possible to link with other accounts, including JASMIN accounts. Keycloak is used to provide OpenID Connect support for web applications, and for Kubernetes authentication. Although Keycloak can manage its own users and groups, in the Identity Manager setup it consumes the users and groups from FreeIPA via the LDAP integration in order to provide a single user account across all clusters.
The web interfaces for FreeIPA and Keycloak are exposed through a single gateway/proxy host. This host is also configured to allow SSH access for all active users, which means it can be used with SSH agent forwarding as a jump host for SSH access to clusters without an external IP (similar to the way that the MISSING LINK work.)
The Identity Manager does not have self-service user registration or password reset - these operations must be performed by an admin on behalf of the user.
Cluster configuration &nbsp; The following variables are available when creating an Identity Manager:
Variable Description Required? Can be updated? External IP The external IP that will be attached to the gateway host. This is the the IP that can be used as a jump host for SSH access. Yes No Admin password The password for the admin account. When the Identity Manager is created, this is the only user that exists. Please make sure you choose a secure password. WARNING: This password cannot be changed. Changing the admin password in the FreeIPA web interface will break cluster configuration for all clusters. Yes No Admin IP ranges One or more IP ranges from which admins will access the FreeIPA and Keycloak web interfaces, in CIDR notation. Any attempt to access the admin interfaces froman IP address that is not in these ranges will be blocked. FreeIPA and Keycloak allow the creation and modification of users and permissions for all your clusters, so it is recommended that this range be as small as possible. If you are not sure what value to use here, contact your local network administrator to find out the appropriate value for your network. Yes Yes FreeIPA size The machine size to use for the FreeIPA server. Yes No Keycloak size The machine size to use for the Keycloak server. Yes No Gateway size The machine size to use for the gateway server. Yes No Gateway domain The domain to use for the gateway server.
If left empty, &lt;dashed-gateway-ip&gt;.sslip.io is used (this uses the sslip.io service). For example, if the selected gateway IP is 192.171.139.83, the domain will be 192-171-139-83.sslip.io.
If given, the domain must already be configured to point to the External IP , otherwise configuration will fail. Only use this option if you have control over your own DNS entries - the CaaS system will not create a DNS entry for you. No No Once configuration is complete, the FreeIPA web interface will be available at https://&lt;gateway domain&gt;. You should be able to authenticate with the username admin and the password that was given at deployment time:
FreeIPA web interface The Keycloak web interface is available at https://&lt;gateway domain&gt;/auth/. You should be able to authenticate with the same username and password as FreeIPA.
Keycloak web interface Managing users &nbsp; The users of your clusters are not related in any way to JASMIN users - in fact, there is no requirement that the users of your clusters have a JASMIN account. The pattern we encourage is that one or more admins with JASMIN accounts and access to the JASMIN Cloud Portal deploy and maintain clusters on behalf of their users. Those admins can then create user accounts and grant access to clusters for their own users without those users even needing to be aware of JASMIN.
Creating a user &nbsp; To add a new user, first log in to the FreeIPA interface. Do not add users via the Keycloak interface. You will be taken to the users panel, where you click the Add button:
FreeIPA interface: adding a new user This will pop up a dialogue for you to populate some basic information about the user. The User login , First name , Last name and New/Verify password fields are the ones that need to be populated. Pick a strong password for the user - they can change this later via the FreeIPA interface if they wish:
User information dialogue Click Add to create the user. You must then securely distribute this password to the user - if possible, write it down and give it to them in person, otherwise use an encrypted email.
The first time they log in, they will be asked to set a new password. Make sure they do this as soon as possible:
Update password dialogue The newly added user cannot do anything except view the users and modify some of their own information. They can see, but not edit, their group memberships.
View of user info Adding an SSH public key &nbsp; Adding an SSH public key can be done either by the user themselves or by an admin. First, navigate to the details page for the user. In the Account Settings section, there is an item called SSH public keys. Click the Add button next to it:
Adding an SSH key (1) This will open a dialogue where the SSH public key can be entered:
Adding an SSH key (2) After clicking Set , the user interface will show New: key set under the SSH public keys item. However, the key is not preserved until the user is saved by clicking the Save button:
Adding an SSH key (3) Once saved, the content of the SSH public keys item will change to a fingerprint, which means the key was saved correctly. The key can be updated or deleted at any point in the future if the associated private key is compromised or lost:
Changing a user&rsquo;s password &nbsp; FreeIPA has no facility for self-service password reset, however users can change their own password or an admin can reset it on their behalf. The procedure is the same in both cases, except that when changing their own password the user is required to provide their current password as well as the new one.
To change a user&rsquo;s password, first navigate to the user details page then select Reset password from the Actions dropdown:
Reset password (1)) This will open a dialogue where a new password can be entered. An admin changing the password on behalf of another user will only see the New/Verify Password fields:
Reset password (2) A user resetting their own password will also see Current Password and OTP fields. The current password must be provided. OTP can be ignored.
User resetting own password After clicking Reset Password , the password is changed.
If a user&rsquo;s password is reset by an admin, the user will be asked to change their password the first time they log in, like when a new user is created.
Deleting a user &nbsp; To delete a user, navigate to the Identity &gt; Users &gt; Active users page. On this page, check the box next the user you want to disable, then click the Delete button:
Deleting a user (1) In the confirmation dialogue that pops up, make sure to select preserve as the Delete mode - it is not recommended to permanently delete users:
Deleting a user (2) Upon clicking the Delete button, the user will be moved to the Preserved users section:
Deleting a user (3) They will no longer show up as a user on any CaaS hosts or in Keycloak. They can be easily restored by selecting the user and clicking the Restore button.
Managing groups &nbsp; When you deploy a cluster through CaaS, it may create one or more access control groups in FreeIPA as part of it&rsquo;s configuration. Some clusters can also consume additional groups created in FreeIPA. This is discussed in more detail in the documentation for each cluster type, but the way you manage group membership is the same in all cases.
Creating a new group &nbsp; To create a new group, navigate to the Identity &gt; Groups &gt; User groups section and click the Add button:
Creating a new group (1) In the resulting dialogue, set the Group name and, if you wish, a Description (recommended!). The Group Type can be left as POSIX , even if the group is only to be used for OpenID Connect. By leaving GID empty, a free GID will be allocated:
Creating a new group (2) After clicking the Add button, the new group will be available for adding users.
Adding and removing users &nbsp; First, navigate to the Identity &gt; Groups &gt; User groups section:
Adding/removing users (1) Click on the group that you want to add/remove users for to get to the details page for that group. To add users, click the Add button:
Adding/removing users (2) In the dialogue that pops up, select the users you want to add and click the &gt; button to move them from Available to Prospective :
Adding/removing users (3) Adding/removing users (4) Click Add to add the users to the group.
To remove users from a group, select them in the user list for the group and click Delete :
Adding/removing users (5) Upon confirmation, the users will be removed from the group.
The admins group &nbsp; There is one special group that is created in FreeIPA by default, called admins. This group is respected by all cluster types and members are granted permissions across all clusters deployed using CaaS, including (but not limited to):
Full admin access to the FreeIPA and Keycloak web interfaces SSH access to all hosts deployed using CaaS cluster-admin access to all Kubernetes clusters Access to all Pangeo clusters Managing OpenID Connect clients &nbsp; For an application to use OpenID Connect to authenticate users, it must first be registered as a client with Keycloak. Clients are issued with an ID and secret so that Keycloak knows which application is making an authorisation request.
To manage your OpenID Connect clients, go to Keycloak at https://&lt;gateway domain&gt;/auth/ and click Administration Console. Upon signing in with valid admin credentials (see The admins group above) you will be redirected to the Keycloak admin console. Click on Clients in the menu to see the list of clients:
Keycloak admin console Keycloak itself uses OpenID Connect to handle authentication for its web and command-line interfaces, so there are several clients related to Keycloak operations. CaaS will also automatically create new OpenID Connect clients for clusters that need them - most notably Kubernetes clusters - in which case the client will be named after the cluster. The client with Client ID kubernetes in the list above is an example of a client created by CaaS.
In order to configure an OpenID Connect client to talk to Keycloak, you also need the client secret. To find out the secret for a client, click on the client and then click on the Credentials tab:
Keycloak: credentials tab The client secret is then shown in a disabled text box, where it can be copied from:
Keycloak: client secret`}).add({id:32,tag:"en",href:"/docs/for-cloud-tenants/cluster-as-a-service-kubernetes/",title:"Cluster-as-a-service - Kubernetes",description:"Cluster-as-a-service - Kubernetes",content:`This article describes how to deploy and use a Kubernetes cluster using JASMIN Cluster-as-a-Service (CaaS).
Introduction &nbsp; Kubernetes is an open-source system for automating the deployment, scaling and management of containerised applications.
Kubernetes is an extremely powerful system, and a full discussion of it&rsquo;s capabilities is beyond the scope of this article - please refer to the Kubernetes documentation. This article assumes some knowledge of Kubernetes terminology and focuses on things that are specific to the way Kubernetes is deployed by CaaS.
In CaaS, Kubernetes is deployed in a single-master configuration using Rancher Kubernetes Engine (RKE). This configuration was chosen so that a single external IP can be used for SSH access to the cluster and for ingress - external IPs are a scarce resource in the JASMIN Cloud and the number available to each tenancy is limited. It is for this reason that load-balancer services are also not available. Highly-available (HA) configurations may be available in the future.
All externally-exposed services, including the Kubernetes API, are authenticated using the Identity Manager, meaning that FreeIPA groups can be used to control access to the cluster.
The following services are also configured by CaaS (described in more detail later):
The Nginx Ingress Controller The Openstack Cloud Provider (Block Storage and Metadata only) Jetstack&rsquo;s cert-manager The Kubernetes dashboard Cluster configuration &nbsp; The following variables are available when creating a Kubernetes cluster:
Variable Description Required? Can be updated? Identity manager The CaaS Identity Manager that is used to control access to the cluster. Yes No Version The Kubernetes version to use. The available versions are determined by the RKE version used by the CaaS configuration. This can be changed after initial deployment to upgrade a cluster to a newer Kubernetes version. Before doing this, you should back up your cluster - in particular, you should take a snapshot of the etcd database and make sure any data in persistent volumes is backed up. Yes Yes Worker nodes The number of worker nodes in the cluster. This can be scaled up or down after deployment. When scaling down, there is currently no effort made to drain the hosts in order to remove them gracefully: we rely on Kubernetes to reschedule terminated pods. This may change in the future. Yes Yes Master size The size to use for the master node. The master node is configured to be unschedulable, so no user workloads will run on it (just system workloads). Yes No Worker size The size to use for worker nodes. Consider the workloads that you want to run and pick the size accordingly. The capacity of the cluster can be increased by adding more workers, but the size of each worker cannot be changed after the first deployment. Yes No Root volume size The size of the root volume of cluster nodes, in GB. This volume must be sufficiently large to hold the operating system (~3GB), all the Docker images used by your containers (which can be multiple GBs in size) and all the logs and ephemeral storage for your containers. For reference, Google Kubernetes Engine (GKE) deploys hosts with 100GB root disks by default. At least 40GB is recommended. Yes No External IP The external IP that will be attached to the master node. This IP is where the Kubernetes API will be exposed, and can be used for SSH access to the nodes. Yes No Admin IP ranges One or more IP ranges from which admins will access the Kubernetes API and dashboard (if enabled), in CIDR notation. Any attempt to access the API or dashboard from an IP address that is not in these ranges will be blocked. Access to the Kubernetes API may allow the creation of resources in your cluster, so it is recommended that this range be as small as possible. If you are not sure what value to use here, contact your local network administrator to find out the appropriate value for your network. Yes Yes Kubernetes dashboard Indicates whether to deploy the Kubernetes dashboard. If selected, the Kubernetes dashboard will be available at the configured domain (see below). Yes Yes Dashboard domain The domain to use for the Kubernetes dashboard. If left empty, dashboard.&lt;dashed-external-ip&gt;.sslip.io is used. For example, if the selected external IP is 192.171.139.83, the domain will be dashboard.192-171-139-83.sslip.io. If given, the domain must already be configured to point to the selected External IP , otherwise configuration will fail. Only use this option if you have control over your own DNS entries - the CaaS system or Kubernetes will not create a DNS entry for you. No No Accessing the cluster &nbsp; Kubernetes is configured to use the OpenID Connect support of the Identity Manager for authentication and authorisation. This means that all interactions with the cluster are authenticated and authorised against the users in FreeIPA, via the Keycloak integration.
Using the dashboard &nbsp; If the option to deploy the dashboard was selected, the Kubernetes dashboard will be available at https://&lt;dashboard domain&gt;. Upon visiting the dashboard, you will be redirected to Keycloak to sign in:
Keycloak sign-in screen Any user that exists in your FreeIPA database is able to log in to the dashboard, but only those with permissions assigned for the cluster will be able to see or do anything. Here is an example of what a user with no permissions will see:
View for user with no permissions And here is an example of what a user with full admin rights will see (see Using Kubernetes RBAC below):
View for user with full admin rights Using kubectl &nbsp; This section assumes that you have kubectl, the Kubernetes command-line client, installed on your workstation. In order to authenticate with Keycloak, you must also install the kubelogin plugin, which provides OpenID Connect authentication for kubectl.
In order to configure OpenID Connect, you need to know the client ID and secret of the OpenID Connect client for your Kubernetes cluster in Keycloak. If you are an admin, you can find this information in the Keycloak admin console - the client will be named after the cluster. If you are not an admin, your admin should provide you with this information.
Use the following commands to configure kubectl to connect to your Kubernetes cluster using your Identity Manager, replacing the variables with the correct values for your clusters:
# Put the configuration in its own file export KUBECONFIG=./kubeconfig # Configure the cluster information kubectl config set-cluster kubernetes \\ --server https://$KUBERNETES_EXTERNAL_IP:6443 \\ --insecure-skip-tls-verify=true Cluster &#34;kubernetes&#34; set. # Configure the OpenID Connect authentication kubectl config set-credentials oidc \\ --auth-provider=oidc \\ --auth-provider-arg=idp-issuer-url=https://$ID_GATEWAY_DOMAIN/auth/realms/master \\ --auth-provider-arg=client-id=$CLIENT_ID \\ --auth-provider-arg=client-secret=$CLIENT_SECRET User &#34;oidc&#34; set. # Configure the context and set it to be the current context kubectl config set-context oidc@kubernetes --cluster kubernetes --user oidc Context &#34;oidc@kubernetes&#34; created. kubectl config use-context oidc@kubernetes Switched to context &#34;oidc@kubernetes&#34;. Once kubectl is configured, use the oidc-login plugin to authenticate with Keycloak and obtain an ID token. Running this command launches a temporary lightweight web server on your workstation that performs the authentication flow with Keycloak. A browser window will open where you enter your username and password:
kubectl oidc-login Open http://localhost:8000 for authentication You got a valid token until 2019-07-11 21:58:06 +0100 BST Updated ./kubeconfig You can now use kubectl to query the Kubernetes resources to which you have been granted access:
kubectl get nodes NAME STATUS ROLES AGE VERSION kubernetes-master-0 Ready controlplane,etcd 12h v1.13.5 kubernetes-worker-0 Ready worker 12h v1.13.5 kubernetes-worker-1 Ready worker 12h v1.13.5 kubernetes-worker-2 Ready worker 12h v1.13.5 Using Kubernetes RBAC &nbsp; Kubernetes includes a powerful Role-Based Access Control (RBAC) system. A full discussion of the RBAC system is beyond the scope of this documentation, but this section gives some examples of how RBAC in Kubernetes can be used in combination with FreeIPA groups to allow fine-grained access to the cluster.
For every Kubernetes cluster that is deployed, CaaS automatically creates a group in FreeIPA called &lt;clustername&gt;_users. This group, along with the admins group, are assigned the cluster-admin role using a ClusterRoleBinding, which grants super-user access to the entire cluster. In order to grant a user super-user access to the cluster, they just need to be added to one of these groups (depending on whether you want them to be a super-user on other clusters as well).
It is also possible to create additional groups in FreeIPA and attach more restrictive permissions to them.
Example 1: Read-only cluster access &nbsp; For example, suppose you have some auditors who require read-only access to the entire cluster in order to know what workloads are running. The first thing to do is create a group in FreeIPA - in this case, you might create a group called kubernetes_auditors. Once the group is created, you can reference it in Kubernetes by using the prefix oidc: - in this case the group would be referenced in Kubernetes as oidc:kubernetes_auditors. To grant read-only access to this group for the entire cluster, create a ClusterRoleBinding linking that group to the built-in view role:
apiVersion: rbac.authorization.k8s.io/v1 kind: ClusterRoleBinding metadata: name: kubernetes-auditors-read roleRef: apiGroup: rbac.authorization.k8s.io kind: ClusterRole name: view subjects: - apiGroup: rbac.authorization.k8s.io kind: Group name: oidc:kubernetes_auditors Example 2: Read-write namespace access &nbsp; As another example, suppose you have some developers who want to deploy their app in your cluster, and you want to grant them read-write access to a single namespace to do this. Again, the first thing you would do is create a group in FreeIPA called, for example, myapp_developers. You can then assign this group the built-in edit role, but this time use a RoleBinding that is tied to a particular namespace:
apiVersion: rbac.authorization.k8s.io/v1 kind: RoleBinding metadata: name: myapp-developers-edit namespace: myapp roleRef: apiGroup: rbac.authorization.k8s.io kind: ClusterRole name: edit subjects: - apiGroup: rbac.authorization.k8s.io kind: Group name: oidc:myapp_developers Using the cluster &nbsp; It is beyond the scope of this documentation to discuss how to use Kubernetes: please refer to the Kubernetes documentation for that. This section describes some things about the way Kubernetes is deployed by CaaS that will make a difference to how your applications are deployed.
Ingress &nbsp; In CaaS Kubernetes, Ingress resources are handled by the Nginx Ingress Controller, which is exposed at the external IP used by the master node. The Ingress Controller supports a wide range of Ingress annotations that can be used to customise the behaviour for particular services - visit the documentation for more details.
In order to expose a service using an Ingress resource, each host given in the resource specification must have a DNS entry that points to the external IP of the master node (where the Ingress Controller is listening). CaaS or Kubernetes will not create these DNS records for you, and it is not possible to use an IP address as a host. If you cannot create or edit DNS records, you can use xip.io (or similar services) - these are &ldquo;magic domains&rdquo; that provide DNS resolution for any IP address using domains of the form [subdomain.]&lt;ip&gt;.xip.io.
TLS with cert-manager &nbsp; CaaS Kubernetes deployments also include Jetstack&rsquo;s cert- manager, which provides Kubernetes- native resources for obtaining and renewing SSL certificates - visit the documentation for more information. CaaS installs a ClusterIssuer called letsencrypt that can automatically fetch and renew browser-trusted SSL certificates from Let&rsquo;s Encrypt using ACME. By using annotations, certificates can be fetched automatically for Ingress resources:
apiVersion: extensions/v1 kind: Ingress metadata: name: myapp annotations: kubernetes.io/ingress.class: &#34;nginx&#34; cert-manager.io/cluster-issuer: &#34;letsencrypt&#34; spec: tls: - hosts: - example.example.com secretName: myapp-tls # This secret will be created by cert-manager rules: - host: example.example.com http: paths: - path: / pathType: prefix backend: service name: myapp port: number: 8080 Storage &nbsp; CaaS Kubernetes is also configured to take advantage of the fact that it is running on Openstack. In particular, a storage class is installed that can dynamically provision Cinder volumes in response to [persistent volume claims](https://kubernetes.io/docs/concepts/storage/persistent- volumes/#persistentvolumeclaims) being created. This storage class is called csi-cinder-sc-delete, and is consumed like this:
apiVersion: v1 kind: PersistentVolumeClaim metadata: name: myclaim spec: storageClassName: csi-cinder-sc-delete accessModes: - ReadWriteOnce resources: requests: storage: 10GiIf there is enough quota available, this persistent volume claim should result in a new Cinder volume being provisioned and bound to the claim. The Cinder volume will show up in the Volumes tab of the JASMIN Cloud Portal with a name of the form kubernetes-dynamic-pvc-&lt;uuid&gt;.`}).add({id:33,tag:"en",href:"/docs/for-cloud-tenants/cluster-as-a-service-pangeo/",title:"Cluster-as-a-Service - Pangeo",description:"Cluster-as-a-Service - Pangeo",content:`This article describes how to deploy and use a Pangeo cluster using JASMIN Cluster-as-a-Service (CaaS).
Introduction &nbsp; Pangeo is a community that promotes a philosophy of open, scalable and reproducible science, focusing primarily on the geosciences. As part of that effort, the Pangeo community provides a curated Python ecosystem based on popular open-source packages like xarray, Iris, Dask and Jupyter notebooks, along with documentation and recipes for deployment on various infrastructures.
The Pangeo cluster type in CaaS is a multi-user implementation of the Pangeo ecosystem using JupyterHub deployed on Kubernetes, giving users a scalable and fault- tolerant infrastructure to use for doing science, all through a web-browser interface. Authentication is handled by the Identity Manager for the tenancy via JupyterHub&rsquo;s LDAP integration. Each authenticated user gets their own Jupyter notebook environment running in its own container, isolated from other users. The automatic spawning of containers for authenticated users is handled by JupyterHub, which also provides an interface for admins to manage the running containers. This is achieved by using the Pangeo Helm chart to deploy the Pangeo ecosystem on a CaaS Kubernetes cluster.
Cluster configuration &nbsp; The Pangeo ecosystem is deployed on top of CaaS Kubernetes, so all the configuration variables for Kubernetes also apply to Pangeo clusters.
In addition, the following variables are available to configure the Pangeo installation:
Variable Description Required? Can be updated? Notebook CPUs The number of CPUs to allocate to each user notebook environment. Yes Yes Notebook RAM The amount of RAM, in GB, to allocate to each user notebook environment. Yes Yes Notebook storage The amount of persistent storage, in GB, to allocate to each user notebook environment. This is where users will store their notebooks and any other files they import. The storage is persistent across notebook restarts - a user can shut down their notebook server and start a new server later without losing their data. Backups are not provided - if required, they are the responsibility of the user or cluster admins. Yes Yes Pangeo domain The domain to use for the Pangeo notebook web interface.
If left empty, pangeo.&lt;dashed-external-ip&gt;.sslip.io is used. For example, if the selected external IP is 192.171.139.83, the domain will be pangeo.192-171-139-83.sslip.io.
If given, the domain must already be configured to point to the selected External IP (see Kubernetes configuration), otherwise configuration will fail. Only use this option if you have control over your own DNS entries - the CaaS system or Kubernetes will not create a DNS entry for you. No No These variables define the amount of resource available to each user for processing - in order to appropriately configure (a) the size of your cluster worker nodes and (b) the resources for each notebook environment, you will need to consider how many users you are expecting and what workloads they might want to run.
Accessing the cluster &nbsp; Access to the underlying Kubernetes cluster is achieved in the same way as any other CaaS Kubernetes cluster.
The Pangeo web interface will be available at https://&lt;pangeo domain&gt;. Access to the Pangeo interface is managed through FreeIPA, and users sign in with the same username and password as for other clusters. As part of the cluster configuration, CaaS will create a FreeIPA group called &lt;clustername&gt;_notebook_users. Granting access to the Pangeo interface is as simple as adding a user to this group.
Before adding user to group:
Adding user to group: before And after:
Adding user to group: after Using the Pangeo environment &nbsp; A full discussion of the capabilities of Jupyter notebooks, the JupyterLab environment and the many libraries included in the Pangeo ecosystem is beyond the scope of this documentation. There are plenty of examples on the web, and Pangeo provide some [example notebooks](https://github.com/pangeo-data/pangeo- example-notebooks).
As a very brief example of the power and simplicity of Jupyter notebooks, especially on Kubernetes, this short video (no sound) shows a user signing into a CaaS Pangeo cluster and uploading a notebook. When run, the notebook spawns a Dask cluster inside Kubernetes and uses it to perform a noddy but relatively time-consuming calculation. You can see the Dask cluster scale up to meet demand in the Dask dashboard:
Administering the hub &nbsp; JupyterHub allows admin users to manage the notebooks running in the system, and even to impersonate other users. Unfortunately, the JupyterHub LDAP integration does not currently allow for an entire group to be designated as admins, so admin access in JupyterHub is granted specifically to the FreeIPA admin user.
To access the admin section, first click Hub &gt; Control Panel in the JupyterLab interface:
Administering the hub (1) This will open the JupyterHub control panel - any user can use this to start and stop their notebook server, but admins see an extra Admin tab:
Administering the hub (2) Clicking on this tab will show a list of the users in the hub, along with buttons to start and stop the servers for those users:
Administering the hub (3) Additional admins can be added by clicking the edit user button for that user. This will pop up a dialogue:
Administering the hub (4) Check the Admin checkbox and click Edit User to save. The user is now an admin for the hub.`}).add({id:34,tag:"en",href:"/docs/for-cloud-tenants/cluster-as-a-service-shared-storage/",title:"Cluster-as-a-Service - Shared storage",description:"Cluster-as-a-Service - Shared storage",content:`This article describes how to deploy and use shared storage clusters using JASMIN Cluster-as-a-Service (CaaS).
Introduction &nbsp; CaaS provides shared storage clusters that can be mounted on multiple nodes to provide common storage across all those nodes.
These storage clusters are not intended to be directly consumed by users, but are taken as cluster configuration options by other clusters. In particular, Slurm clusters take a shared storage cluster as a configuration option - the shared storage is mounted on each cluster node for user home directories.
NFS &nbsp; Network File System (NFS) is a protocol for accessing remote network-attached storage. NFS is also used to refer to the implementation of the protocol in the Linux kernel.
A CaaS NFS shared storage cluster provides a simple NFS server. A volume is attached of the specified size, formatted as an XFS filesystem, mounted at /srv and exported with no authentication.
NFS servers do not get an external IP, and so are only accessible from the tenancy&rsquo;s internal network.
Cluster configuration &nbsp; The following variables are available to configure an NFS cluster:
Variable Description Required? Can be updated? Identity manager The CaaS Identity Manager that is used to control access to the cluster. Yes No Volume size The size of the NFS data volume in GB. Yes No Size The size to use for the NFS server. Yes No`}).add({id:35,tag:"en",href:"/docs/for-cloud-tenants/cluster-as-a-service-slurm/",title:"Cluster-as-a-Service - Slurm",description:"Cluster-as-a-Service - Slurm",content:`This article describes how to deploy and use a Slurm cluster using JASMIN Cluster-as-a-Service (CaaS).
&nbsp; CaaS Slurm clusters are currently disabled because of a security problem with the images that were being used. We are working on a new system which will provide slurm clusters. Introduction &nbsp; The Slurm Workload Manager is a popular open- source job scheduler. It provides facilities for executing and monitoring workloads across a set of nodes and managing contention for those nodes by maintaining a queue of pending jobs.
Slurm is a powerful scheduling system, and a full discussion of the available commands and options is beyond the discussion of this article - please consult the Slurm documentation. This article focuses on the specifics of how to deploy and access a Slurm cluster in CaaS.
In CaaS, a Slurm cluster consists of a single login node and several worker nodes. The Linux users and groups on the cluster are managed by the Identity Manager for the tenancy, meaning that SSH access to the nodes can be controlled using FreeIPA groups. User home directories are mounted on all nodes using a shared storage cluster. Slurm is configured with a single queue, to which all the compute hosts are added.
The login node can optionally be assigned an external IP, however external IPs are a scarce resource in the JASMIN Cloud - if you want to preserve your external IPs for other clusters, you can use the Identity Manager gateway host as a jump host.
Cluster configuration &nbsp; The following variables are available to configure a Slurm cluster:
Variable Description Required? Can be updated? Identity manager The CaaS Identity Manager that is used to control access to the cluster. Yes No Shared storage The shared storage cluster to use for user home directories. Yes No Worker nodes The number of worker nodes in the cluster. This can be scaled up or down after deployment. When scaling down, there is currently no effort made to drain the hosts in order to remove them gracefully: jobs executing on the removed hosts will fail. This may change in the future. Yes Yes Login node size The size to use for the login node. Yes No Compute node size The size to use for the compute nodes. Yes No External IP The external IP to attach to the login node. This is optional - if not given, the cluster can still be accessed by using the Identity Manager&rsquo;s gateway host as a jump host for SSH. No No Accessing the cluster &nbsp; The Slurm hosts are configured to use the users and groups from FreeIPA using SSSD. They are also configured to use SSH keys from FreeIPA for SSH authentication (password-based SSH is disabled).
For every Slurm cluster that is deployed, CaaS automatically creates a group in FreeIPA called &lt;clustername&gt;_users. This group, along with the admins group, are permitted SSH access to the hosts in the cluster. To permit a user SSH access to a Slurm cluster, they just need to be added to one of these groups (depending on whether you also want them to be an admin on other clusters).
Once they have been added to one of these groups, the Slurm cluster can be accessed via SSH. The following is an example of accessing a Slurm cluster without an external IP using the Identity Manager&rsquo;s gateway as a jump host:
# Add SSH key to the session ssh-add /path/to/ssh/key # SSH to the identity manager gateway with agent forwarding enabled ssh -A jbloggs@192.171.139.83 # SSH to the Slurm login node ssh 192.168.3.16 # Check that we are in our home directory pwd /home/users/jbloggs # Check the Slurm status sinfo PARTITION AVAIL TIMELIMIT NODES STATE NODELIST compute* up 1-00:00:00 3 idle slurm-compute-[0-2] # Run a simple job srun -N3 -l /bin/hostname 0: slurm-compute-0.novalocal 1: slurm-compute-1.novalocal 2: slurm-compute-2.novalocal A more in-depth discussion of the capabilities of Slurm is beyond the scope of this document - please refer to the Slurm documentation.`}).add({id:36,tag:"en",href:"/tags/cmip5/",title:"Cmip5",description:"",content:""}).add({id:37,tag:"en",href:"/tags/cmip6/",title:"Cmip6",description:"",content:""}).add({id:38,tag:"en",href:"/tags/community/",title:"Community",description:"",content:""}).add({id:39,tag:"en",href:"/docs/software-on-jasmin/community-software-checksit/",title:"Community Software: checksit",description:"Community Software: checksit",content:`Overview &nbsp; checksit is a tool that checks the structure and content of a file against a range of available checks. Checks can be made using either &ldquo;spec&rdquo; files defining rules that objects within a file must meet, or comparison against a template file.
Whilst initial development focussed around the standards developed for NCAS data, checksit can be adapted to check files against any desired requirements.
Features &nbsp; Currently, checksit can:
use spec files and define rules against which to check files check a file against a given template file check for compliance against NCAS-GENERAL-2.0.0 and NCAS-IMAGE-1.0 standards output in either &ldquo;standard&rdquo; mode or a one line &ldquo;compact&rdquo; mode summarise output from multiple &ldquo;compact&rdquo; mode file checks Work in progress includes:
check for compliance against other NCAS standards (e.g. NCAS-RADAR) check against future versions of standards (NCAS-GENERAL-2.1.0 and NCAS-IMAGE-1.1) allow user defined specs and rules Visit the GitHub repository linked at the bottom of this page for further information on what is being worked on. Use on JASMIN &nbsp; checksit is available on all sci machines. To check a file in your current directory:
/apps/jasmin/community/checksit/checksit check name-of-file.ext For a complete guide on how to use checksit, please visit the documentation site linked at the bottom of this page.
Further information &nbsp; Documentation: https://checksit.readthedocs.io/en/latest/
GitHub: https://github.com/cedadev/checksit`}).add({id:40,tag:"en",href:"/docs/software-on-jasmin/community-software-esmvaltool/",title:"Community Software: ESMValTool",description:"Community Software: ESMValTool",content:`ESMValTool is installed on JASMIN as a community package. This article provides:
a brief overview of the ESMValTool software a description of the main features of the tool a quick-start for using ESMValTool on JASMIN links to further information Overview of ESMValTool &nbsp; The Earth System Model Evaluation Tool (ESMValTool) is a community diagnostics and performance metrics tool for the evaluation of Earth System Models (ESMs) that allows for routine comparison of single or multiple models, either against predecessor versions or against observations. The priority of the effort so far has been to target specific scientific themes focusing on selected Essential Climate Variables, a range of known systematic biases common to ESMs, such as coupled tropical climate variability, monsoons, Southern Ocean processes, continental dry biases and soil hydrology-climate interactions, as well as atmospheric CO2 budgets, tropospheric and stratospheric ozone, and tropospheric aerosols.
The tool is being developed in such a way that additional analyses can easily be added. A set of standard recipes for each scientific topic reproduces specific sets of diagnostics or performance metrics that have demonstrated their importance in ESM evaluation in the peer-reviewed literature. The ESMValTool is a community effort open to both users and developers encouraging open exchange of diagnostic source code and evaluation results from the CMIP ensemble. This will facilitate and improve ESM evaluation beyond the state-of- the-art and aims at supporting such activities within the Coupled Model Intercomparison Project (CMIP) and at individual modelling centres. Ultimately, we envisage running the ESMValTool alongside the Earth System Grid Federation (ESGF) as part of a more routine evaluation of CMIP model simulations while utilizing observations available in standard formats (obs4MIPs) or provided by the user.
Installation as a &ldquo;community package&rdquo; on JASMIN &nbsp; ESMValTool is installed on JASMIN as a community package. This means it is provided, and maintained, by developers outside the CEDA/JASMIN Team. If you have queries about using ESMValTool on JASMIN then please contact the JASMIN Helpdesk and we will forward them to the team that supports this package on JASMIN.
Main Features &nbsp; ESMValTool has the following features:
Facilitates the complex evaluation of ESMs and their simulations submitted to international Model Intercomparison Projects (e.g., CMIP). Standardized model evaluation can be performed against observations, against other models or to compare different versions of the same model. Wide scope: includes many diagnostics and performance metrics covering different aspects of the Earth System (dynamics, radiation, clouds, carbon cycle, chemistry, aerosol, sea-ice, etc.) and their interactions. Well-established analysis: standard namelists reproduce specific sets of diagnostics or performance metrics that have demonstrated their importance in ESM evaluation in the peer-reviewed literature. road documentation: a user guide (Eyring et al., 2015); SPHINX; a log-file is written containing all the information of a specific call of the main script: creation date of running the script, version number, analyzed data (models and observations), applied diagnostics and variables, and corresponding references. This helps to increase the traceability and reproducibility of the results. High flexibility: new diagnostics and more observational data can be easily added. Multi-language support: Python, NCL, R&hellip; other open-source languages are possible. CF/CMOR compliant: data from many different projects can be handled (CMIP, obs4mips, ana4mips, CCMI, CCMVal, AEROCOM, etc.). Routines are provided to CMOR-ize non-compliant data. Integration in modelling workflows: for EMAC, NOAA-GFDL and NEMO, can be easily extended. Quick User Guide on JASMIN &nbsp; The latest version of ESMValTool is available for users on JASMIN and can be accessed via a standard module:
module load esmvaltool To run a yaml-formatted recipe:
esmvaltool run recipe.yml For a complete guide on how to configure the tool, set up and run available diagnostic recipes please consult the documentation at: https://docs.esmvaltool.org/en/latest/
Further information &nbsp; Documentation: https://docs.esmvaltool.org/en/latest/ Website: https://www.esmvaltool.org/index.html GitHub: https://github.com/ESMValGroup/ESMValTool`}).add({id:41,tag:"en",href:"/docs/software-on-jasmin/conda-environments-and-python-virtual-environments/",title:"Conda environments and Python virtual environments",description:"Conda environments and Python virtual environments",content:`Introduction &nbsp; This article describes two types of software environments that you can create in order to install packages for your own use on JASMIN. Typical examples why you may wish to do this is if you have asked us to add packages to Jaspy but wish to make use of them before the next release, or if they are not likely to be relevant to other users.
Separate pages explain the details of how to create and install Python virtual environments and Conda environments. This page gives an overview of what they are, and how to choose which one is most suitable for your needs.
Description of Python virtual environments and Conda environments &nbsp; A Python virtual environment is a relatively lightweight environment, which is used for running Python packages, typically installed using the &ldquo;pip&rdquo; installer from the Python Package Index (pypi) or locally from Python source containing a &ldquo;setup.py&rdquo; file. This enables you to install packages in your home directory without writing to the underlying Python installation itself (for example when you do not have write permission), and you can have any number of separate virtual environments and &ldquo;activate&rdquo; the relevant one when needed. When you run &ldquo;pip&rdquo; to install a Python package, additional Python packages may be installed automatically in order to satisfy dependencies. Depending on the package being installed, if it requires compiled libraries to accompany it, it may try to compile these locally, but depending what development libraries are available, occasionally this might not succeed. By contrast, a Conda environment is a much bulkier, more fully featured environment, using the conda package manager. This enables the installation of packages from conda channels, typically conda-forge, which are not restricted to being Python packages. Where packages contain compiled libraries, these are generally available as pre-compiled binaries. As with python virtual environments, you can have any number of these environments and activate the required one. When you run the conda installer, similarly it will install whatever additional packages are required in order to satisfy dependencies. (It is also possible to use the pip installer when working with conda environments.) Environment size &nbsp; To take an example of the size, a new Python virtual environment without additional packages occupies about 10MB and contains under 1000 files (maybe approximately twice this if using the --system-site-packages option explained in more detail elsewhere), whereas as a new conda base environment occupies about 400MB and contains over 20,000 files.
Installation examples &nbsp; To give an example of installing a Python package, the numexpr library is a numerical expression evaluator for NumPy. It is available as a pip package called numexpr, and also as a conda package called numexpr. (For some packages, the two may have slightly different names.) It can be installed successfully into either a Python virtual environment using pip install numexpr or a conda environment using conda install numexpr. In either case, the numpy package on which it depends, amongst other things, will be installed automatically if required.
To give an example of installing a non-python package, zsh is a Unix shell which combines various features of bash and csh. You cannot install this using pip install because it is not a python package, but it is available on conda-forge, and can be installed into a conda environment using conda install zsh.
Combining environments &nbsp; We already provide a wide range of packages via Jaspy. This is in itself a conda environment, and it is important to note that although you can use a Python virtual environment to install additional packages when using a conda environment, you cannot have more than one conda environment activated at the same time.
When using Python virtual environments, you are advised to start by activating a Jaspy environment, as this will ensure that you are using a version of Python that we support, as well as significantly increasing the range of compiled libraries available during the &ldquo;pip install&rdquo; process. You can also use the &ldquo;&ndash;system-site-packages&rdquo; option to access the Python packages provided by Jaspy itself, as described in more detail on the virtual environments help page. However, if you choose to use your own conda environment, then you will activate it instead of Jaspy, and you will need to install into it everything that you will need to accompany the package which you wish to use. Note that because you can install pip packages into conda environment, it is not generally useful to create a virtual environment in order to extend your own private conda environment. The reason for creating one to extend Jaspy is that users do not have write permission to add packages to Jaspy itself.
Choosing between a Python virtual environment and a Conda environment &nbsp; Because python virtual environments are much more lightweight that conda environments, and also give you access to packages that we provide via Jaspy, we would generally recommend that you start by trying a Python virtual environment. However, this might prove not to be possible, for example because:
The package that you wish to install is not available via PyPI (perhaps it is not a Python package). The package that you wish to install depends on compiled libraries that do not build successfully during a &ldquo;pip install&rdquo;. Often pre-compiled versions will be available from conda-forge. If you do decide to install a conda environment, then remember to install additional packages that you might otherwise have used via Jaspy.`}).add({id:42,tag:"en",href:"/docs/short-term-project-storage/configuring-cors-for-object-storage/",title:"Configuring CORS for object storage",description:"Confguring cross-origin resource sharing (CORS) for object storage.",content:`Introduction &nbsp; This article describes how to configure Cross-Origin Resource Sharing (CORS) on a JASMIN Caringo S3 object store.
S3 CORS configuration &nbsp; JASMIN&rsquo;s DataCore (previously Caringo) S3 object storage allows domain owners to configure Cross-Origin Resource Sharing (CORS) at bucket level. This article assumes you have read the this help article which introduces the object store and the use of the s3cmd command line tool.
Prerequisites &nbsp; You will need a valid S3 Token ID and Secret Key for the domain that you wish to modify.
e.g.
key will not be displayed again! Token ID: &lt;The Token for your Domain&gt; S3 Secret Key: &lt;The Secret for your Domain&gt; Expiration Date: 2024-02-13 Owner: &lt;Your JASMIN ID&gt; Description: test See using s3cmd for instructions on generating these. CORS XML Configuration File &nbsp; CORS configuration is set on the S3 bucket using an XML file format, as shown below:
&lt;CORSConfiguration&gt; &lt;CORSRule&gt; &lt;AllowedOrigin&gt;http://www.example1.com&lt;/AllowedOrigin&gt; &lt;AllowedMethod&gt;PUT&lt;/AllowedMethod&gt; &lt;AllowedMethod&gt;POST&lt;/AllowedMethod&gt; &lt;AllowedMethod&gt;DELETE&lt;/AllowedMethod&gt; &lt;AllowedHeader&gt;*&lt;/AllowedHeader&gt; &lt;/CORSRule&gt; &lt;CORSRule&gt; &lt;AllowedOrigin&gt;http://www.example2.com&lt;/AllowedOrigin&gt; &lt;AllowedMethod&gt;PUT&lt;/AllowedMethod&gt; &lt;AllowedMethod&gt;POST&lt;/AllowedMethod&gt; &lt;AllowedMethod&gt;DELETE&lt;/AllowedMethod&gt; &lt;AllowedHeader&gt;*&lt;/AllowedHeader&gt; &lt;/CORSRule&gt; &lt;CORSRule&gt; &lt;AllowedOrigin&gt;*&lt;/AllowedOrigin&gt; &lt;AllowedMethod&gt;GET&lt;/AllowedMethod&gt; &lt;/CORSRule&gt; &lt;/CORSConfiguration&gt;The above example shows a configuration which allows CORS access from external web sites www.example1.com and www.example2.com.
You can create a new file on your filesystem to store your CORS configuration using the above example as a reference. In the next step, you&rsquo;ll learn how to apply this file to your bucket.
Applying CORS Settings to a Bucket &nbsp; To apply the CORS XML file you&rsquo;ve created, you can use any S3 compatible client to set the CORS configuration.
The following example uses s3cmd on a Linux system.
First confirm that your s3cmd settings are correct by showing the info of the bucket.
e.g.
s3cmd info s3://testbin1 s3://testbin1/ (bucket): Location: objectstore4.jc.rl.ac.uk Payer: none Expiration Rule: none Policy:  &#34;Version&#34;:&#34;2008-10-17&#34;, &#34;Id&#34;:&#34;testbin1 Policy&#34;, &#34;Statement&#34;: [  &#34;Sid&#34;:&#34;1: Full access for Users&#34;, &#34;Effect&#34;:&#34;Allow&#34;, &#34;Principal&#34;:&#34;anonymous&#34;:[&#34;*&#34;], &#34;Action&#34;:[&#34;*&#34;], &#34;Resource&#34;:&#34;*&#34; ,  &#34;Sid&#34;:&#34;2: Read-only access for Everyone&#34;, &#34;Effect&#34;:&#34;Allow&#34;, &#34;Principal&#34;:&#34;anonymous&#34;:[&#34;*&#34;], &#34;Action&#34;:[&#34;GetObject&#34;,&#34;GetBucketCORS&#34;], &#34;Resource&#34;:&#34;*&#34;  ]  CORS: none ACL: ahuggan: FULL_CONTROL This example shows a bucket which currently doesn&rsquo;t have a CORS policy set. Specifically, this is the section we&rsquo;re interested in:
CORS: noneIn this example, we&rsquo;ll set a simple &ldquo;allow all&rdquo; CORS configuration. We&rsquo;ve already created a file named test-cors-file which we will be uploading to the bucket:
&lt;CORSConfiguration&gt; &lt;CORSRule&gt; &lt;AllowedOrigin&gt;*&lt;/AllowedOrigin&gt; &lt;AllowedMethod&gt;GET&lt;/AllowedMethod&gt; &lt;AllowedMethod&gt;HEAD&lt;/AllowedMethod&gt; &lt;AllowedHeader&gt;*&lt;/AllowedHeader&gt; &lt;/CORSRule&gt; &lt;/CORSConfiguration&gt;Using the s3cmd command, we apply the CORS XML file to our S3 bucket:
s3cmd setcors test-cors-file s3://testbin1 (your S3 address will be different to the one shown here)
We can now run the info command to confirm that the CORS configuration from our file has been set on the bucket:
s3cmd info s3://testbin1 s3://testbin1/ (bucket): Location: objectstore4.jc.rl.ac.uk Payer: none Expiration Rule: none Policy:  &#34;Version&#34;:&#34;2008-10-17&#34;, &#34;Id&#34;:&#34;testbin1 Policy&#34;, &#34;Statement&#34;: [  &#34;Sid&#34;:&#34;1: Full access for Users&#34;, &#34;Effect&#34;:&#34;Allow&#34;, &#34;Principal&#34;:&#34;anonymous&#34;:[&#34;*&#34;], &#34;Action&#34;:[&#34;*&#34;], &#34;Resource&#34;:&#34;*&#34; ,  &#34;Sid&#34;:&#34;2: Read-only access for Everyone&#34;, &#34;Effect&#34;:&#34;Allow&#34;, &#34;Principal&#34;:&#34;anonymous&#34;:[&#34;*&#34;], &#34;Action&#34;:[&#34;GetObject&#34;,&#34;GetBucketCORS&#34;], &#34;Resource&#34;:&#34;*&#34;  ]  CORS: &lt;CORSConfiguration&gt; &lt;CORSRule&gt; &lt;AllowedOrigin&gt;*&lt;/AllowedOrigin&gt; &lt;AllowedMethod&gt;HEAD&lt;/AllowedMethod&gt; &lt;AllowedMethod&gt;GET&lt;/AllowedMethod&gt; &lt;AllowedHeader&gt;*&lt;/AllowedHeader&gt; &lt;/CORSRule&gt; &lt;/CORSConfiguration&gt; ACL: ahuggan: FULL_CONTROL To delete the CORS config from the bucket, we can run the following command:
s3cmd delcors s3://testbin1 s3://testbin1/: CORS deleted`}).add({id:43,tag:"en",href:"/tags/connection/",title:"Connection",description:"",content:""}).add({id:44,tag:"en",href:"/tags/consortium/",title:"Consortium",description:"",content:""}).add({id:45,tag:"en",href:"/tags/cordex/",title:"Cordex",description:"",content:""}).add({id:46,tag:"en",href:"/docs/interactive-computing/creating-a-virtual-environment-in-the-notebooks-service/",title:"Creating a virtual environment in the jasmin notebooks service",description:"Creating a virtual environment in the notebooks service",content:`Creating a virtual environment is useful to allow a discrete set of extra packages to be installed to meet specific requirements. This allows a user to run multiple environments with different dependencies without conflicts.
There are a number of ways to create a virtual environment to use with the notebook service. This document outlines the most common and reccomended methods, and then some other ways which you might find useful.
Please note that environments created for the notebook service will not work on the jasmin scientific analysis servers or the LOTUS batch processing.
Step 1: Creating a virtual environment &nbsp; This step creates a python virtual environment, and allows you to install packages into it.
&nbsp; These commands are intended for use at the jupyter notebooks shell, not on the JASMIN sci machines To get started, head to https://notebooks.jasmin.ac.uk and click the terminal button.
terminal button Then, type these commands at the bash shell which appears.
First, make a directory in which to store your virtual environments. You can put this wherever you like, as long as you reference the same place later. You could store several virtual environments within this directory, for different purposes. Then, change into that directory.
mkdir ~/nb_envs cd ~/nb_envs Next, create a new empty virtual environment. We recommended including the --system-site-packages argument which will allow you to add packages on top of jaspy, rather than starting completely from scratch.
python -m venv name-of-environment --system-site-packages Then, activate the specific virtual environment created above, which will allow you to install packages.
source name-of-environment/bin/activate If you want to be able to use your virtual environment as a jupyter notebook kernel (reccomended), you should install ipykernel using pip.
pip install ipykernel You can then install whatever packages you need in the environment.
pip install pyjokes If you change your mind and need to add more packages in the future, it is simple to activate the virtual environment in the same way as above and use pip to install more packages.
Step 2: Making the notebook service recognise your new kernel. &nbsp; These steps are also run from the notebooks&rsquo; service shell, as above.
If you aren&rsquo;t still there from the last step, cd to the location of your venv.
cd ~/nb_envs If it isn&rsquo;t already active, activate the virtual environment.
source name-of-environment/bin/activate Running the following command will make the notebook&rsquo;s service notice your new virtual environment, and include it in the list of kernels which you can run code with. You only have to do this once.
python -m ipykernel install --user --name=name-of-environment Step3: Using Your New Kernel &nbsp; Select kernel, in this case: 'name-of-environment' You can then choose this kernel from the jupyterhub homepage, or from the top right of any open notebook. No changes to the python code within are required.
kernel name in notebook title tab Other tips &amp; useful knowledge &nbsp; Activating an environment without it being a kernel. &nbsp; If you follow Step 1 above to create a virtual environment, it is possible to use the packages from this environment in a python file without making it a kernel. While this can be useful, it has the very distinct disadvantage of hardcoding the path to your virtual environment in your python code. For this reason we discourage using this method with a medium level of severity. To do this, simply add the following code to your python file before any imports. Adjust the venv_path variable to be correct for the venv you created.
import sys import pathlib import platform venv_path = &#34;~/nb_envs/name-of-environment&#34; py_version = platform.python_version_tuple() sys.path.append( str( pathlib.Path( f&#34;venv_path/lib/pythonpy_version[0].py_version[1]/site-packages/&#34; ).expanduser() ) )Explanation: this adds the site-packages folder from your venv directly to the path python uses to search for packages ($PYTHONPATH). This lets python find them to import.
Can I install packages from inside my python code? &nbsp; We very strongly recomend NOT trying to install python packages from inside notebook code. pip isn&rsquo;t designed for it, and it is almost always easier to activate the venv as above and install things that way.
If you wish to record the set of packages inside your venv so you can install them en-masse later, pip has the facility to do this. To export a list of packages that exist inside a venv, from the notebooks bash shell with the virtual environment in question activated:
pip freeze &gt; requirements.txt To install a list of packages which have been exported:
pip install -r requirements.txt Exporting packages in this way is also useful for sharing your environment with others, reinstalling when it breaks etc. It&rsquo;s a good idea to keep the requirements file alongside the code in version control. If your code becomes more complex it is probably more sensible to make it a python package, and install it as one, but doing that is outside the scope of this document.
If you really must, you can call pip from inside your notebook like this: (after first updating the packages variable to be the ones you want to install.)
import sys import subprocess as sp packages = [&#39;pyjokes&#39;] sp.check_call([sys.executable, &#39;-m&#39;, &#39;pip&#39;, &#39;install&#39;] + packages) Can I use conda instead of a virtual environment? &nbsp; Yes, no problem.
To create a conda environment, sinply run the following at the JASMIN Notebooks shell:
conda create --name name-insert-here ipykernel Install any packages you which to use in the environment:
conda install --name name-insert-here pyjokes Make the notebook service recognise your environment as a kernel:
conda run --name name-insert-here python -m ipykernel install --user --name name-insert-here Can I get rid of my old kernels from the notebook service? &nbsp; Yes.
To list the names of kernels you have installed, run the following at the JASMIN notebook&rsquo;s shell:
jupyter kernelspec list To remove one of them, run:
jupyter kernelspec uninstall insert-name-here`}).add({id:47,tag:"en",href:"/docs/software-on-jasmin/creating-and-using-miniconda-environments/",title:"Creating and using miniconda environments",description:"Creating and using miniconda environments",content:`On JASMIN, we provide a wide range of packages via the Jaspy environment (which is itself a Conda environment). This page gives detail on how to create and use your own personal Conda environments via the miniconda installer, as an alternative to the use of Jaspy.
To decide whether you should use a Python virtual enviro nment or a Conda environment , first see the page: overview of software environments.
Obtaining miniconda &nbsp; In order to create your own conda environments, you will first need to download the miniconda installer. It is possible as an alternative to use the full Anaconda, but your initial base environment will be much bigger if you do that (at time of writing this installs 5GB, compared to 400MB with miniconda) so we suggest the use of miniconda.
This can be downloaded using:
wget https://repo.anaconda.com/miniconda/Miniconda3-latest-Linux-x86_64.sh Deactivating Jaspy &nbsp; You cannot have your own conda environment activated at the same time as Jaspy, so it is recommended that if you have loaded the jaspy module, then you start by typing:
module unload jaspy Creating a base environment &nbsp; You can run the installer by typing:
bash Miniconda3-latest-Linux-x86_64.sh
You will be asked to confirm the licence agreement, to choose an installation location, and to decide whether it should run &ldquo;conda init&rdquo;. It is recommended that you:
Accept the default location (~/miniconda3). If you need to change this, see the section &ldquo;Varying the installation location&rdquo; near the end of this page for more info. Say no to the question about &ldquo;conda init&rdquo;, because saying yes will cause it to add lines to your ~/.bashrc file causing your base environment to be activated every time you log in, which may interfere with the use of Jaspy. If you say no, you can still follow the instructions below when you wish to activate your base environment. (Add the -b option at the end of the above command to run the installer in batch mode, which will also skip the &ldquo;conda init&rdquo;. Or add -h to see help on other available command-line options.)
Activating the base environment &nbsp; Assuming that you made the choices recommended above when running the installer, you should type the following in order to activate the base environment:
source ~/miniconda3/bin/activate(You may encounter documentation elsewhere which suggests &ldquo;conda activate&rdquo; instead, but the above command is a workaround for the fact that you have not run &ldquo;conda init&rdquo;, the reasons for which are explained above.)
Your command prompt will then change to include &ldquo;(base) &quot; at the start, in order to remind you that this environment is activated. You can deactivate the environment by typing:
conda deactivate Creating and activating a sub-environment &nbsp; Although once you have activated the base conda environment, you can in principle start to install packages immediately, your use of conda will generally be better organised if you do not install packages directly into the base environment, but instead use a named sub-environment. You can have multiple sub-environments under a single base environment, and activate the one that is required at any one time. Unless you install packages directly into the base environment, your sub-environments will work independently.
To create a named environment (for example, called &ldquo;myenv&rdquo;), ensure that the base environment is activated (the command prompt should start with &ldquo;(base) &ldquo;), and type:
conda create -n myenvIt will show the proposed installation location, and once you answer the prompt to proceed, will do the installation. If you have followed these instruction, this location should be /home/users/&lt;your_username&gt;/miniconda3/envs/myenv. You can alternatively give it a different location using the option -p &lt;path&gt; instead of -n &lt;name&gt;.
Once you have created your sub-environment, you can activate it using conda activate &lt;name&gt; for example:
conda activate myenvThe command prompt will then change (e.g. to start with &ldquo;(myenv) &ldquo;) to reflect this. Typing conda deactivate once will return you to the base environment; typing it a second time will deactivate conda completely (as above).
conda env listwill list your environments.
Installing conda packages &nbsp; Once you have activated a named environment, you can install packages with the conda install command, for example:
conda install gccYou can also force particular versions to be installed. See the [conda cheat sheet](https://docs.conda.io/projects/conda/en/4.6.0/_downloads/52a95608c49671267e40c689e0bc00ca/conda- cheatsheet.pdf) for details.
To list the packages installed in the currently activated environment, you can type conda list.
Running packages from your conda environment &nbsp; In order to run packages from a conda environment that you installed previously, you will first need to activate the environment in the session that you are using. This means repeating some of the commands typed above. Of course, you will not need to repeat the steps to create the environment or install the software, but the following may be needed again:
module unload jaspy source ~/miniconda3/bin/activate\` conda activate myenv\` Installing pip packages &nbsp; Many python packages that are available via PyPI are also available as conda packages in conda-forge, and it is generally best to use these via &ldquo;conda install&rdquo; as above.
Nonetheless, you can also install pip packages (as opposed to conda packages) into your conda environment. However, first you should type:
conda install pipbefore typing the desired commands such as
pip install numpyIf you do not install pip into your sub-environment, then either:
your shell will fail to find the pip executable, or your shell will find pip in your base environment, which will lead to pip packages being installed into the base environment, resulting in potential interference between your conda environments Explicitly installing pip into your sub-environment will guard against this.
The mamba installer &nbsp; When you install packages into a conda environment, the installer first has to resolve the environment. This means using available package dependency metadata in order to decide which versions of packages to install, so as to end up with a self-consistent environment. If you are working with a large environment and/or working with legacy versions of packages, sometimes (in our experience with preparing Jaspy environments) the conda installer can be very slow and use a lot of memory, and may fail to resolve the environment. In this situation, we have tended to find better performance with the mamba installer, which uses a different algorithm and is implemented in C++ rather than Python, for speed.
To use mamba, you would first type conda install mamba, and then you can use mamba install &lt;package_name&gt; instead of conda install &lt;package_name&gt; in order to install the other package(s) of interest. You would still use the conda command for other operations such as conda activate.
If you will be using mamba in multiple sub-environments, then it might make sense to install mamba into the base environment rather than each sub- environment separately, despite our general suggestion of installing packages into named sub-environments. To do this, you might need to use conda deactivate to return to the base environment before installing mamba, then re-activate your sub-environment to install other packages.
Cloning a conda environment &nbsp; There can be occasions when you wish to create a conda environment which is based on the contents of an existing environment. An example when you might wish to do this is in order to create an environment of your own which is based on Jaspy but with certain changes such as the addition or removal of certain packages. (Recall that your environment cannot be activated at the same time as Jaspy.)
To do this, you can export a list of packages to a YAML file and use this file to create the new environment &ndash; as follows:
first activate the conda environment that you wish to clone (for Jaspy, load the jaspy module) export a list of contents to a YAML file (for example &ldquo;environment.yml&rdquo;) by typing conda env export &gt; environment.yml deactivate this environment (or as the case may be, unload the jaspy module) ensure that the relevant base environment is activated create the new environment (for example &ldquo;my_new_env&rdquo;) by using: conda env create -n my_new_env -f environment.ymlNote the use of &ldquo;conda env create&rdquo;, rather than &ldquo;conda create&rdquo; as above.
(As above, if you have installed mamba, you can also use &ldquo;mamba&rdquo; in place of &ldquo;conda&rdquo; at this stage.)
You might also edit the YAML file before using it to create the environment if you do not want an exact clone &ndash; for example, adding packages, removing packages that are not of relevance, or removing version requirements in order to give the environment solver more flexibility about what versions to install (for example if you do not require particular legacy versions, or if the versions in the original environment are no longer available).
Varying the installation location &nbsp; (This is the section that is referred to above, where running the Miniconda installer is discussed.)
The default installation location offered by the installer for your base environment will be ~/miniconda3 (that is, a &ldquo;miniconda3&rdquo; subdirectory of your home directory). We recommend accepting this default, or using another location under your home directory. It is possible to change this, but note that a conda environment can have tens of thousands of files and that group workspaces on JASMIN will generally perform poorly for this use case. If you need to make a conda environment which is shared with collaborators, you may need to request a small files GWS as these will give better performance.
If you are creating a conda environment for very short-term testing only, you may find best performance using /tmp due to the large number of files. However, you may need several gigabytes, which is too big for the /tmp areas on most of the &ldquo;sci&rdquo; machines at time of writing, although sci3, sci6 and sci8 have larger /tmp areas. Choose an appropriate machine, make use of the df command to check available disk space, and ensure that you do not fill up /tmp as this would impact negatively on other users.`}).add({id:48,tag:"en",href:"/tags/cylc/",title:"Cylc",description:"",content:""}).add({id:49,tag:"en",href:"/docs/interactive-computing/dask-gateway/",title:"Dask Gateway",description:"Introduction &nbsp; Dask Gateway is a service which manages dask clusters for users. On JASMIN, it creates a dask cluster in LOTUS, our batch computing cluster.",content:`Introduction &nbsp; Dask Gateway is a service which manages dask clusters for users. On JASMIN, it creates a dask cluster in LOTUS, our batch computing cluster. It automatically creates a dask for you, scheduling Slurm jobs to create dask schedulers and workers as appropriate.
Prerequisites &nbsp; Before using Dask Gateway on JASMIN, you will need:
An existing JASMIN account and valid jasmin-login access role: Apply here&nbsp; &nbsp; &nbsp; Subsequently (once jasmin-login has been approved and completed), the dask access role: Apply here&nbsp; &nbsp; &nbsp; The jasmin-login access role ensures that your account is set up with access to the LOTUS batch processing cluster, while the dask role grants access to the special LOTUS partition used by the Dask Gateway service.
Creating a dask cluster &nbsp; In the JASMIN Notebooks service &nbsp; In the JASMIN notebooks service, authentication to dask-gateway happends automatically. You can use the snippet below to create a cluster and get a dask client which you can use:
import dask_gateway # Create a connection to dask-gateway. gw = dask_gateway.Gateway(&#34;https://dask-gateway.jasmin.ac.uk&#34;, auth=&#34;jupyterhub&#34;) # Inspect and change the options if required before creating your cluster. options = gw.cluster_options() options.worker_cores = 2 # Create a dask cluster, or, if one already exists, connect to it. # This stage creates the scheduler job in SLURM, so may take some time. # While your job queues. clusters = gw.list_clusters() if not clusters: cluster = gw.new_cluster(options, shutdown_on_close=False) else: cluster = gw.connect(clusters[0].name) # Create at least one worker, and allow your cluster to scale to three. cluster.adapt(minimum=1, maximum=3) # Get a dask client. client = cluster.get_client() ######################### ### DO DASK WORK HERE ### ######################### # When you are done and whish to release your cluster: cluster.shutdown() Elsewhere on JASMIN &nbsp; (eg. on the sci machines)
&nbsp; It is not necessary to do this if you only want to use dask in the JASMIN notebook service. At the current time, it is still necessary to use the notebooks service to generate an API token to allow you to connect to the gateway server.
&nbsp; It is very important that your API token is not shared between users and remains secret. With it, another user can submit dask jobs to lotus as you, and they could exploit this to see anything in your jasmin account. Setup &nbsp; Make a dask configuration folder in your home directory mkdir -p ~/.config/dask Create a configuration file for dask-gateway touch ~/.config/dask/gateway.yaml Change the permissions on the file so that only you can read it chmod 600 ~/.config/dask/gateway.yaml Head to https://notebooks.jasmin.ac.uk/hub/token , put a note in the box to remind yourself what this token is for, press the big orange button then copy then token.
Paste the following snippet into ~/.config/dask/gateway.yaml, replace the part in brackets with the API token you just copied.
gateway: address: https://dask-gateway.jasmin.ac.uk auth: type: jupyterhub kwargs: api_token: replaceWithYourSecretAPIToken You&rsquo;re done. You can now use dask gateway from the command line. Access the dask dashboard &nbsp; Currently the dask dashboard is not accessible from a browser outside the JASMIN firewall. If your browser fails to load the dashboard link returned, please use our graphical desktop service to run a Firefox browser inside the firewall to view your dashboard.
Use a custom python environment &nbsp; By default the jasmin notebooks service and dask gateway use the latest version of the jaspy software environment. However, often users would like to use their own software environments.
Understanding the problem &nbsp; When dask gateway greates a dask cluster for a user, it runs a setup command to activate a conda environment or python venv. To have dask use your packages, you need to create a custom environment which you can pass to dask gateway to activate.
However, for techical reasons, it is not currently possible to use the same virtual environment in both the notebook service and on jasmin. So you will need to make two environments, one for your notebook to use and one for dask to use.
&nbsp; It is VERY important that these environments have the same packages installed in them, and that the packages are exactly the same version in both environments.
If you do not keep packages and versions in-sync you can expect many confusing errors.
If you use a self-containted conda enironment this is not a problem, and you can use this as a kernel in the notebooks service and on the sci machines. You can skip to Putting it all together below.
Creating a virtual environment for dask. &nbsp; Login to the JASMIN sci machines. Activate jaspy module load jaspy Create your environment in the normal way python -m venv name-of-environment Activate the environment source name-of-environment/bin/activate Install dask and dask gateway and dependencies: without this step your environment will not work with dask. pip install dask-gateway dask lz4 Creating a virtual environment for the notebooks service &nbsp; Follow the instructions here to create a virtual environment. Install dask and dask gateway and dependencies: without this step your environment will not work with dask. pip install dask-gateway dask lz4 Putting it all together &nbsp; Set your notebook virtual environment as the kernel for the notebook in question as shown in the instructions linked above. Set options.worker_setup to a command which will activate your dask virtual environment. For example options.worker_setup = &#34;source /home/users/example/name-of-environment/bin/activate&#34; If you have an existing dask cluster, close it and ensure all lotus jobs are stopped before recreating it using the new environment. Code Examples &nbsp; Examples of code and notebooks which can be used to test the JASMIN dask gateway service are available on GitHub.`}).add({id:50,tag:"en",href:"/docs/data-transfer/",title:"Data transfer",description:"How to move data to and from JASMIN",content:""}).add({id:51,tag:"en",href:"/docs/data-transfer/data-transfer-overview/",title:"Data transfer overview",description:"Overview of data transfer",content:`This article introduces the topic of data transfer to/from JASMIN.
Introduction to Data Transfer on JASMIN &nbsp; As a JASMIN user you are very likely to be involved in data transfer. You might need to copy data files/directories from JASMIN to remote sites (such as your own PC, MONSooN or ARCHER2) or bring new data on to JASMIN. These data transfer articles explain how to use the basic transfer tools such as rsync and scp as well as more sophisticated methods such as GridFTP. They also cover which transfer services and servers are available to JASMIN users.
For many users, moving small amounts of data over short distances, the basic tools will meet their requirements. However, data transfer is a complicated topic so we also provide articles about how you can improve your transfer rates to make the most of the available bandwidth. We include details about transfers over connections to specific sites (such as the Met Office). Advice is also provided about automating and scheduling data transfers, along with tips for different transfer workflows.
Transfers to/from JASMIN &nbsp; 1. Transfers initiated from JASMIN &nbsp; When initiating a transfer from a transfer server on JASMIN you would usually start by logging on to the server (via SSH). Once you are logged in you can initiate a connection to the outside world in order to push/pull the data you require.
2. Transfers initiated from elsewhere &nbsp; When initiating a transfer from elsewhere you will transfer data files to/from a source machine (which may be inside or outside JASMIN) to the transfer server.
Transfer directories &nbsp; You will typically transfer data to/from a Group Workspace that you have been granted access to. If you are copying data from JASMIN you might want to copy data from the CEDA archive (mounted on JASMIN) to a remote site. You might also wish to copy small volumes of data to/from your $HOME directory. All of these locations are available on the transfer servers.
JASMIN Transfer servers &nbsp; JASMIN provides specific servers for managing data transfers. Please read about the different servers available for particular data transfer needs, and about the various data transfer tools available.
Improving your transfer rates &nbsp; To achieve better transfer rates, for large transfers or where speed and reliability are important, you are recommended to:
use the Globus data transfer service (recommended), or use the high-performance data transfer servers ( hpxfer access role required) use other parallel-capable transfer tools such as bbcp, lftp (parallel-capable ftp client), or gridftp: see Data transfer tools Transfer rates depend on many factors, so try to consider all of these:
do you really need to transfer some/all of the data? is the data in the CEDA Archive already (don&rsquo;t copy it, if so, just process it in-place!) can your workflow deal with processing just smaller &ldquo;chunks&rdquo; at a time (streaming)? do you really need to have/keep all the source data, if it&rsquo;s stored somewhere else? the network path all the way from where the source data resides, to the destination file system high-performance data transfer tools are great, but is the &ldquo;last mile&rdquo; over WiFi to your laptop? what is the length of the network path? If it&rsquo;s international or intercontinental, SSH-based methods won&rsquo;t work well. Consider Globus. the host at each end what sort of host is it (laptop, departmental server, virtual machine, physical machine) and what is its network connectivity? the file systems at each end not all file systems perform the same, for given types of data or transfer methods the size and number of files involved large numbers of small files can take a long time to transfer are the data in deep directory trees? These can take a long time to recreate on the destination file system consider creating a tar/zip archive to transfer fewer but larger files, or at least a method that copes well with many files in parallel or &ldquo;in flight&rdquo; at once. checking data integrity some methods will verify data integrity at source and destination to ensure integrity. This can be resource-heavy and slow. time of day would scheduling your transfer to happen at quieter times, mean that it completes more efficiently and/or without impacting others? Consider source and destination time zones!`}).add({id:52,tag:"en",href:"/docs/data-transfer/data-transfer-tools/",title:"Data Transfer Tools",description:"Data Transfer Tools",content:`This article lists the data transfer tools available on JASMIN and provides links to articles that describe them in more detail.
Data Transfer tools &nbsp; The are many tools that you can use for transferring data to/from JASMIN. See the articles linked below for more details.
Tool Info Globus An efficient, secure data transfer service available to all JASMIN users (recommended). Includes capability to schedule, repeat and orchestrate transfers between third-party hosts and receive notifications of job status. Has web and command-line interfaces. Efficient for moving large volumes and/or numbers of files, especially over long distances. scp A basic transfer tool that works over the SSH protocol. Similar to &ldquo;cp&rdquo; but copies between remote servers. rsync (over SSH) Like scp but slightly more sophisticated. Allows synchronisation between remote directory trees. sftp SSH FTP - works over SSH. bbcp A command-line tool that allows the user to specify parallel transfer over multiple streams, using SSH authentication. GridFTP (over SSH) An old but comprehensive data transfer tool. Highly configurable and able to transfer over multiple parallel streams. Used over SSH in this case. Superceded by Globus GridFTP (certificate-based) As above, but using certificate-based authentication instead of SSH credentials. Efficient for moving large volumes and/or numbers of files, especially over long distances. Superceded by Globus FTP File Transfer Protocol. An aged transfer protocol suitable for small file transfers but limited. LFTP Parallel-capable FTP client. wget, curl Download tools for accessing resources over HTTP primarily. (see 3rd party documentation) sharing GWS data via http for exposing part(s) of a Group Workspace via HTTP to users without JASMIN accounts. Python transfer tools Methods of managing/scripting data transfer tasks using Python. You can use libraries such as requests in a Python 3 virtual environment on the transfer servers. MASS client (Met Office) A specific command-line tool installed on the mass-cli1.ceda.ac.uk server on JASMIN. Enables extractions from the Met Office MASS Archive directly on to OPeNDAP rclone A 3rd party, open-source command-line utility which can interface to, and synchronise data between, a wide variety of cloud and other storage backends, such as Google Drive and AWS S3 compatible object stores. It can also sync data over SSH. This utility is not installed on JASMIN but is well-documented and trivial for users to download and configure themselves on one of the data transfer servers) Please note install instructions, and dos and don&rsquo;ts for rclone on JASMIN.`}).add({id:53,tag:"en",href:"/tags/deprecated/",title:"Deprecated",description:"",content:""}).add({id:54,tag:"en",href:"/tags/desktop/",title:"Desktop",description:"",content:""}).add({id:55,tag:"en",href:"/docs/",title:"Docs",description:"",content:""}).add({id:56,tag:"en",href:"/tags/earth/",title:"Earth",description:"",content:""}).add({id:57,tag:"en",href:"/docs/short-term-project-storage/elastic-tape-command-line-interface-hints/",title:"Elastic Tape command-line interface hints",description:"Elastic Tape command-line interface hints",content:`&nbsp; Information below relates to the Elastic Tape command-line tools. The JDMA system provides a better interface for putting/retrieving data into the Elastic Tape System) A new system called NLDS is coming very shortly (as of Feb 2023) and will eventually replace both of these. This article explains the return codes of certain Elastic Tape (ET) commands.
et_put.py &nbsp; Command-line tool to register large numbers of files for upload to Elastic Tape
Return codes &nbsp; rc 0: normal exit rc 1: error in start up parameters rc 2: error processing list &nbsp; When writing data to the ET system, it is very important that data remains in place on disk, in the location where ET expects to find them, until the status of the batch in question has reached CACHED_SYNCED or SYNCED. This means that the data have actually been written to tape, but is not the case until that status is shown.
The location where ET expects to find the files will be specified in the LISTFILE that the user supplied to the et_put.py command, or all files and directories under the DIR. The status of user&rsquo;s batches can be checked by going to the webpage: http://et-monitor.fds.rl.ac.uk/et_user/ET_AlertWatch.php. You need to be logged into JASMIN to see this webpage, via the nx-login servers, and use Firefox as the web browser.
Deleting the data from disk prematurely can cause problems for the ET system as a whole (impacting other users) so please be careful with this aspect.
et_get.py &nbsp; Command-line tool to download large numbers of files from Elastic Tape
Return codes &nbsp; 0: normal exit 1: error in start up parameters 2: cannot write to target directory 3: error received during download 4: closed by interrupt (^c probably) 5: completed with &#34;bad files&#34; (see list via stderr) et_rm.py &nbsp; Command-line tool to delete files from Elastic Tape
Return codes &nbsp; rc 0: normal exit rc 1: error in start up parameters rc 2: error processing list et_ls.py &nbsp; Command-line tool for listing holdings in Elastic Tape
et_ls.py and grep &nbsp; The first character on any data line is the line&rsquo;s type. This allows a script to know the type of line it is trying to parse
Return codes &nbsp; 0: normal exit 1: error in start up parameters or reading config file 2: requestor is not authorised for the intended workspace 4: closed by interrupt (^c probably) or as a result of a head/tail command et_transfer_mp &nbsp; Return codes &nbsp; 0: OK 1: config error 2: log directory error 3: already running 4: error creating client`}).add({id:58,tag:"en",href:"/tags/environment/",title:"Environment",description:"",content:""}).add({id:59,tag:"en",href:"/docs/batch-computing/example-job-2-calc-md5s/",title:"Example Job 2: Calculating MD5 Checksums on many files",description:"Example Job 2: Calculating MD5 Checksums on many files",content:`This page records some early CEDA usage of the LOTUS cluster for various relatively simple tasks. Others may wish to use these examples as a starting point for developing their own workflows on LOTUS.
Case 1: Calculating MD5 Checksums on many files &nbsp; This is a simple case because:
the archive only needs to be read by the code and the code that we need to run involves only the basic linux commands so there are no issues with picking up dependencies from elsewhere. Case Description** &nbsp; we want to calculate the MD5 checksums of about 220,000 files. It will take a day or two to run them all in series. we have a text file that contains 220,000 lines - one file per line. Solution under LOTUS &nbsp; Split the 220,000 lines into 22 files of 10,000 lines. Write a template script to: Read a text file full of file paths Run the md5sum command on each file and log the result. Write a script to create 22 new scripts (based on the template script), each of which takes one of the input files and works through it. And this is how it looks &nbsp; Log in to the sci server (from a login server):
ssh -A &lt;username&gt;@sci1.jasmin.ac.uk Split the big file
split -l 10000 -d file_list.txt Produces 22 files called &#34;x00&#34;...&#34;x21&#34; Create the template file: scan_files_template.sh
#!/bin/bash #SBATCH -e %J.e infile=/home/users/astephen/sst_cci/to_scan/__INSERT_FILE__ while read f ; do /usr/bin/md5sum $f &gt;&gt; /home/users/astephen/sst_cci/output/scanned___INSERT_FILE__.log done &lt; $infileRun a script to generate all the script files:
for i in \`ls /home/users/astephen/sst_cci/to_scan/\` ; do cp scan_files_template.txt bin/scan_files_$i.sh perl -p -i -w -e &#39;s/__INSERT_FILE__/&#39;$i&#39;/g;&#39; bin/scan_files_$i.sh doneSubmit all 22 jobs to LOTUS:
for i in \`ls /home/users/astephen/sst_cci/to_scan/\` ; do echo $i sbatch -p short-serial -o /home/users/astephen/sst_cci/output/$i /home/users/astephen/sst_cci/bin/scan_files_$i.sh doneWatch the jobs running:
squeue -u &lt;username&gt; And the result &nbsp; All jobs ran within about an hour.
Case 2: Checksumming CMIP5 Data &nbsp; A variation on Case 2 has been used for checksumming datasets in the CMIP5 archive. The Python code below will find all NetCDF files in a DRS dataset and generate a checksums file and error log. Each dataset is submitted as a separate bsub job.
&#34;&#34;&#34; Checksum a CMIP5 dataset usage: checksum_dataset.py dataset_id ... where dataset_id is a full drs id including version e.g. cmip5.output1.MOHC.HadGEM2-ES.historical.6hr.atmos.6hrLev.r1i1p1.v20110921 &#34;&#34;&#34; import os import os.path as op import sys import optparse DRS_ROOT = &#39;/badc/cmip5/data&#39; def submit_job(dataset): # Assume version is in the dataset-id for now parts = dataset.split(&#39;.&#39;) path = op.join(DRS_ROOT, &#39;/&#39;.join(parts)) if not op.exists(path): raise Exception(&#39;%s does not exist&#39; % path) job_name = dataset cmd = (&#39;bsub -q lotus -J job_name &#39; &#39;-o job_name.checksums -e job_name.err &#39; &#34;/usr/bin/md5sum &#39;path/*/*.nc&#39;&#34;).format(job_name=job_name, path=path) print(cmd) os.system(cmd) def main(): parser = optparse.OptionParser(description=&#39;Checksum DRS datasets&#39;) (options, args) = parser.parse_args() datasets = args for dataset in datasets: submit_job(dataset) if __name__ == &#39;__main__&#39;: main()If you have a file containing a list of dataset ids you can submit each as a separate job by invoking the above script as follows:
./checksum_dataset.py $(cat datasets_to_checksum.dat) sbatch-q short-serial -J cmip5.output1.MOHC.HadGEM2-ES.rcp85.day.seaIce.day.r1i1p1.v20111128 -o cmip5.output1.MOHC.HadGEM2-ES.rcp85.day.seaIce.day.r1i1p1.v20111128.checksums -e cmip5.output1.MOHC.HadGEM2-ES.rcp85.day.seaIce.day.r1i1p1.v20111128.err /usr/bin/md5sum &#39;/badc/cmip5/data/cmip5/output1/MOHC/HadGEM2-ES/rcp85/day/seaIce/day/r1i1p1/v20111128/*/*.nc&#39; Job &lt;745307&gt; is submitted to queue &lt;lotus&gt;. ...`}).add({id:60,tag:"en",href:"/training/advanced/training-exercises-coming-soon/",title:"Example training exercise",description:"Exercises to help you get the most out of JASMIN",content:`Watch this space &nbsp; We&rsquo;ll be adding more content soon, as we reorganise the JASMIN help content further.
For now, please see JASMIN Training Workshop materials&nbsp; .`}).add({id:61,tag:"en",href:"/tags/exercise/",title:"Exercise",description:"",content:""}).add({id:62,tag:"en",href:"/docs/mass/external-access-to-mass-faq/",title:"External Access to MASS FAQ",description:"External Access to MASS FAQ",content:`Introduction &nbsp; The Managed Archive Storage System (MASS) provides storage and restore services for large volumes of Met Office data. It is a service operated by the UK Met Office.
This article provides answers to MASS frequently asked questions: Click on the link for each of the FAQs below to expand the answer.
General &nbsp; Can I use my existing MASS account No. You need a separate MASS account for use on the Met Office internal network (CDN), Monsoon, ECMWF HPCs, and JASMIN. With these different account types, you can have permission to access different datasets specific to these computing environments. How do I use MOOSE? Please see the MOOSE User Guide here Will my account expire? Yes. By default, MASS via JASMIN accounts will expire after 500 days and your account will be automatically disabled.
Shortly before your account is due to expire you will receive an email, and it will contain instructions for you and your sponsor about how to extend your access. If your account has already expired and you are looking to reactive it, please email: Monsoon@metoffice.gov.uk
Why am I asked for a password when logging in to mass-cli? There are two reasons that may result in you being prompted for a password when attempting to login to the MASS client machine (mass-cli.jasmin.ac.uk).
The first is if you do not have permission to access the machine. A quick method to check is to verify if you are a member of the moose user group. It should be listed when you use the ‘groups’ command:
[login1]$ groups mooseIf this happens, please contact: Monsoon@metoffice.gov.uk
The second is if you forget the -A option for agent forwarind when you ssh to a JASMIN login node. You can test for this condition by listing loaded identities on the login node, and finding you have none:
[login1]$ ssh-add -l Could not open a connection to your authentication agent.If this happens, please exit back to your local machine and ssh in again using the -A flag or tick the relevant box for &ldquo;agent forwarding&rdquo;.
How can I directly login to the MASS client machine? You can&rsquo;t, but you can edit your ssh configuration so that it automatically enables you to jump through the intermediary login servers.
Add the following to your home institute ssh config file ($HOME/.ssh/config file):
Host mass-cli User your_jasmin_userid HostName mass-cli.jasmin.ac.uk ProxyCommand ssh -YA -t your_jasmin_userid@login1.jasmin.ac.uk -W %h:%p 2&gt;/dev/nullYou should then be able to login directly using:
$ ssh mass-cliPlease note that this only works if you are using OpenSSH version 5.4 or greater as earlier versions do not support the -W flag. You can check your version using: ssh -v
MOOSE messages and what to do &nbsp; Is this process running in the correct environment? When running &lsquo;moo install&rsquo; you may get an error message similar to:
Cannot read file: /home/user/&lt;userid&gt;/.moosedir/moose - is this process running in the correct environment?This can be the result of the wrong combination of Unix user-id and UID having been used to encrypt the credentials file. If you encounter this error message, please type id on the command line whilst logged into JASMIN, and send the uid= section of the output to: Monsoon@metoffice.gov.uk
Your credentials file will then be reissued.
Your password is due to expire in X day(s). Occasionally on running a MOOSE command you will be told that your password is due to expire with a message of the form:
Your password is due to expire in 6 day(s). A new password can be generated using 'moo passwd -r'. This refers specifically to your MASS via JASMIN, it does not affect any other MOOSE accounts you may have.
You need to run the command as advised in order to update your credentials whilst you are logged into mass-cli. You do not actually need to provide a new password, as this is generated and hidden from you by the command.
If you have a retrieval in progress, it is safe to run this command as it will not affect processes already running.
ERROR_SINGLE_COPY_UNAVAILABLE MOOSE - Single Copy Unavailable error
On occasion, a tape library needs to be taken down for maintenance. If a user is trying to retrieve a single-copy file stored on one of those tapes, the retrieval will temporarily fail with the message ERROR_SINGLE_COPY_UNAVAILABLE. As soon as the maintenance is completed, the file will be available again.
Tapes are taken out of MASS for copying to the new MASS system and become unavailable for roughly 14 days. The process is as follows:
Thursday (week one): Tapes are marked unavailable for indexing by the system. Tuesday (week two): Tapes get taken out for copying to the new MASS system. Following Thursday (week three): Tapes are returned to Met Office library and should be available again. So, if you find that data or files are unavailable due to the ERROR_SINGLE_COPY_UNAVAILABLE error, try reading the data again on Friday, and if still not available, try the following Friday when the migration should have completed.
MOOSE basics &nbsp; What is MOOSE? The software that allows you to interact with MASS. What is a project? A collection of access rules. What is an access rule? Permission to access an area in MASS. For example, project-random might have an access rule to moose:/crum/random-numbers
Being part of project-random would allow you to access the random-numbers set.
How do I see what projects I am a member of? You can use: moo prls How do I see what access rules a project has? You can use: moo projinfo -l projectname (Replace projectname with the name of one of your projects) How do I get access to a project, or add an access rule to one of my projects? Please contact your sponsor. They can then complete this form if they also agree you require access:
https://metoffice.service-now.com/sp?id=sc_cat_item&sys_id=5653331e1bbaf0d88ffa422ad34bcba0&referrer=recent_items
Please note that the link above is only visible to those in the Met Office.
Why can I not access a set that I know is part of a project? If you are given access to a project but do not have access to all the sets associated with it, this can be due to the Access Control Lists (ACLs).
The project owner will be able to change the ACLs on sets to make them readable if it is appropriate.
How do I retrieve a file from MASS? Use moo get or moo select. More information about both commands is in the MOOSE User Guide. How do I make sure my directory has all the available data retrieved from MASS? The problem: You are running a model over a period of several days or weeks, and you need to analyse the output of the model as it runs. You have a moo get or moo select command that you run to fetch the data that is available. You want to be able to re-run it to fetch the files or fields that have been added to MASS since you last ran the command, but you do not want it to waste time re-fetching things you already have.
The solution: Use the -i or &ndash;fill-gaps option when you run moo get or moo select. This option tells MOOSE that you only want to fetch files that don&rsquo;t already exist in the specified local directory. Note that MASS works out where gaps are by doing checks to see if files of the expected name exist in your destination directory, so it won&rsquo;t behave correctly if you rename files after you have retrieved them, or if you use the -C option with moo select which condenses all the matching fields into a single file.
You might also find the -g / --get-if-available option to moo get useful. This tells MOOSE to get every file from your moo get list that is available, but ignore ones that are not there rather than exit with an error. This could help if you are expecting files to be archived at some point but are not sure whether they will be there when your job runs. If you use this option MOOSE will get as much as it can from your list without bailing out.
How can I script my data retrieval from MASS? There are restrictions on how to login to JASMIN and use of Linux utilities such as ‘cron’ and ‘at’ but it is possible to remotely initiate a retrieval from MASS on to JASMIN, provided you have your ssh agent running on a machine local to you.
eval $(ssh-agent -s) ssh-add ~/.ssh/jasmin_id_rsa ssh -A -X sci1.jasmin.ac.uk &#39;ssh mass-cli my_script.sh&#39;If you have set up your $HOME/.ssh/config to allow more direct access, then the following should work:
ssh mass-cli my_script.shThis will run the script “my_script.sh” on the MASS client VM. You can put the moose retrieval commands into a script and it should work:
#!/bin/bash SRC_URI=moose:/opfc/atm/global/SOMETHING moo get $SRC_URI jasmin_copy.pp exitIf you have access to an appropriate JASMIN workspace, then you can scp data from the workspace directly through one of the dedicated data transfer VMs. Again, you need the ssh-agent running locally:
eval $(ssh-agent -s) ssh-add ~/.ssh/jasmin_id_rsa scp userid@xfer1.jasmin.ac.uk:/group_workspaces/cems/&lt;project&gt;/jasmin_file.pp my_local_copy.pp Can I run MASS retrievals on LOTUS or through a workload manager? In addition to the interactive mass-cli server there is also the moose1 server that is only accessible through the
&lt;a href=&quot;/docs/batch-computing/lotus-overview/&quot;&gt;LOTUS batch processing cluster&lt;/a&gt;. To submit jobs to moose1 you must use the [SLURM scheduler](https://help.jasmin.ac.uk/docs/batch-computing/slurm-scheduler-overview/). You will need to specify the account mass and partition mass, for example:
sbatch -A mass -p mass [&lt;options&gt;] &lt;jobscript&gt;where &lt;jobscript&gt; looks something like:
#!/bin/bash SRC_URI=moose:/opfc/atm/global/SOMETHING moo get $SRC_URI jasmin_copy.pp exitIt is also easy to configure the Rose/Cylc workflow manager to submit jobs to moose1 through the SLURM scheduler by including the following lines in your suite.rc file:
[[[job submission]]] method = slurm [[[directives]]] --partition=mass --account=mass [&lt;options&gt;]`}).add({id:63,tag:"en",href:"/tags/filezilla/",title:"Filezilla",description:"",content:""}).add({id:64,tag:"en",href:"/docs/for-cloud-tenants/",title:"For Cloud Tenants",description:"How to use your tenancy in the JASMIN Community Cloud",content:""}).add({id:65,tag:"en",href:"/docs/data-transfer/ftp-and-lftp/",title:"ftp and lftp",description:"Data Transfer Tools: ftp and lftp",content:`This article provides information about FTP (File Transfer Protocol) as a data transfer tool. In particular:
what is FTP? where and how can I use FTP on JASMIN? what are its limitations? What is FTP? &nbsp; FTP is a well-established transfer protocol enabling connections from a client to download files from, or upload files to, a server, although limited in security. A wide variety of client tools are available to the user, 2 implementations of which are available on the JASMIN transfer servers, although no server is provided. ftp is also the name of the basic FTP client program, see below.
Where and how can I use FTP on JASMIN? &nbsp; FTP can only be used as a client on JASMIN, to pull data from external FTP servers to local storage on JASMIN, for example a Group Workspace or your home directory. There is no FTP server within JASMIN providing the ability to upload files to these locations. Please use an alternative, more secure method instead. See other Data Transfer Tools such as scp/rsync/sftp, bbcp or GridFTP (over SSH, certificate-based or using Globus Online)
On the transfer servers, you can use one of the installed FTP clients to download data from elsewhere. These are:
ftp basic ftp client. Usage details lftp parallel-capable ftp client. Usage details CEDA however runs 2 FTP servers within the JASMIN environment providing download-only access to the CEDA archive. Access to these is controlled by your CEDA account and any dataset-specific privileges which are associated with that account.
What are its limitations? &nbsp; FTP was never designed as a secure protocol and has several limitations affecting how it can be used safely within an environment like JASMIN. Some external sites offer anonymous FTP download. In this case, no username or password needs to be exchanged and (as long as the data resources do not need to be protected in any way) this can provide a simple but effective data transfer method. Few external sites now provide FTP access to protected data resources, hence many data-intensive institutions are now focussing on more sophisticated data delivery methods which can meet the demands of security and performance in a multi-user environment. Basic client usage: ftp &nbsp; The ftp client is available on the transfer servers xfer[123].jasmin.ac.uk
Example 1: Downloading a file to a location on JASMIN from a remote FTP server.
This involves setting up an interactive client session. Once logged in (in this case, using anonymous FTP), you use FTP commands to interact with the remote server and locate and download the data you require. The session is terminated with bye.
ftp someserver.somesite.ac.uk Trying 123.456.78.123... Connected to someserver.somesite.ac.uk (123.456.78.123). 220---------------------------------------------------------------------------- 220-Welcome message from somesite.ac.uk 220---------------------------------------------------------------------------- 220 Name (123.456.78.123:username): anonymous 331 Please specify the password. Password: Once connected, the prompt changes to ftp&gt;:
230 Login successful. Remote system type is UNIX. Using binary mode to transfer files. cd /sites/pub/testdir/ (out)(out)250- 250-This is the somesite ftp repository. 250- 250 Directory successfully changed. get md5.sum local: md5.sum remote: md5.sum 227 Entering Passive Mode. 150 Opening BINARY mode data connection for md5.sum (45 bytes). 226 Transfer complete. 45 bytes received in 0.00267 secs (16.83 Kbytes/sec) bye 221 Goodbye. Full details of commands available within an interactive session with the ftp client are available via the man page (man ftp).
Parallel-capable client usage: lftp &nbsp; The alternative client lftp is less verbose, but the basic workflow is the same.
lftp someserver.somesite.ac.uk Once connected, the prompt changes to lftp and the name of the remote server:
cd /sites/pub/testdir cd ok, cwd=/sites/pub/testdir/ get md5.sum 45 bytes transferred bye The interactive shell provided by lftp also benefits from tab completion and use of up/down arrows for command history.
In fact, lftp can also be used as an SFTP client, with the added benefit that it can handle multiple SFTP transfers in parallel.
In the following example, we connect to a remote SFTP server using the sftp:// syntax. Once logged in to the remote server, the prompt changes and you can enter lftp-specific commands like mirror, in this case with -P 4 as the option to use 4 sftp processes in parallel. Try other values but please consider other users so a suggested limit is 16.
lftp sftp://username@someserver.somesite.ac.uk Password: (enter password when prompted) mirror -P 4 sourcedata bye Note that if you&rsquo;re connecting to a JASMIN transfer server in this way, then you would need to make your JASMIN private key available in an ssh agent locally, and you would not be prompted for the password.`}).add({id:66,tag:"en",href:"/docs/getting-started/generate-ssh-key-pair/",title:"Generate an SSH key pair",description:"Generate an SSH key pair",content:`This article explains how to create an SSH key pair for logging in to JASMIN.
You can also use this procedure to update an existing SSH key pair for JASMIN. However, if you are experiencing problems logging in to JASMIN you are advised to first check Login problems before changing your key. Once you have created your SSH key pair it will need to be uploaded to the JASMIN accounts portal. If this is the first time you have created a key pair then this will be done when you create an account on the portal (Step 2 of Get Started with JASMIN). If you are updating your key for an existing account then you will need to update it in your JASMIN profile.
The shell terminal &nbsp; Generating an SSH key pair requires an SSH client and a Shell terminal. Linux and Mac users can use a standard terminal which is very likely to have SSH installed. Windows users are advised to install the MobaXterm application which provides a linux-style terminal with all the relevant utilities included. Figures 1 and 2 show example terminal windows on a Mac and Windows (using MobaXterm).
Mac terminal Terminal using Mobaxterm client on Windows Using ssh-keygen to create an SSH key pair &nbsp; The Linux command ssh-keygen should be used to generate your SSH key pair. Open a terminal and generate your public and private key, as follows (replace the e-mail address with your own):
ssh-keygen -t rsa -b 2048 -C &#34;me@somewhere.ac.uk&#34; -f ~/.ssh/id_rsa_jasmin At the prompt, type a secure passphrase to protect your SSH private key. This is a requirement for access to JASMIN machines. Use a new, different passphrase whenever you generate a new key. Note that nothing is echoed to the screen when you enter your passphrase, so it may look like it is not working.
The output will look something like this: Generating public/private rsa key pair. Enter passphrase (empty for no passphrase): &lt;ADD PASSPHRASE HERE&gt; Enter same passphrase again: &lt;REPEAT PASSPHRASE HERE&gt; Your identification has been saved in /home/users/meuser/.ssh/id_rsa_jasmin. Your public key has been saved in /home/users/meuser/.ssh/id_rsa_jasmin.pub. The key fingerprint is: 74:14:95:8a:31:73:cc:5c:af:be:91:04:01:c2:39:0b me@somewhere.ac.uk Running ssh-keygen will generate two files in your $HOME/.ssh/ directory:
id_rsa_jasmin - private key file (which should have permission &ldquo;400&rdquo;, i.e. readable only by you) id_rsa_jasmin.pub - public key file The public key file is the part that you need to share in order to access JASMIN. The private key file should be protected and not shared with others.
Converting a PuTTYGen SSH private key for use with MobaXterm (Windows only) &nbsp; If you have previously used the PuTTY utilities to login to JASMIN and you wish to move over to using MobaXterm then please see these instructions to convert your SSH private key from the PuTTYGen format to the OpenSSH format (as used by Linux/Mac). Please save your resulting OpenSSH key as id_rsa_jasmin in your $HOME/.ssh/ directory.`}).add({id:67,tag:"en",href:"/docs/software-on-jasmin/geocat-replaces-ncl/",title:"Geocat replaces NCL",description:"GeoCat - replaces NCAR Command Language (NCL)",content:`Introduction &nbsp; This article introduces geocat&nbsp; as a replacement on JASMIN for NCAR Command Language (NCL) which is now deprecated.
NCL now deprecated &nbsp; NCL is now deprecated by NCAR (see this announcement), there is no Rocky 9 version available, so we will not be providing it when JASMIN moves from CentOS to using Rocky 9 in the next few months. The plan is to add to Jaspy the geocat-viz package, which is NCAR&rsquo;s Python replacement for NCL.
Installation in a conda environment &nbsp; To give you a chance now to familiarise yourself with geocat-viz, here are some instructions for how you could install it in a Conda environment under your own home directory.
&nbsp; Note that such an environment cannot be activated at the same time as Jaspy. Total disk space required is 3.2GB.
Commands marked with #* below will be needed again in order to activate the environment in later sessions.
Deactivate jaspy in this session:
module unload jaspy #* Download miniforge installer:
wget &lt;https://github.com/conda-forge/miniforge/releases/latest/download/Miniforge3-Linux-x86_64.sh&gt; Install base environment:
bash Miniforge3-Linux-x86_64.sh Accept the default answers to the questions, saying no to the question about conda init.
Activate the base environment:
source ~/miniforge3/bin/activate #* Create and activate an environment:
mamba create -n my-geocat-env conda activate my-geocat-env #* Install the packages:
mamba install geocat-viz geocat-datafiles Try one of the examples from:
https://geocat-examples.readthedocs.io/en/latest/gallery/index.html
wget https://geocat-examples.readthedocs.io/en/latest/_downloads/efafc109e5344e8e33052ad5213ee4be/NCL_box_1.py python NCL_box_1.py (should display a plot)
Full documentation is at https://geocat-viz.readthedocs.io/en/latest/`}).add({id:68,tag:"en",href:"/docs/getting-started/get-jasmin-portal-account/",title:"Get a JASMIN portal account",description:"Get a JASMIN portal account",content:`This article explains how to register on the JASMIN accounts portal.
Having a jasmin portal account does not by itself provide you with any access to JASMIN machines or services.
JASMIN accounts portal &nbsp; The JASMIN accounts portal is the place where you manage your JASMIN account and can apply for access to the many services which you may want to use on JASMIN.
JASMIN accounts portal Apply for a new JASMIN account &nbsp; To apply for a JASMIN account you need to use an email address affiliated with your academic institution. Then proceed as follows:
Step 1 : On JASMIN accounts portal select &ldquo;Apply for a new JASMIN account&rdquo;. This will take you to the following page to enter your details.
Application details page Step 2 : Select your research discipline.
Research discipline Step 3 : Select the institution you are affiliated with. If your institution is not listed, you can add new institution details by clicking the plus button. Remember to provide supporting information to assess your eligibility for a JASMIN account and then submit your application
Select institution Step 4 : Follow the URL link sent to your email address. Once your email has been verified, you will receive a second email with a subject &lsquo;Application approved&rsquo; inviting you to complete the account creation. This link will take you to the following page where you have to choose your JASMIN account credentials, register your SSH public key and then click Create account
Create account Step 5 : An example of registering SSH public key
Add public key Step 6 : Agree to the JASMIN Terms and Conditions of Access
Accept conditions of use Step 7 : Your JASMIN account is created and you can log in using your credentials
Try login`}).add({id:69,tag:"en",href:"/docs/getting-started/get-login-account/",title:"Get a login account",description:"Get a login account",content:`This article explains how to apply for access to the shared JASMIN servers.
Get a login account &nbsp; A user with a jasmin-login account is allocated a HOME directory of 100GB and can access the shared JASMIN servers (Scientific servers, data transfer servers) and the LOTUS batch cluster. Sign in into your JASMIN accounts portal where you can apply for a JASMIN login account representing the JASMIN access role appropriate to your affiliation.
Sign in Step 1: Select Login services and navigate to the &lsquo;More information&rsquo; on this service
More information Step 2: Apply for access to jasmin-login service
Apply for jasmin-login Step 3: Provide supporting information
Provide supporting information Step 4: Your request is pending for approval
Request pending Step 4: Upon approval, a notification email is sent to you. Additionally, a notification counter in the bell will appear on the top left corner of the menu bar on your JASMIN account portal page. You have now access to the login server and to the scientific servers
Notification Under &lsquo;My Services&rsquo; you can view all the services that you currently have access to or have requested access for. Note: Every time a notification is acknowledged the counter is reset or decremented.
Now you can proceed to How to login`}).add({id:70,tag:"en",href:"/docs/getting-started/get-started-with-jasmin/",title:"Get Started with JASMIN",description:"Get Started with JASMIN",content:`This article explains the steps involved for most users to gain access to the JASMIN environment.
The JASMIN&nbsp; scientific data analysis environment is administered by CEDA&nbsp; and supports a wide variety of scientific workflows across environmental science domains.
Essential steps &nbsp; The steps listed in Table 1 (below) are required for scientific end-users to gain ssh access to the JASMIN login machines which are the &ldquo;front door&rdquo; for most users. Other services are available once these basic steps have been completed.
An overview of JASMIN compute &amp; storage components is given in the presentation given at the JASMIN workshop - we strongly encourage all new users to watch this video recording and take a look at the accompanying exercises. These go into detail about all the basic things you may want to do with JASMIN.
Table 1. Steps involved for a scientific end-user to gain login access to JASMIN. Click on the links under the &lsquo;Details&rsquo; column to find instructions for each step.
Step Details Comments 1 Generate an SSH key Create this locally, ready to upload it to your JASMIN Account profile 2 Get a JASMIN portal account Access to JASMIN services is controlled by the JASMIN Accounts Portal - you must register for an account. Using this portal, you will then need to apply for access to the JASMIN services and privileges you require (as described in the steps below). Some of these services will require manual approval by individuals external to the CEDA/JASMIN team. Creating a JASMIN portal account does not by itself provide you with any access to JASMIN machines or services. You must complete all the steps below to gain full access. 3 Check network details Check details of your network connection to JASMIN to ensure you are able to connect. In order to maintain a secure and reliable scientific infrastructure for its users, JASMIN restricts login access by maintaining an &ldquo;allow list&rdquo; of network domains. 4 Request ssh login access to JASMIN Apply for the jasmin-login service, which will allow you to connect to JASMIN machines using ssh. 5 Apply for access to additional services on JASMIN JASMIN has a range of additional services, access to which is managed via the Accounts Portal. Search and apply for any services you require in the portal. In most cases, users will &ldquo;belong&rdquo; to a particular scientific project which may already have a presence on JASMIN, often in the form of a Group Workspace. See here how to Apply for access to a Group Workspace. 6 How to login Follow these steps for logging in to JASMIN via ssh, but we also have several other tutorials that may be useful - see Exercises 1-3 here. 7 Get a CEDA account The CEDA Archive provides access to thousands of atmospheric, climate change, and earth observation datasets. The Archive is directly accessible read-only throughout JASMIN. Some datasets on the CEDA Archive require specific agreements, and to apply for access to these, you will need a CEDA account. 8 Link your JASMIN and CEDA accounts The final step is to link your CEDA account to your JASMIN account. This allows you filesystem access to data on CEDA Archive. This is a step that you will be guided through in the JASMIN accounts portal. The table above describes the initial steps to get you started on JASMIN - however, there are a variety of ways that users can get the most out of JASMIN, that are not described in the table. Users are strongly encouraged to read further about JASMIN, and/or to discuss with scientific colleagues to gain an understanding of the resources available.
The documentation in this site is split into sections, based on different areas/services on JASMIN. You can navigate these sections in the menu on the left-hand side of your screen. A short description of each of these sections is below:
Getting Started - this details all the steps needed to get started on JASMIN. Most documents are linked to from the table above, but there may be some other useful information there too. Interactive Computing - this introduces the resources on JASMIN available for interactive computing. This type of computing is the most common workflow on JASMIN for new users. LOTUS batch processing cluster - this introduces the available resources on JASMIN for batch computing. Software on JASMIN - Information on running software packages within JASMIN Data Transfer - this category includes guidance on transferring data to and from JASMIN. MASS - JASMIN has Read-only access to the Met Office MASS storage archive. This section explains how to get access. Short-term project storage - this section introduces the concept of shared Group Workspaces and the different storage types on JASMIN. Group Workspaces (GWSs) are portions of disk allocated for particular projects to manage themselves, enabling collaborating scientists to share network accessible storage on JASMIN. Long-term archive storage - this section describes the long-term CEDA Archive which consists of thousands of atmospheric, climate change, and earth observation datasets. This is directly accessible as a file system from the shared science machines on JASMIN. For Cloud Tenants - JASMIN also provides a cloud computing service, this section describes this. Workflow management - this category details the various tools available for managing your workflow. The CEDA team also regularly hosts training workshops and events. Details about past and future events can be found on the events section of the CEDA website.`}).add({id:71,tag:"en",href:"/docs/getting-started/",title:"Getting Started",description:"Key things to know to get you started on JASMIN",content:""}).add({id:72,tag:"en",href:"/docs/data-transfer/globus-command-line-interface/",title:"Globus Command-Line Interface",description:"Data Transfer Tools: Using the Globus Command-Line Interface",content:`&nbsp; Updated for new JASMIN Default Collection (replaces previous JASMIN Globus Endpoint) This article describes
how to transfer data using the Globus Command Line Interface. It covers: how an end-user can set up their host (laptop, desktop or home directory on their departmental server) with the Globus Command-Line Interface (CLI) examples of common tasks using the CLI It is not necessary to use the Globus CLI on a JASMIN server: it is a tool that you can use anywhere (for example your own desktop/laptop) to interact with the Globus service, to orchestrate a transfer between 2 endpoints (collections, in new Globus terminology). The CLI is not centrally installed on JASMIN, and does not need to be in the same place as either of the 2 collections involved in the transfer. The fact that one of those collections is the JASMIN collection does not mean that you need to be on JASMIN to orchestrate the transfer: you could use the CLI on your own laptop/desktop, even if the 2 collections were 2 institutional Globus collections on opposite sides of the world. You could of course decide to install the CLI in your home directory on JASMIN if that were useful as part of your processing/data transfer workflow.
The Globus CLI is fully documented here with examples. It provides a command-line interface for managed transfers via the Globus cloud-based transfer service, which usually achieves the best possible transfer rate over a given route compared to other methods. Typically this will be significantly faster than can be achieved over scp, rsync or sftp transfers, particularly if the physical network path is long.
The Globus CLI is designed for use either interactively within an interactive shell or in scripts. An alternative Python software development kit (SDK) is also available and should be considered for more sophisticated workflows.
Alternatively, the Globus web interface at https://app.globus.org can be used as an easy-to-use interface to orchestrate transfers interactively.
Whichever method is used: CLI, SDK or web interface, transfers are invoked as asynchronous, managed tasks which can then be monitored, and if need be set to retry automatically until some pre-set deadline.
Prerequisites &nbsp; Linux environment with normal user privileges, or Mac environment with ability to install applications, or Windows environment with ability to install applications Python environment for that platform, with ability to create virtual environments (to enable installation of additional packages) For use of the JASMIN Default Collection: An active JASMIN user account, with “jasmin-login” role You may also wish to set up your own Globus endpoint using Globus Connect Personal, though this is not needed for these examples. Initial Setup &nbsp; Get a Globus identity &nbsp; Go to https://app.globus.org and either:
choose one of the listed identity providers (e.g. GitHub, Google, &hellip;) follow the link at the bottom to &ldquo;use Globus ID to sign in&rdquo; See also https://docs.globus.org/how-to/get-started/
Set up the Globus CLI on your machine &nbsp; Do the following on your own (local) machine. Make a Python virtual environment and activate it:
python3 -m venv ./venv source ./venv/bin/activate Download the Globus CLI and install it into the virtual environment ( venv).
pip install globus-cli Try the globus login command. The first time you run this, you will be prompted to authorise the Globus CLI to carry out operations on behalf of your Globus ID. The URL will open in your default browser, where you should authenticate with your Globus ID credentials. If you prefer, you can copy/paste the URL from the command-line to a browser of your choice. Either way, you then need to click &ldquo;Allow&rdquo; in the browser window, then copy/paste the resulting &ldquo;Native App Authorization Code&rdquo; back to the terminal window where you issued the globus login command:
globus login --no-local-server Please authenticate with Globus here: ------------------------------------ https://auth.globus.org/v2/oauth2/authorize?client_id=abc1234-9c3c-4ad42-be31-8d6c87101239014&amp;redirect_uri=https%3A%2F%2Fauth.globus.org%2Fv2%2Fweb%2Fauth-code&amp;scope=openid+profile+email+urn%3Aglobus%3Aauth%3Ascope%3Aauth.globus.org%3Aview_identity_set+urn%3Aglobus%3Aauth%3Ascope%3Atransfer.api.globus.org%3Aall+urn%3Aglobus%3Aauth%3Ascope%3Agroups.api.globus.org%3Aall+urn%3Aglobus%3Aauth%3Ascope%3Asearch.api.globus.org%3Aall&amp;state=_default&amp;response_type=code&amp;access_type=offline&amp;prompt=login ------------------------------------ Enter the resulting Authorization Code here: You should then see the following:
You have successfully logged in to the Globus CLI! You can check your primary identity with globus whoami For information on which of your identities are in session use globus session show Logout of the Globus CLI with globus logout You can now use the Globus CLI commands as listed by the following command:
globus --help Usage: globus [OPTIONS] COMMAND [ARGS]... Interact with Globus from the command line All \`globus\` subcommands support \`--help\` documentation. Use \`globus login\` to get started! The documentation is also online at https://docs.globus.org/cli/ Options: -v, --verbose Control level of output -h, --help Show this message and exit. -F, --format [unix|json|text] Output format for stdout. Defaults to text --jmespath, --jq TEXT A JMESPath expression to apply to json output. Takes precedence over any specified &#39; --format&#39; and forces the format to be json processed by this expression --map-http-status TEXT Map HTTP statuses to any of these exit codes: 0,1,50-99. e.g. &#34;404=50,403=51&#34; Commands: bookmark Manage endpoint bookmarks collection Manage your Collections delete Submit a delete task (asynchronous) endpoint Manage Globus endpoint definitions get-identities Lookup Globus Auth Identities group Manage Globus Groups list-commands List all CLI Commands login Log into Globus to get credentials for the Globus CLI logout Logout of the Globus CLI ls List endpoint directory contents mkdir Create a directory on an endpoint rename Rename a file or directory on an endpoint rm Delete a single path; wait for it to complete search Use Globus Search to store and query for data session Manage your CLI auth session task Manage asynchronous tasks transfer Submit a transfer task (asynchronous) update Update the Globus CLI to its latest version version Show the version and exit whoami Show the currently logged-in identity Examples &nbsp; Find an endpoint (aka collection) We will use the globus endpoint search subcommand. Find help on the particular options for that with
globus endpoint search --help Usage: globus endpoint search [OPTIONS] [FILTER_FULLTEXT] Search for Globus endpoints with search filters. If --filter-scope is set to the default of &#39;all&#39;, then FILTER_FULLTEXT is required. If FILTER_FULLTEXT is given, endpoints which have attributes (display name, legacy name, description, organization, department, keywords) that match the search text will be returned. The result size limit is 100 endpoints. Options: --filter-scope [all|administered-by-me|my-endpoints|my-gcp-endpoints|recently-used|in-use|shared-by-me|shared-with-me] The set of endpoints to search over. [default: all] --filter-owner-id TEXT Filter search results to endpoints owned by a specific identity. Can be the Identity ID, or the Identity Username, as in &#34;go@globusid.org&#34; --limit INTEGER RANGE The maximum number of results to return. [default: 25; 1&lt;=x&lt;=1000] -v, --verbose Control level of output -h, --help Show this message and exit. -F, --format [unix|json|text] Output format for stdout. Defaults to text --jmespath, --jq TEXT A JMESPath expression to apply to json output. Takes precedence over any specified &#39;--format&#39; and forces the format to be json processed by this expression --map-http-status TEXT Map HTTP statuses to any of these exit codes: 0,1,50-99. e.g. &#34;404=50,403=51&#34; Search for the collections matching the search term &ldquo;tutorial&rdquo;:
globus endpoint search &#34;tutorial&#34; ID | Owner | Display Name ------------------------------------ | ------------------------------------------------------------ | ---------------------------------------------- 6c54cade-bde5-45c1-bdea-f4bd71dba2cc | 6df1b656-c953-40a3-91a9-e9e8ad5173ea@clients.auth.globus.org | Globus Tutorial Collection 1 31ce9ba0-176d-45a5-add3-f37d233ba47d | 6df1b656-c953-40a3-91a9-e9e8ad5173ea@clients.auth.globus.org | Globus Tutorial Collection 2 The 2 globus tutorial collections actually &ldquo;see&rdquo; the same filesystem, so we&rsquo;ll just use the first one.
For convenience, let&rsquo;s set environment variables representing the ID of this collection:
export c1=6c54cade-bde5-45c1-bdea-f4bd71dba2cc echo $c1 6c54cade-bde5-45c1-bdea-f4bd71dba2cc Let&rsquo;s try listing that collection, so that we know we can interact with it. We are prompted to grant consent first: globus ls $c1 The collection you are trying to access data on requires you to grant consent for the Globus CLI to access it. Please run: globus session consent &#39;urn:globus:auth:scope:transfer.api.globus.org:all[*https://auth.globus.org/scopes/6c54cade-bde5-45c1-bdea-f4bd71dba2cc/data_access]&#39; to login with the required scopes. Copy &amp; paste the command it gives you (don&rsquo;t copy the one above) and run it, which should open a web browser window. Follow the instructions which should complete the process, then return to your terminal session.
Now let&rsquo;s find another collection, this time a public test collection which can be used for performance testing:
globus endpoint search &#34;star dtn&#34; ID | Owner | Display Name ------------------------------------ | ------------------ | ------------------------------------------------- ff2ee779-54fb-4dac-ade2-57568c587ae3 | esnet@globusid.org | ESnet STAR DTN private collection ece400da-0182-4777-91d6-27a1808f8371 | esnet@globusid.org | ESnet Starlight DTN (Anonymous read only testing) e9e0d9f4-c419-44e0-8198-017fd61bf0c4 | esnet@globusid.org | ESnet Starlight DTN (read-write testing) We&rsquo;ll use the one labelled Anonymous read only testing. Set stardtn to the ID of this endpoint:
export stardtn=ece400da-0182-4777-91d6-27a1808f8371 &nbsp; None of the endpoints mentioned so far require authentication in order to use them. This makes demonstrating basic functionality simpler, but we&rsquo;ll look at how to use one that does, later. Listing files at a path on an collection Use the endpoint ls command to list the contents of the stardtn endpoint, at the path /
globus ls $stardtn:/ 500GB-in-large-files/ 50GB-in-medium-files/ 5GB-in-small-files/ 5MB-in-tiny-files/ Climate-Huge/ Climate-Large/ Climate-Medium/ Climate-Small/ bebop/ logs/ write-testing/ 100G.dat 100M.dat 10G.dat 10M.dat 1G.dat 1M.dat 500G.dat 50G.dat 50M.dat These are files and directories containing dummy data which can be used for test purposes.
Copy a file from one endpoint to another Let&rsquo;s transfer the file 1M.dat from the stardtn endpoint to c1:
globus transfer $stardtn:/1M.dat $c1:/~/1M.dat Message: The transfer has been accepted and a task has been created and queued for execution Task ID: 74cb181c-bf63-11ee-a90e-032e06ca0965 The transfer task is a separate activity and does not require any connection from the CLI client to either of the 2 endpoints: the Globus transfer service manages the transfer for us. We can check on the progress of this transfer task with:
globus task show 74cb181c-bf63-11ee-a90e-032e06ca0965 Label: None Task ID: 74cb181c-bf63-11ee-a90e-032e06ca0965 Is Paused: False Type: TRANSFER Directories: 0 Files: 1 Status: SUCCEEDED Request Time: 2024-01-30T11:33:58+00:00 Faults: 0 Total Subtasks: 2 Subtasks Succeeded: 2 Subtasks Pending: 0 Subtasks Retrying: 0 Subtasks Failed: 0 Subtasks Canceled: 0 Subtasks Expired: 0 Subtasks with Skipped Errors: 0 Completion Time: 2024-01-30T11:34:01+00:00 Source Endpoint: ESnet Starlight DTN (Anonymous read only testing) Source Endpoint ID: ece400da-0182-4777-91d6-27a1808f8371 Destination Endpoint: Globus Tutorial Collection 1 Destination Endpoint ID: 6c54cade-bde5-45c1-bdea-f4bd71dba2cc Bytes Transferred: 1000000 Bytes Per Second: 421388 We can also list the destination collection to check that the file has reached its destination:
globus ls $c1:/~/ 1M.dat We can also make a subdirectory with mkdir: globus mkdir $c1:/~/mydata/ The directory was created successfully We can move our 1M.dat into that directory with a globus rename command globus rename $c1 /~/1M.dat /~/mydata/1M.dat File or directory renamed successfully We now have a directory mydata containing files 1M.dat:
globus ls $c1:/~/mydata/ 1M.dat Recursively copy a directory and its contents, from one endpoint to another Now Let&rsquo;s copy a directory from the stardtn collection which contains some small files, to our destination endpoint c1 (The Globus tutorial collections only provide very limited storage space).
The files we want to copy are at the path /5MB-in-tiny-files/a/a/ on the stardtn endpoint, and are small, as their names suggest:
globus ls $stardtn:/5MB-in-tiny-files/a/a/ a-a-1KB.dat a-a-2KB.dat a-a-5KB.dat Copy the parent directory recursively to ep1:
globus transfer -r $stardtn:/5MB-in-tiny-files/a/a $c1:/~/star-data Message: The transfer has been accepted and a task has been created and queued for execution Task ID: 4ae9bab0-7d40-11ec-bef3-a18800fa5978 Check destination content:
globus ls $c1 mydata1/ star-data/ globus ls $c1:/~/star-data a-a-1KB.dat a-a-2KB.dat a-a-5KB.dat We could now delete one of the small files using the globus delete command: globus delete $c1:/~/star-data/a-a-2KB.dat Message: The delete has been accepted and a task has been created and queued for execution Task ID: be4d6934-7d40-11ec-891f-939ceb6dfaf1 And list contents again, to verify that it has been deleted:
globus ls $c1:/~/star-data a-a-1KB.dat a-a-5KB.dat Sync a source directory to a target (repeatable) We could now repeat the copying of the source data, but this time using the -s or --sync-level exists command so that we only copy the data that is now missing from the destination. The full set of sync options is [exists|size|mtime|checksum].
globus transfer -s exists -r $stardtn:/5MB-in-tiny-files/a/a $c1:/~/star-data Message: The transfer has been accepted and a task has been created and queued for execution Task ID: 759a3cac-7d41-11ec-bef3-a18800fa5978 This should only copy the data that do not already exist at the desination: We end up with the same set of files at the destination:
globus ls $c1:/~/star-data a-a-1KB.dat a-a-2KB.dat a-a-5KB.dat But we can see that only 2000 bytes were transferred (so we know it only copied that one file, which is what we wanted):
globus task show 759a3cac-7d41-11ec-bef3-a18800fa5978 Label: None Task ID: 759a3cac-7d41-11ec-bef3-a18800fa5978 Is Paused: False Type: TRANSFER Directories: 1 Files: 3 Status: SUCCEEDED Request Time: 2022-01-24T18:14:24+00:00 Faults: 0 Total Subtasks: 5 Subtasks Succeeded: 5 Subtasks Pending: 0 Subtasks Retrying: 0 Subtasks Failed: 0 Subtasks Canceled: 0 Subtasks Expired: 0 Subtasks with Skipped Errors: 0 Completion Time: 2022-01-24T18:14:58+00:00 Source Endpoint: ESnet Starlight DTN (Anonymous read only testing) Source Endpoint ID: ece400da-0182-4777-91d6-27a1808f8371 Destination Endpoint: Globus Tutorial Collection 1 Destination Endpoint ID: 6c54cade-bde5-45c1-bdea-f4bd71dba2cc Bytes Transferred: 2000 Bytes Per Second: 60 This task could be repeated in a shell script, cron job or even using the Globus timer functionality, for either a source or destination directory that is expected to change.
Interact with a collection that requires authentication Most Globus Connect Server endpoints are configured to require some form of authentication &amp; authorization process. In the case of the JASMIN Default Collection, you link your Globus identity to your JASMIN identity. This may be different for other collections that you use elsewhere.
Let&rsquo;s find, then set up an alias to the JASMIN Default Collection Endpoint. We can search for that name:
globus endpoint search &#34;jasmin default&#34; ID | Owner | Display Name ------------------------------------ | ------------------------------------------------------------ | ------------------------- a2f53b7f-1b4e-4dce-9b7c-349ae760fee0 | a77928d3-f601-40bb-b497-2a31092f8878@clients.auth.globus.org | JASMIN Default Collection Set up an alias for this collection:
export jdc=a2f53b7f-1b4e-4dce-9b7c-349ae760fee0 If you&rsquo;ve already interacted with this collection recently, you should find that you can list it with the CLI already. If not, you will be prompted to authenticate. Follow through all the steps until you complete the process, then return to the terminal session.
If successful, you can now interact with the JASMIN endpoint, for example listing your home directory:
globus ls $jdc:/~/ ... (file listing of your JASMIN home directory) ... The authentication via your JASMIN account lasts for 30 days, so you can run and re-run transfers during that period without needing to repeat the process (hence without any human interaction, if you have scheduled/automated transfers, see below).
If this needs to be renewed, then:
the simple way to do this is to either:
(manually) visit the Globus web interface and access the JASMIN Default Collection again (manuall) use the CLI to list the collection again In either case, if the authentication has timed out, you will be prompted to follow instructions to renew it, then the action (listing the directory) should complete successfully.
There are ways to do use a &ldquo;refresh token&rdquo; programatically to renew the authentication. Watch this space for details of how to do that (or f)
Automation &nbsp; The functionality demonstrated above can be combined into scripts which can perform useful, repeatable tasks such as:
recursively syncing the contents of directories between 2 endpoints Globus provide 2 implementations of this here:
Examples of automation using the Globus CLI, specifically:
cli-sync.sh : bash script using the Globus CLI as demonstrated above globus_folder_sync.py : Python code using the Globus Python Software Development Kit (SDK) We have not covered the Python SDK here, but this is a useful example of how you could integrate Globus transfer functionality into your own code and workflows. You would need to install and authorise this SDK first.
Taking the first of these examples, we can adapt it slightly:
1. Select the JASMIN endpoint at the destination, and set the destination path. Modify the corresponding variables in the script to these values:
DESTINATION_COLLECTION=&#39;a2f53b7f-1b4e-4dce-9b7c-349ae760fee0&#39; #JASMIN Default Collection ID DESTINATION_PATH=&#39;/home/users/&lt;username&gt;/sync-demo/&#39; #replace &lt;username&gt; with your JASMIN username 2. If you haven&rsquo;t already, activate the Python virtual environment where you have the CLI installed, and login:
source ~/.globus-cli-venv/bin/activate globus login 3. Check that you can interact with the JASMIN collection from the CLI, by trying to list it
Follow any instructions needed, if you need to renew your authentication.
4. Run the script to sync the data from the Globus Tutorial Endpoint to the destination directory.
You should see output similar to that shown below.
./cli-sync.sh Checking for a previous transfer Last transfer f5db7238-8f06-11ec-8fe0-dfc5b31adbac SUCCEEDED, continuing Verified that source is a directory Submitted sync from 6c54cade-bde5-45c1-bdea-f4bd71dba2cc:/share/godata/ to a2f53b7f-1b4e-4dce-9b7c-349ae760fee0:/~/sync-demo/ Link: https://app.globus.org/activity/04e277f4-8f07-11ec-811e-493dd0cf73a1/overview Saving sync transfer ID to last-transfer-id.txt 5. Check on the status of the task. You could do this by
following the URL to https://app.globus.org to view the task under &ldquo;activities&rdquo;, or globus task show &lt;taskid&gt; 6. You could then make some change to either source or destination directory, and simply re-run the script
./cli-sync.sh 7. Experiment by changing the SYNCTYPE. Other options are:
See here for descriptions of the available sync levels:
EXISTS SIZE MTYPE CHECKSUM 8. Automating repeats of the sync operation
You could then consider how to repeat the task automatically. For example:
triggering a re-run of the cli-sync.sh command according to some condition that&rsquo;s met in your workflow. scheduling the running of the cli-sync.sh command on your own machine using cron on your own machine. Remember: the invocation of the command does NOT need to be done on JASMIN, it can be done wherever you have the CLI installed, for example your local machine. use the web interface (go to &ldquo;Transfer &amp; Timer Options&rdquo;) to configure repeating tasks initiated there. Learn about how to use timers with Globus: these can be set up using the web interface or using an additional CLI globus-timer-cli which can be installed into the same virtualenv as the main globus cli. Learn about Globus Flows to create fully automated workflows. Globus have created a number of pre-canned workflow actions (e.g. &ldquo;make directory&rdquo;, &ldquo;transfer&rdquo;, &ldquo;delete&rdquo;, ..) which you can chain together in your own workflow, or combine with your own to create custom workflows. A useful example might be: watching a directory for arrival/creation of a certain file triggering a compute/analysis step on files in the directory (using a Globus Compute endpoint of your own?) transferring the output of that analysis to elsewhere, and cleaning up`}).add({id:73,tag:"en",href:"/docs/data-transfer/globus-connect-personal/",title:"Globus Connect Personal",description:"Globus Connect Personal",content:`Introduction &nbsp; This article describes how to create your own Globus endpoint using Globus Connect Personal.
Please read Globus transfers with JASMIN first for a wider introduction to Globus.
Using Globus Connect Personal (GCP) would enable you to transfer files to/from another Globus Endpoint using any of the Globus Online transfer tools (Web app, CLI or [Python SDK](https://globus-sdk- python.readthedocs.io/en/stable/)).
The term &ldquo;endpoint&rdquo; has changed meaning with version 5 of Globus, so users now interact with &ldquo;collections&rdquo;. but see Endpoints vs Collections&nbsp; for a fuller explanation of these entities.
For example, if you set up GCP on your desktop/laptop, you could transfer data files to/from your home directory or other storage on JASMIN.
&nbsp; You may not need to do this if your institution already has a Globus endpoint available to you. You should NOT install this on a JASMIN server, as a Globus endpoint is already provided for you. If you plan to install it in your user area on your departmental server, check with your local IT administrator whether that&rsquo;s an OK thing to do. Point them at the relevant Globus documentation but note that you should be able to do the install with regular/user privileges and that the software does not usually need to be left running: it can be started for the duration of any data transfer tasks, then stopped once they have completed. Set up Globus Connect Personal on end-user machine &nbsp; Installers are available for Linux, Mac and Windows operating systems:
Linux (command-line) https://docs.globus.org/how-to/globus-connect-personal-linux/#globus-connect-personal-cli Mac https://docs.globus.org/how-to/globus-connect-personal-mac/ Windows https://docs.globus.org/how-to/globus-connect-personal-windows/ The instructions below show the process for Linux (command-line):
These commands should be executed on YOUR OWN MACHINE (not JASMIN):
wget https://downloads.globus.org/globus-connect-personal/linux/stable/globusconnectpersonal-latest.tgz tar xzf globusconnectpersonal-latest.tgz This will produce a versioned globusconnectpersonal directory Replace x.y.z in the line below with the version number you see
cd globusconnectpersonal-x.y.z ./globusconnectpersonal (see links above for details of how to install without the graphical user interface, if you need to)
Complete the installation using the setup key. If a graphical environment is detected, a window will appear, to guide you through the steps. If not, text prompts will appear.
(Please see the relevant installation guide for your platform, linked above, for further details)
Start Globus Connect Personal (Linux) &nbsp; ./globusconnectpersonal -start If you use the web application at https://app.globus.org, you should now be able to see your GCP endpoint listed under &ldquo;Collections&rdquo; when you filter by &ldquo;Administered by you&rdquo;. You can now try listing the files on it and perhaps transferring a file to/from one of the Globus Tutorial endpoints using the web interface.
The setup process will have prompted you for a name for your endpoint. It is assigned a unique ID, too.
If you have the Globus Command-Line Interface installed (see here), you can find the ID of your own endpoint with the CLI command:
globus endpoint search &lt;name&gt; --filter-owner-id &lt;your globus id&gt; If successful, you should now be able to interact with your endpoint via any of the Globus tools (web app, CLI and Python SDK).
For example, you could list the files on the endpoint:
globus ls &lt;endpoint_id&gt;:&lt;path&gt; Set directory permissions &nbsp; Don&rsquo;t forget to configure which directory paths on your system can be accessed by GCP. By default these may NOT be accessible, so you need to allow access.
Windows: GCP icon in taskbar, then Options / Access Mac: menu bar icon / Preferences / Access Linux: by editing the config file ~/.globusonline/lta/config-paths, see here&nbsp; for syntax.`}).add({id:74,tag:"en",href:"/docs/data-transfer/globus-transfers-with-jasmin/",title:"Globus transfers with JASMIN",description:"Globus transfers with JASMIN",content:`This article describes how to do data transfers using JASMIN&rsquo;s new Globus endpoint (now called a collection ), based on the most recent version of Globus Connect Server.
JASMIN&rsquo;s old Globus endpoint, based on the previous version of the Globus service, ceased operating on 18 December 2023 as support was discontinued by Globus. We have implemented a new endpoint, based on Globus Connect Server v5.4, with equivalent (but better!) functionality.
The new collection can be used as a drop-in replacement for the previous endpoint, aside from a few differences in terminology, and a change to the authentication process.
Main differences &nbsp; There are some differences to how the new (v5) version of Globus works on JASMIN compared to previously:
Users now interact with a collection The collection to use is called &ldquo;JASMIN Default Collection&rdquo; and has ID a2f53b7f-1b4e-4dce-9b7c-349ae760fee0 You now use the JASMIN Accounts Portal to authenticate (using your JASMIN account credentials) via OpenID Connect (OIDC). During the authentication process, you are redirected to the JASMIN Accounts Portal to link your Globus identity with your JASMIN account. Consent needs to be granted at a number of points in the process to allow the Globus service to carry out actions on your behalf. The default lifetime of the authentication granted to your JASMIN account is now 30 days. After this, you may need to refresh the consent for your &ldquo;session&rdquo;. This service is now available to all users of JASMIN: you no longer need to hold the hpxfer access role. The following examples show you how to authenticate with the new JASMIN Default Collection and list the contents of your home directory. As before, however, the following file systems are available via this collection
File system Access $HOME (/home/users/&lt;username&gt;) Read-write /gws (group workspaces) Read-write /work/xfc (transfer cache) Read-write /badc (CEDA Archive) /neodc Read-only List your home directory using the web app &nbsp; 1. Navigate to https://app.globus.org
2. Log in with your Globus identity (this could be a globusid.org or other identity)
log in 3. In File Manager, use the search tool to search for &ldquo;JASMIN Default Collection&rdquo;. Select it.
Find JASMIN Default Collection 4. In the transfer pane, you are told that Authentication/Consent is required. Click Continue.
Consent 5. Click the link to use the JASMIN Accounts Portal OIDC server to link your JASMIN identity
6. You are taken to a page on the JASMIN Accounts portal, where you are invited to &ldquo;Authorise&rdquo; the external application to authenticate and access your essential account information.
Authorise application 7. If successful, you are taken back to the Globus web app, where you are invited to &ldquo;Allow&rdquo; the app to use the listed information and services.
Allow the app to use the info 8. The directory listing of your home directory should now appear in the transfer pane.
9. Try navigating to another collection known to you (previously known as endpoint) in the other pane and transferring some data. If you have Globus Connect Personal running locally, you should be able to transfer files to/from that.
List your home directory using the command-line interface (CLI) &nbsp; 1. Load the virtual environment where you have the Globus CLI installed:
(in this example, a Python virtual environment named ~/.globus-cli-venv already exists. If it doesn&rsquo;t create one with the command python3 -m venv ~/.globus-cli-venv on your local machine). Activate this virtual environment as follows:
source ~/.globus-cli-venv/bin/activate 2. It&rsquo;s recommended to update to the latest version of the CLI by doing the following:
pip install -U globus-cli 3. Check that you have an active globus session and follow any instructions given, e.g.
globus login globus session show 4. Use the &ldquo;globus ls&rdquo; command to list the collection using its ID, starting at the path of your home directory (/~/)
globus ls a2f53b7f-1b4e-4dce-9b7c-349ae760fee0:/~/ TIP: you can set the ID of the collection to be an environment variable like this, for convenience:
export JASMIN_GLOBUS=a2f53b7f-1b4e-4dce-9b7c-349ae760fee0 globus ls $JASMIN_GLOBUS:/~/ 6. You will be taken through an equivalent set of steps to those needed for the web app. First off, you will be asked to copy/paste a URL into your browser and copy/paste back the resulting authentication code.
7. Once the authentication/consent process has been completed, you should see a listing of your home directory.
8. Use the globus transfer command to copy data to/from another collection (previously known as endpoint) to your home directory, within the JASMIN Default Collection. (see globus transfer --help for details)`}).add({id:75,tag:"en",href:"/docs/interactive-computing/graphical-linux-desktop-access-using-nx/",title:"Graphical linux desktop using NoMachine NX",description:"Graphical linux desktop using NoMachine NX",content:`This article explains how to connect to a graphical linux desktop within the JASMIN environment using NoMachine NX.
Introduction &nbsp; Benefits &nbsp; This service provides a graphical Linux desktop on JASMIN, ideal for use with graphics-heavy tasks like interactive work with large images. The desktop environment includes a Firefox web browser which can be used to access internal-only web resources. Using graphical applications over a wide-area network can be very slow, and is not recommended or supported on JASMIN. This service provides a better alternative with graphical desktop within the JASMIN environment itself, rather than on the user&rsquo;s local machine.
A small client application, available for you to install on your local machine, enables you to connect to specific servers within JASMIN. Graphics are then relayed to the client application in a more efficient form, resulting in much better performance particularly if you need to interact with what&rsquo;s being displayed.
The service provides an improved user experience and is strongly recommended over standard X11 graphics.
The following &ldquo;special&rdquo; login servers have the NX service available and can be used as described below:
nx-login1.jasmin.ac.uk (best for use from university networks) nx-login2.jasmin.ac.uk (Contingency config similar to login2.jasmin.ac.uk, to make it available from clients without reverse DNS lookup to a domain in the JASMIN allow-list. Use this option if you need to connect from home and do not have an institutional VPN available) nx-login3.jasmin.ac.uk (Contingency config as above) nx-login4.jasmin.ac.uk (Contingency config as above, but also supports users with usernames &gt; 8 but also supports users with usernames &gt; 8 characters. No support for usernames &gt; 14 characters: contact helpdesk for advice) Notes &nbsp; In all other respects these are the same as the standard login servers, but should only be used with the NX enterprise client as described below, (other than for testing your connection) as this preserves system resources for their intended purpose. Although the graphical desktop session which you create with this service should persist when you close the client (unless you specifically log out), you should not rely on this feature, so please don&rsquo;t report this as a problem: occasionally machines run out of resources and sessions get killed. Keeping sessions open consumes resources on the server even when you&rsquo;re not using the session, which may mean that other users can&rsquo;t use the service. nx-login4 has been introduced to help cater for users whose usernames exceed 8 characters length. This works around a known limitation in the NX server software but may not solve the problem for users with very long names (created before we introduced a limit to prevent this happening: if this still affects you and you cannot make onward connections to other machines in NX, please contact the helpdesk) Installing NoMachine Enterprise Client &nbsp; Download the appropriate version of the NoMachine Enterprise Client from [NoMachine](https://www.nomachine.com/download-enterprise#NoMachine- Enterprise-Client). This page contains links to several different products. The only one you need to install is &ldquo;NoMachine Enterprise Client&rdquo;.
Versions are available for Windows, Mac and Linux. You may need privileges on your local machine in order to install the software so you may need to ask for help from your local IT helpdesk.
Note that &ldquo;Nomachine Enterprise Client&rdquo; is a different application to the &ldquo;Nomachine Enterprise Desktop&rdquo; available from the more publicised download link on the NoMachine website or other applications in the NoMachine suite: the desktop edition contains additional components to enable remote access to your own (local) machine from a remote location: perhaps convenient but not what we are trying to enable for you here.
The NoMachine Enterprise Client is purely a client to connect to a remote server: in our case the server is at the JASMIN end, where the desktop session will exist.
Remember to check for updates for the enterprise client to ensure you always have the latest stable version. You can configure the application to check for updates (and optionally apply them automatically) by going to Settings / Updates in the menu.
Setting up your connection &nbsp; As you can see from the following videos, the instruction steps below are very similar for Windows / Mac / Linux, once the enterprise client is installed. Note that the interface may look slightly different depending on which version number of the client you have installed (we can&rsquo;t promise to keep the videos up to date with every new version, unfortunately!)
Windows Mac Linux Instructions for v8.x clients: (older clients may vary but same concept overall)
Open the NX client
On Mac and Windows, click the NoMachine Icon On Linux, the default location for the executable once installed is /usr/NX/bin/nxplayer, so you may want to add this to your path. Your desktop environment may enable you to add an icon to your desktop. In the &ldquo;Machines&rdquo; view, select &ldquo;Add&rdquo;
You&rsquo;re now in the &ldquo;Address&rdquo; tab. Type a name for this connection profile, and the full hostname, e.g. nx-login2.jasmin.ac.uk. Set the Protocol to &ldquo;SSH&rdquo;, which will change the port to 22. Go to the &ldquo;Configuration&rdquo; tab.
Choose &ldquo;Use key-based authentication with a key you provide&rdquo; , then click the Modify button to the right. The default is &ldquo;Use password authentication&rdquo;: don&rsquo;t use this. Use the button to the right to navigate to your private key, or type the path in the box. Your private key may be in a hidden directory e.g. ~/.ssh (see Troubleshooting) It is recommended NOT to &ldquo;import the private key to the connection file&rdquo;. Make sure you tick the box &ldquo;Forward Authentication&rdquo; IMPORTANT Go back to the &ldquo;Add connection&rdquo; dialog
If all is correct, click &ldquo;Add&rdquo; In the &ldquo;Machines&rdquo; list
You should see your new connection listed. Either double-click it, or right-click and select &ldquo;Start connection&rdquo; (Note that you can right-click to Edit/Remove/Rename or see Troubleshooting ) Connecting &nbsp; Enter your JASMIN username and your SSH passphrase (it is NOT recommended to save your passphrase in the connection file). Click OK.
You may see a list of all the other desktop sessions currently in progress from other users. Ignore these and click &ldquo;New desktop&rdquo;.
Select &ldquo;Create a new virtual desktop&rdquo;, then click &ldquo;Create&rdquo;
Note the instructions for how to reach the NX menu once in the session, and select screen settings from the list of icons: Recommended setting is &ldquo;Fit to window&rdquo; (leftmost icon)
Click OK on this and subsequent screens giving information about the NX and desktop environments.
You should be presented with a linux deskop on the server to which you connected, e.g. nx-login2.jasmin.ac.uk
Click &ldquo;Activities&rdquo; (top left menu on desktop) Open a terminal window by clicking the &ldquo;Terminal&rdquo; icon in the menu down the left hand side.
To see the list of sci servers which is normally presented at login (which helps in selected a less-loaded sci server), type the following:
cat /etc/motd Using the graphical desktop environment &nbsp; Once you have set up the environment to your liking, you can
use the web browser on that system to access web-based resources available only within JASMIN make SSH connections to other systems within JASMIN such as sci1.jasmin.ac.uk use graphical applications on other systems within JASMIN and send the output bask to this desktop Click &ldquo;Activities&rdquo; (top left menu on desktop) click Activities Click the Firefox icon in the side bar menu to start the Firefox web browser. Use this to access web-based resources only available within JASMIN. Do not use for personal web browsing. To toggle Firefox between taking up the whole of your desktop, and running in a smaller, sizeable window, double-click its title bar (this applies to any windowed application on the desktop). open Firefox browser Click the Terminal icon open Terminal application Try an onward SSH connection, for example to a SCI machine. ssh -AX &lt;user&gt;@sci1.jasmin.ac.uk (where &lt;user&gt; should be replaced by your JASMIN username).
Work interactively on a SCI machine as you would normally, but any graphical tools/applications should now work efficiently.
(Example of a graphical application on another machine within JASMIN). Try opening a simple graphical application on sci1.jasmin.ac.uk with the command:
xclock (you may find -AY works if -AX does not).
You may also get a few warning messages like this, which can safely be ignored:
Warning: Missing charsets in String to FontSet conversionCancel the graphical application (xclock) with CTRL + c, or use the application&rsquo;s own exit command, if it has one.
With other graphical applications opened on other servers within JASMIN, you may get warning/error messages like these as they start up: these can safely be ignored. Sometimes an application window can take a few seconds to appear, but should work normally after that.
Failed to open connection to &#34;session&#34; message bus: /usr/bin/dbus-launch terminated abnormally without any error message Running without a11y support! Gtk-Message: 08:58:38.169: Failed to load module &#34;pk-gtk-module&#34; Gtk-Message: 08:58:38.171: Failed to load module &#34;canberra-gtk-module&#34;&lt;br&gt; To log out of the virtual desktop, locate the menu top-right, and select your name, then &ldquo;Log Out&rdquo; 1. Don&rsquo;t worry if it appears that you&rsquo;re able to power off the machine with other users logged in: you would need administratrive privileges for this (which you don&rsquo;t have) so you can&rsquo;t do this accidentally. Please don&rsquo;t try, however! Notes &nbsp; The number of &ldquo;virtual desktops&rdquo; which can be created per user is limited to 1 in order to preserve system resources. Although in theory sessions and desktop windows should persist when you close down the NoMachine client and when you re-open it to the same connection, you should not rely on this feature. Keeping long-running sessions open reduces resources available to other users. The option to shut down the machine does not work for a &ldquo;regular&rdquo; user (only admins). Please just &ldquo;Log out&rdquo; instead. Troubleshooting &nbsp; Authentication error (Windows users) &nbsp; Try reformatting your private key using a tool available within MobaXterm. If you have tested and can successfully connect to nx-login2.jasmin.ac.uk from a MobaXterm terminal but NOT from the NoMachine NX client (&ldquo;Authentication Failed&rdquo;), then try following the steps below: these instructions are for Windows users. Note that this doesn&rsquo;t make you a new key, it just makes a newly-formatted version of your key, which can sit alongside your existing private key file. The public key stays the same, so there&rsquo;s no need to upload anything new to your JASMIN profile. Open the MobaKeyGen tool: MobaXterm menu / Tools / MobaKeyGen (SSH Key Generator) Click Load, navigate to your existing private key file (you may need to change the filter to show all files (.) instead of just (*.ppk). Select your key, click Open You will be prompted for the passphrase which you set when creating the key. In the MobaKeyGen menu, select Conversions / Export OpenSSH key (the 2nd option) Choose a new name for the file (it is recommended to just append something on to the end of your existing key name, so that it&rsquo;s clear that they are formats of the same key, e.g. id_rsa_jasmin -&gt; id_rsa_jasmin_f (but the name is not significant). Close the &ldquo;MobaXterm SSH Key Generator&rdquo; window Make yourself a new NX connection profile, pointing to the new file You should now be able to connect. The following video shows this sequence in action (although the key is named slightly differently) Transposed symbol keys &nbsp; After the first connection (particularly for Mac users), subsequent connections to the same connection profile sometimes have some symbols keys e.g. @ and &quot; transposed.
Watch the following video for how to correct this.
Doing as shown leaves a small drop-down choice tool in your Gnome desktop menu so that you can correct the problem if it re-occurs later. The correct choice for the author&rsquo;s UK Mac was &ldquo;English (UK, Macintosh)&rdquo;, but you may need to experiment with the choices available to match your own keyboard layout.
If you click the small keyboard-layout icon (bottom right when viewing the list of choices), you will be shown a preview of that keyboard layout to compare with your own.
Connection timeout &nbsp; Please do not try and connect using the proprietary &ldquo;NX&rdquo; protocol. Select &ldquo;SSH&rdquo; as the protocol. If you mistakenly use &ldquo;NX&rdquo; as the protocol you may see an error similar to the following when you try to connect (The correct port for SSH connections is 22)
A connection timeout has occurred while trying to connect to &#39;nx-login2.jasmin.ac.uk&#39; on port &#39;4000&#39;. The issue could either be caused by a networking problem, by a firewall or NAT blocking incoming traffic or by a wrong server address. Please verify your configuration and try again. Authentication method &nbsp; Please use &ldquo;Private key&rdquo; as the authentication method, not &ldquo;Authentication agent&rdquo;, as the former has been found to work more consistently and reliably, particularly for onward connections to other machines.
Client version &nbsp; Make sure you have installed and are using the most recent version of the NoMachine Enterprise Client (not the NoMachine Enterprise Desktop or any other applications from NoMachine).
Key format &nbsp; If you created your SSH private key using the &ldquo;PuTTYgen&rdquo; application, and are getting &ldquo;Authentication failed&rdquo; for a key pair that you know works OK for simple terminal connections, it could be that you need to convert the private key to &ldquo;OpenSSH format&rdquo; for use here. By doing this you would be creating an alternately-formatted version of the same private key, so the public key stays the same (and you don&rsquo;t need to re-upload that to JASMIN).
Open PuTTYgen and &ldquo;Load an existing private key file&rdquo; (click &ldquo;Load&rdquo;) Ignore the notice about saving it in PuTTY&rsquo;s own format (this is not useful here) (click &ldquo;OK&rdquo;) In the PuTTYgen menu, select &ldquo;Conversions&rdquo;, then &ldquo;Export OpenSSH key&rdquo; Save the newly-formatted private key file locally. The passphrase needed to unlock it should not have changed. Use this newly-formatted key file with NoMachine NX. Passphrase vs Password &nbsp; Be sure to use the PASSPHRASE associated with your SSH private key, and not the PASSWORD associated with your JASMIN account, when prompted using the NX client.
Can&rsquo;t find your private key? &nbsp; The location of your private key on your local machine may be in a hidden directory for example ~/.ssh. In order to navigate to it to provide the location when setting up your connection profile, you may need to enable the display of hidden directories/files in your local desktop environment first. On a Mac you can do this with the shortcut CMD&#43;SHIFT&#43;. . In Windows this is under File Explorer / View / Hidden Items. It&rsquo;s also possible that your home directory itself (normally /Users/&lt;username&gt;) is not configured to be displayed by default in Finder. If this is case, go to Finder / Preferences / Sidebar / Show these items and tick the box next to the item representing your username: this should make it appear, and .ssh should be a subdirectory of this.
Can&rsquo;t make an onward connection &nbsp; Previous versions of the Windows client had problems with &ldquo;forward authentication&rdquo; enabled, but this is required for onward connection to other machines. If this happens, try:
Does your username have &gt; 8 characters? If so, try using nx-login4. Uninstalling the v7 client client Deleting the C:\\Users\\&lt;username&gt;\\.nx directory on your machine Re-installing and trying again. Deleting and making a new connection profile for the nx-login server you&rsquo;re connecting to. Can&rsquo;t display graphics from sci machine or other onward connection &nbsp; Did you omit the -X option from the SSH command when you made the onward connection to that machine? Try -Y if -X doesn&rsquo;t work for you.
Disk space &nbsp; Check your disk usage in your JASMIN home directory: if this is over the 100G limit, you may not be able to write any temporary files and this could prevent NoMachine from being able to start a new session or even reconnect to an existing virtual desktop session. Clear out some space and re-check with pdu -sh $HOME to find out how much space you&rsquo;re using.
Can&rsquo;t connect or gets stuck connecting to a previous session &nbsp; Sometimes, you can&rsquo;t connect because you have a previous session which did not terminate correectly, or you might have problems reconnecting to a previous desktop session. Sometimes the client will get stuck with a &ldquo;spinning wheel&rdquo; before eventually timing out. You can terminate your own previous session as follows:
Follow instructions in Connecting until step 2 where all the users&rsquo; sessions on the machine are displayed. Find the one corresponding to your username Right-click it and select &ldquo;Terminate session&rdquo; Note that you may lose any unsaved work in the session that you terminate, but it should clear the stuck session and allow you to reconnect. Please try this first before asking the support team, as this is the first thing that they will try in order to clear your session.
&ldquo;It worked yesterday&rdquo; &nbsp; For occasions where &ldquo;it worked last time I tried to connect, but now doesn&rsquo;t&rdquo;, please first try the above step to clear any previous session which might have got stuck, otherwise the time-honoured IT support advice of &ldquo;turning it off and on again&rdquo; is applicable: try restarting your local machine where the NX client is running, as this can sometimes clear issues with the client, your machine or your network connection. Don&rsquo;t forget to re-connect via your VPN if available.`}).add({id:76,tag:"en",href:"/docs/data-transfer/gridftp-cert-based-auth/",title:"GridFTP (certificate-based authentication)",description:"Data Transfer Tool: GridFTP (certificate-based authentication)",content:`This article describes how to transfer data using gridftp with certificate- based authentication.
&nbsp; The globus-url-copy command used here should not be confused with the Globus online data transfer service. They used to be associated, but no longer. If you are starting out and looking for a reliable, high-performance transfer method, the recommendation now is to learn about Globus Transfers with JASMIN (using the Globus online data transfer service) instead of command-line gridftp as described in this document. Basics of certificate-based authentication &nbsp; Gridftp servers commonly use a network of &ldquo;trust&rdquo; based on electronic certificates. In order to make use of a gridftp server at one end of your proposed transfer, you will need to use a certificate which identifies you as the user, and which is issued by an identity provider which is &ldquo;trusted&rdquo; by the servers at both ends. The trust between the servers is maintained by the administrators of the service who will ensure that the necessary certificates are in place.
The presentation of a valid credential which is trusted by the server at the other end is merely the authentication step (proving who you are). Authorisation also needs to follow: you, as a user (identified by the credential you present) need to be authorised to use the resource at the other end. You should check with the operator of the other gridftp server to see what additional steps are required before you can actually perform a transfer.
Getting a short-term credential &nbsp; In order to access the JASMIN gridftp server, you can now use your JASMIN portal account to gain a short-term credential which the server will recognise to authenticate you. This is the same username and password you would use to log in to https://accounts.jasmin.ac.uk to administer your JASMIN account. IT IS NOT YOUR SSH PASSPHRASE.
Here&rsquo;s what to do:
Download tools to interact with JASMIN&rsquo;s Online Certificate Authority (OnlineCA). You can use these to interact with other OnlineCAs too (not just JASMIN&rsquo;s. These replace the &ldquo;myproxy-logon&rdquo; tool previously mentioned here) Use these tools to: 1. &ldquo;Bootstrap trust&rdquo; i.e. to setup your local certificate store with those needed to interact with the JASMIN server [First time use only] 2. Obtain a short-term credential using your JASMIN account details [First time, and to renew your short-term credendial as needed] Use this short-term credential to authenticate with a remote gridftp server which trusts this credential (for example, the JASMIN gridftp server) Download OnlineCA tools &nbsp; On the machine you intend to use as the transfer client, e.g. xfer1.jasmin.ac.uk, in your JASMIN home directory, download 2 shell scripts which will interact with the Online CA for you. Make them executable:
wget https://raw.githubusercontent.com/cedadev/online_ca_client/master/contrail/security/onlineca/client/sh/onlineca-get-cert-wget.sh wget https://raw.githubusercontent.com/cedadev/online_ca_client/master/contrail/security/onlineca/client/sh/onlineca-get-trustroots-wget.sh chmod u+x onlineca-get-*.sh View help information for the shell scripts:
./onlineca-get-trustroots-wget.sh -h ./onlineca-get-cert-wget.sh -h Bootstrap trust between your own machine and the JASMIN gridftp server: (First time only)
./onlineca-get-trustroots-wget.sh -U https://slcs.jasmin.ac.uk/trustroots/ -b Bootstrapping Short-Lived Credential Service root of trust. Trust roots have been installed in /home/users/USERNAME/.globus/certificates. Obtain a credential, to be written to an output file credfile using your JAMSIN Accounts Portal username USERNAME:
./onlineca-get-cert-wget.sh -U https://slcs.jasmin.ac.uk/certificate/ -l USERNAME -o ./cred.jasmin When prompted, enter the password associated with your JASMIN account (NOT your SSH passphrase)
Change the permissions on your newly-created cred.jasmin file so that it&rsquo;s only readable by you (client software may insist on this):
chmod 600 ./cred.jasmin This credential obtained by this method is valid by default for 720 hours (30 days), as you can see by inspecting the certificate using the following command:
openssl x509 -in cred.jasmin -noout -startdate -enddate notBefore=Mar 11 17:32:59 2022 GMT notAfter=Apr 10 17:32:59 2022 GMT After the notAfter date, it will no longer be valid, but you can repeat this process at any time (e.g. before it expires) to update it.
Example Gridftp usage &nbsp; (General case, or with a JASMIN host as gridftp client)
Once you have obtained a valid short-term credential on the client transfer server, and assuming that the gridftp server at the remote end of the transfer recognises and is able to authorize you via this credential, then you should be able to transfer data between the remote server and local client with commands such as shown below:
Please consult the documentation for the globus-url-copy command for the full range of options and arguments.
Please note that the examples below use a fictitious client gridftp-client.localsite.ac.uk and server gridftp-server.remotesite.ac.uk which need to be replaced in your commands with the hostname of the actual gridftp server and client you are actually using.
Check help documentation for the globus-url-copy command:
globus-url-copy -help NOTE: On some systems, you have to load a relevant module to get access to the globus-url-copy command, however not on the JASMIN [hp]xfer servers.
It is recommended to try things out using the regular xfer servers xfer[12] but to perform &ldquo;real&rdquo; transfers using hpxfer[12] for better performance, but to use the latter you will need the hpxfer access role.
1. Remote directory listing issued by client on gridftp- client.localsite.ac.uk to server gridftp-server.remotesite.ac.uk where you have a home directory /home/users/USERNAME:
globus-url-copy -cred cred.jasmin -vb -list gsiftp://gridftp-server.remotesite.ac.uk/home/users/USERNAME/ 2. Download a file from remote directory /home/users/USERNAME to destination on the client machine:
globus-url-copy -cred cred.jasmin -vb gsiftp://gridftp-server.remotesite.ac.uk/home/users/USERNAME/myfile file:///path/to/localdir/myfile The -p N and -fast options can additionally be used in combination to enable N parallel streams at once, as shown below. You can experiment with N in the range 4 to 16 to obtain the best performance, but please be aware that many parallel transfers can draw heavily on shared resources and degrade performance for other users:
globus-url-copy -cred cred.jasmin -vb -p 16 -fast gsiftp://gridftp-server.remotesite.ac.uk/home/users/USERNAME/myfile file:///path/to/localdir/myfile 3. Recursively download the contents of a directory on a remote location to a local destination.
globus-url-copy -cred cred.jasmin -vb -p 4 -fast -cc 4 -cd -r gsiftp://gridftp-server.remotesite.ac.uk/home/users/USERNAME/mydir/ file:///path/to/localdir/mydir/ Where:
-cc N requests N concurrent transfers (in this case, each with p=4 parallel streams) -cd requests creation of the destination directory if this does not already exist -r denotes recursive transfer of directories -sync and -sync-level options can be used to synchronise data between the two locations, where destination files do not exist or differ - y criteria that can be selected) from corresponding source files. See -help option for details. the file:/// URI is used to specify the destination on the local file system. Uploading data &nbsp; The above commands can also be adapted to invoke transfers from a local source to a remote destination, i.e. uploading data, since the commands all take the following general form:
globus-url-copy [OPTIONS] source-uri desination-uri You can use the above examples by replacing the local machine gridftp-client.localsite.ac.uk with one of the jasmin transfer hosts xfer[12].jasmin.ac.uk as a client, To do this, you first need to be logged in via SSH to one of these hosts and can initiate a transfer by invoking globus-url-copy in one of the ways above.
For high-performance transfer (large volumes and/or longer distances), use hpxfer[12].jasmin.ac.uk for which you will need to have the hpxfer access role. hpxfer[12].jasmin.ac.uk are also recommended for transfers to/from ARCHER2 if initiated at the JASMIN end, but if you are initiating the transfer from the ARCHER2 end, you will need to connect to the JASMIN GridFTP server as described below, see also Transfers from ARCHER2. hpxfer2.jasmin.ac.uk is tuned for very long path transfers (e.g. Western US or Australia/NZ) For remote hosts using JASMIN&rsquo;s dedicated network link (Met Office only) use xfer[12].jasmin.ac.uk as the client (These are virtual machines so have limited performance, but your transfer will be over a dedicated network connection) Connecting to the JASMIN GridFTP server &nbsp; In order to do a transfer using a JASMIN host as the gridftp server (rather than client), you would need to interact with the JASMIN GridFTP server gridftp1.jasmin.ac.uk. You cannot log in to this server directly via SSH: you only initiate GridFTP transfers to and from it from another client.
In the following example, a client is initiated on a fictitious remote host client.remotesite.ac.uk and tests the connection by transferring from /dev/zero on the local machine (at remotesite ) to /dev/null on the JASMIN gridftp server. Note that you can use the SLCS server at JASMIN to obtain the short-term credential required ( but the first time, you will need to download and use the OnlineCA tools as described above ). You can renew your credential and perform the test transfer as follows:
./onlineca-get-cert-wget.sh -U https://slcs.jasmin.ac.uk/certificate/ -l USERNAME -o ./cred.jasmin globus-url-copy -cred cred.jasmin -vb -p 8 -fast /dev/zero gsiftp://gridftp1.jasmin.ac.uk/dev/null Source: file:///dev/ Dest: gsiftp://gridftp1.jasmin.ac.uk/dev/ zero -&gt; null 4153409536 bytes 792.20 MB/sec avg 792.20 MB/sec inst This server is also used as the JASMIN GridFTP Server globus endpoint, see GridFTP transfers using Globus Online (however you can only currently use your CEDA SLCSs credential with Globus Online. The JASMIN team is working on a solution for this).
Please note that the servers xfer[12].jasmin.ac.uk and hpxfer[12].ceda.ac.uk are not gridftp servers. They have the globus- url-copy client installed, so can be used as clients to connect to remote gridftp servers, and also support gridftp over SSH (both incoming and outgoing), but do not act as servers for certificate-based gridftp as shown in these examples. The JASMIN gridftp server for read-write access to home directories and group workspaces is gridftp1.jasmin.ac.uk. Access to this requires the hpxfer access role. See also Transfer Servers.
Third-party transfers &nbsp; It should be possible, with the correct configuration at each site, to initiate on host A a transfer of data between two other gridftp servers B and C (a third party transfer). Both URIs would use gsiftp: as the protocol:
globus-url-copy -vb -p 4 gsiftp://B/source gsiftp://C/destination Further information can be found in the documentation for globus-url-copy.
This is the basis of the Globus Online managed service to orchestrate and monitor transfers between gridftp endpoints in a more user-friendly way. It has evolved considerably since diverging from the &ldquo;traditional&rdquo; gridftp setup described in this article and is recommended as it provides a much easier user experience and better reliability.
See Globus transfers with JASMIN.
Future plans &nbsp; As [support for the open-source Globus Toolkit (including globus-url-copy) has now been withdrawn by Globus](https://www.globus.org/blog/support-open-source- globus-toolkit-ends-january-2018), the future of direct gridftp transfers is uncertain. It is currently maintained by the Grid Community Forum.
We advise users to spend some time understanding and testing transfer workflows with the Globus Online transfer service, including the command-Line, web interfaces and (for advanced users) a Python SDK, as these are likely to replace direct gridftp on JASMIN in due course.`}).add({id:77,tag:"en",href:"/docs/data-transfer/gridftp-ssh-auth/",title:"GridFTP (SSH authentication)",description:"Data Transfer Tools: GridFTP (SSH authentication)",content:`This article describes how to transfer data using GridFTP with SSH authentication.
&nbsp; The globus-url-copy command used here should not be confused with the Globus online data transfer service. They used to be associated, but no longer. If you are starting out and looking for a reliable, high-performance transfer method, the recommendation now is to learn about Globus Transfers with JASMIN (using the Globus online data transfer service) instead of command-line gridftp as described in this document. Introduction &nbsp; GridFTP is the recommended tool for transferring large files or groups of files across high-speed Wide-Area Networks (WANs). It is commonly used with certificate-based authentication, but can also take place between suitably configured* server and client using SSH as the authentication mechanism.
The client may need to have certain ports enabled on the host or institutional firewall if present. Consult your local IT support desk for details and direct them to Configuring GridFTP&nbsp; .
SSH-based GridFTP does not enable the full feature set provided by certificate-based GridFTP and in particular does not work with Globus Online, which provides useful interfaces and APIs for managing large-scale data transfers, but still provides a major step up in performance by &ldquo;filling the pipe&rdquo; more efficiently than scp/rsync/sftp, particularly over longer distances and can do verification and sync operations as part of the transfer.
See also:
Transfer servers for details on which servers within JASMIN have GridFTP available. Transfers from ARCHER2 for details of different routes affecting your choice of server (since this is the one of the most likely places to which JASMIN users will want to transfer data to/from) Establishing a connection &nbsp; Since you will be using SSH as the authentication mechanism, you should ensure that your initial connection to the JASIMN transfer server is made with the -A option enabled, to enable agent forwarding:
ssh -A username1@hpxfer1.jasmin.ac.uk Note that in order to use hpxfer[12].jasmin.ac.uk you will need to have high-performance data transfer access on your JASMIN account. An alternative to try out beforehand, is to use jasmin- xfer1.ceda.ac.uk.
Use the globus-url-copy command to list the contents of your home directory on the remote server (This will only work if you already know that that server supports GridFTP over SSH). In this case, we are making the connection to a fictitious server gridftp.remotesite.ac.uk:
globus-url-copy -vb -list sshftp://username2@gridftp.remotesite.ac.uk/ If username and username2 are the same (on the different systems, the username@ part of the sshftp URI can be omitted.
Note that the URI of the server, in this case sshftp://username2@gridftp.remotesite.ac.uk must come immediately after (as it is an argument to) the -list option. This is particularly important if you are combining this command with other options.
Example GridFTP usage &nbsp; Once you have successfully established that you can connect to the server (as above), then you should be able to transfer data between the remote end (server) and local end (client) with commands such as shown below:
As above, if you have the same username on both local and remote systems, then the username@ part of the sshftp URI can be omitted.
Please consult the documentation for the globus-url-copy command for the full range of options and arguments.
globus-url-copy -help See also &lt;http://toolkit.globus.org/toolkit/docs/latest- stable/gridftp/user/#gridftp-user-basic&gt;
2. Download a file from remote directory /home/users/USERNAME to destination on the local (client) machine, for example a group workspace on JASMIN:
globus-url-copy -vb sshftp://username@gridftp.remotesite.ac.uk/home/users/USERNAME/myfile /group_workspaces/jasmin/myworkspace/myfile The -p N and -fast options can additionally be used in combination to enable N parallel streams at once, as shown below. You can experiment with N in the range 4 to 32 to obtain the best performance, but please be aware that many parallel transfers can draw heavily on shared resources and degrade performance for other users:
globus-url-copy -vb -p 16 -fast sshftp://username@gridftp.remotesite.ac.uk/home/users/USERNAME/myfile /group_workspaces/jasmin/myworkspace/myfile 3. Test performance with large files by downloading from /dev/zero on the remote server to /dev/null locally. This excludes any interaction with either filesystem and gives an upper limit to the performance that can be achieved at the time. Repeat with values of N in the range 4 to 32 to compare rates. Note that the performance takes a while to &ldquo;ramp up&rdquo;, so you will not see the best rates if transferring small files individually as the process never gets up to full speed:
globus-url-copy -vb -p 16 -fast sshftp://username@gridftp.remotesite.ac.uk/dev/zero /dev/null Press CTRL-C to interrupt the transfer. Alternatively you can specify that the transfer should continue for a fixed duration in seconds using the -t option. In this example, data is transferred from the remote host gridftp.remotesite.ac.uk to jasmin-xfer2.ceda.ac.uk.
globus-url-copy -p 16 -fast -t 10 -vb sshftp://username2@gridftp.remotesite.ac.uk/dev/zero /dev/null Source: sshftp://username2@gridftp.remotesite.ac.uk/dev/ Dest: file:///dev/ zero -&gt; null 7797473280 bytes 929.52 MB/sec avg 1024.49 MB/sec inst Cancelling copy... Note the transfer rate achieved in Megabytes/second (MB/sec), although for various reasons this is not to be relied upon as an accurate expectation of speed for real transfers. However, you are unlikely to achieve even half of this data rate viascp, rsync or sftp over the same route. Bbcp may achieve similar rates, however, and this is considered by some as easier to use.
4. Recursively download the contents of a directory on a remote location to a local destination.
globus-url-copy -vb -p 4 -fast -cc 4 -cd -r sshftp://username2@gridftp.remotesite.ac.uk/home/users/USERNAME/mydir/ /group_workspaces/jasmin/myworkspace/mydir/ Where:
-cc N requests N concurrent transfers (in this case, each with p=4 parallel streams) -cd requests creation of the destination directory if this does not already exist -r denotes recursive transfer of directories -sync and -sync-level options can be used to synchronise data between the two locations, where destination files do not exist or differ (by criteria that can be selected) from corresponding source files. See -help option for details. Upload data (push data from JASMIN to remote server) &nbsp; The above commands can also be adapted to invoke transfers from a local source to a remote destination, i.e. uploading data, since the commands all take the following general form:
globus-url-copy [OPTIONS] source-uri desination-uri Be sure to check your connection with the remote machine via a simple SSH login and then a directory listing as shown above.
JASMIN host as remote server &nbsp; So far the examples have used a server within JASMIN as the client in the GridFTP transfer. The transfer can be reversed so that the client is elsewhere and the JASMIN host is the server specified in the destination URI. The following command should work connecting to one of the following transfer servers: (see also Transfer Servers)
xfer[12].jasmin.ac.uk xfer3.jasmin.ac.uk (additional access role required) hpxfer[12].jasmin.ac.uk (high-performance data transfer access required) Push data to JASMIN from a remote server:
globus-url-copy -vb -p 8 -fast mydir/myfile sshftp://username@hpxfer1.jasmin.ac.uk/group_workspaces/jasmin/myworkspace/mydir/ Note that for this to work, you need to be able to authenticate over SSH to the JASMIN host. This should be possible if you can log in interactively, but will NOT work if you are using the command in a cron job or other situation where your ssh-agent (on the host remote to JASMIN) is not running and/or does not have access to your private key. For those situations, consider using either
Globus (recommended), or Gridftp using certificate-based authentication)`}).add({id:78,tag:"en",href:"/tags/group-workspace/",title:"Group Workspace",description:"",content:""}).add({id:79,tag:"en",href:"/guides/",title:"Guides",description:"",content:""}).add({id:80,tag:"en",href:"/guides/guides-coming-soon/",title:"Guides coming soon",description:"More content to follow soon",content:"Watch this space &nbsp; We&rsquo;ll be adding more content soon, as we reorganise the JASMIN help content further."}).add({id:81,tag:"en",href:"/tags/gws/",title:"Gws",description:"",content:""}).add({id:82,tag:"en",href:"/docs/short-term-project-storage/gws-etiquette/",title:"GWS etiquette",description:"GWS  etiquette",content:`This article highlights the essential principles of working with group workspaces.
Keeping informed &nbsp; Please maintain contact throughout the life of the GWS via the following methods:
Using the JASMIN dashboard to check on the status of your GWS (used versus available space). Using the GWS Scanner User Interface to check on where, for how long and by whom, space is being used. GWS Managers should configure the GWS Scanner to gather the above information and arrange email alerts. Look out for emails from the CEDA/JASMIN team News articles on the CEDA&nbsp; or JASMIN&nbsp; websites and by monitoring CEDA social media&nbsp; feeds which may be used to post messages regarding system status or security. If you are aware that a user who has access to your GWS leaves your project, or, for whatever reason, no longer needs to be a member of the GWS, please let the CEDA helpdesk know, as arrangements may need to be made to transfer the ownership of files and/or directories to another member of the GWS (e.g. the manager) to ensure continued access to the data.`}).add({id:83,tag:"en",href:"/docs/short-term-project-storage/gws-scanner/",title:"GWS Scanner",description:"GWS Scanner",content:`Introduction &nbsp; This article explains about the process that runs in the background scanning all group workspaces to gather basic information about usage, which are fed into a database to be made available to users via the GWS Scanner User Interface.
It is intended for GWS Managers and provides details about how to customise the scan that is done on each GWS.
It is run centrally, and is a very resource-intensive task, so please don&rsquo;t run similar tasks of your own, as you will be unnecessarily duplicating resource usage.
There are two different scans of the Group Workspaces (GWSs).
A daily scan which checks for how full the GWS is, and will email the GWS manager if it is over the default threshold of 83%, or a defined threshold in the GWS config file (see below). An approximately fortnightly check of the contents of all GWSs. As a GWS Manager you will receive e-mails summarising the usage and contents of the GWS. By default this is a simple volume level summary of the GWS.
Customisation &nbsp; If you wish for additional directories to be scanned and summarised please add these to the GWS_PATH/.gws_scan/config.ini, where GWS_PATH is the path to your group workspace (the directory and the file may need to be created). Directories can also be excluded from the scan in the same way. This can be useful for speeding up the run time of a scan. Here is an example of a config.ini file.
&nbsp; Please note that the required directory for this configuration data is .gws_scan, not .gws_scanner - the latter is from the previous incarnation of the scanner, and will be be removed in due course) [general] # GWS fullness threshold for which the daily scan will send a warning email (default 83) (in %) volume_warning_threshold = 83 # Directories to check for largest sub-dir and filetypes below (comma separated list), these paths must be relative to the group workspace path i.e. path/to/dir, not /group/workspace/path/to/dir # Defaults to all top level directories inside volume dirs = dir1,path/to/dir2 # Directories to exclude from the scan. This can be useful to speed up the scan if there are know directories with a large number of files, for which the scan information is not very useful excl_dirs = path/to/excl, large_dir # Filetype extensions to count inside directories above (comma separated list) # Defaults to none exts = html,py,jsdirs and excl_dirs can have the * wildcard anywhere in the directory path. From the config above for example: path/to/*, and p*h/to/dir2 would pick up the directory /path/to/dir2, and any other directories which matched the pattern.
Please don&rsquo;t comment out the arguments. If you don&rsquo;t want to use one just leave it blank, this will then just use the internal defaults. E.g.
[general] volume_warning_threshold = dirs = excl_dirs = exts = Report &nbsp; When the fortnightly scan runs it sends the output to the GWS manager as an email, which looks like this:
### Group Workspace Report for: GWS_PATH #### Scan Details Time most recent scan started: 16/04/2019 - 10:15:57 Time most recent scan finished: 16/04/2019 - 12:25:27 Duration of most recent scan (h:m:s): 2:09:29 Scan Complete: True #### Usage Details Filesystem: fuse.quobyte Total Storage: 199.2 TiB Used Storage: 81.8 TiB Free Storage: 117.4 TiB Usage: 42% #### Directory Details To get information about specific directories within this volume, please add the relative paths to the volume config file (.gws_scan/config.ini) - see [https://help.jasmin.ac.uk/article/4499-gws-scanner](https://help.jasmin.ac.uk/docs/short-term-project-storage/gws-scanner/) **Directory** | **Total Files** | **Total Size** | **Sub-directory with most files** | **Files in this Sub-directory** ---|---|---|---|--- all_dirs | 238336 | 81.8 TiB | GWS_PATH/dir1/example/path | 7929 .gws_scanner | 0 | 0.0 B | None | 0 dir1 | 0 | 0.0 B | GWS_PATH/dir1/example/path | 0 #### Filetype Details To get information on the quantity and size of specific filetypes under the directories above, please add the relevant file extensions to the volume config file (.gws_scan/config.ini) - see [https://help.jasmin.ac.uk/article/4499-gws-scanner](https://help.jasmin.ac.uk/docs/short-term-project-storage/gws-scanner/) _No filetypes requested_`}).add({id:84,tag:"en",href:"/docs/short-term-project-storage/gws-scanner-ui/",title:"GWS Scanner UI",description:"User interface to GWS scanner",content:`The Group Workspace (GWS) Scanner UI is an interactive web application for JASMIN users to view their GWSs.
Please note this service is under beta-testing and should be used with care (July 2023)
What is the GWS Scanner UI? &nbsp; A GWS is collaborative storage made available to a group for a project. The GWS Scanner UI provides information about the structure of GWSs in the form of a tree graph showing the folders within the GWS. The tiles of the graph can be scaled or coloured by size, count or heat.
Size refers to the size (in TB or GB) of the folder count refers to the number of files and folders within the directory heat refers to the average time since last access (hot = recent). The tree graph only shows tiles for the folders within the GWS, the files are lumped together as unindexed children, but the files are considered in the calculation of the GWS statistics - e.g. the number of children is the number of folders and files within the GWS. There are also doughnut graphs with additional breakdowns in terms of users, filetypes and heats which can be scaled by either size or count.
Using the GWS Scanner UI &nbsp; Navigate to the GWS Scanner homepage where you should see a Log In button.
Clicking the login button will take you to the login page where you can sign in using your JASMIN account. Upon successful sign-in you should be redirected back to the homepage where you will have the option to view your GWSs.
&nbsp; At any time, you can click the JASMIN logo in the navbar to return to the homepage. Here you will see a table with the names of your GWSs and their path. Clicking on the path will take you to the tree page for the GWS.
Alternatively, if you know the path to your GWS you can search for it in the url, e.g. https://gws-scanner.jasmin.ac.uk/tree/&lt;path-here&gt;. On this page you will see the path to your GWS at the top, then the tree graph with the coloured tiles representing folders within the GWS. Note that some larger GWSs may take longer to load.
There is a Toggle Patterns button which can be used to swap the coloured tiles for patterned tiles. Hovering over a tile will reveal more information about that folder. There are buttons on the right hand side to scale and colour the tiles by size, count or heat as described earlier. There is also a key showing the values the colour of the tiles correspond to in this sidebar as well as information showing when the GWS was last scanned. Scans usually take around two weeks to complete so each GWS should be scanned approximately fortnightly. There is a Go Up One Level button which will take you back a level, but note that this will only work if you have gone deeper into the file path as it will not show the structure above the root GWS folder. You can click on a tile on the graph to view the tree graph inside that folder. For example, you may have a folder called user1 in group-workspace-1, you could click on this tile to see the structure of the user1 directory then you could use the Go Up One Level button to go back to group-workspace-1. Alternatively, you can just use the back button in your browser to go back. You can keep clicking files to go deeper into the GWS structure until you reach an unindexed children level where there are no more folders, only files. This is represented by a tile saying unindexed children which refers to a collection of files (every level will have an unindexed children tile representing the files within that folder).
Scrolling down the page, you will find the doughnut graphs. There is one for the User Breakdown, Filetype Breakdown and Heat Breakdown. Each of these have coloured sections corresponding to different users, filetypes or heats and the size of them is proportional to the size or count (there are Size and Count buttons to change between them). Again, hovering over a section of the graph will give you more information.
Common issues and questions &nbsp; If you get stuck on a loading screen try refreshing the page - we are working on fixing this issue. If you go to the My GWSs page and don&rsquo;t have any GWSs listed, check that your JASMIN account does have access to the GWS you are looking for. Sometimes, if there are lots of tiles they can be hard to read - you can hover over the tile to get the full title or if you want to view the tree graph for that folder, you search for it by URL instead. If you are ever stuck and requiring help, the help beacon can be accessed from any page. Further information &nbsp; Here are some links to learn more about the GWS Scanner:
The GWS Scanner UI If you have any questions or suggestions, feel free to get in touch.`}).add({id:85,tag:"en",href:"/docs/mass/how-to-apply-for-mass-access/",title:"How to apply for MASS access",description:"How to apply for MASS access",content:`Introduction &nbsp; To access data held in the Met Office MASS archive, you will need:
a sponsor access to the mass-cli1 client machine a MASS account Your sponsor will need to be a Senior Met Office Scientist with whom you are working on a collaborative research project. If you are a Met Office employee, your sponsor will be your manager.
Note: The following instructions also assume you already have a JASMIN login account and the jasmin-login service. If you do not, please follow steps 1-4 here.
Step One - Sponsor Form &nbsp; Ask your sponsor to:
Complete the sponsor form Please note that the link above is only visible to those in the Met Office.
The following information will be asked for, so please provide your sponsor with any details they may not have:
Your full name Your official email address Your organization&rsquo;s name Your department name The host country of your organization A list of MASS projects and/or data sets that you need access to. A full MOOSE dataset path is required, and your sponsor should help you determine this. Your JASMIN username Your JASMIN user ID number (UID). You can get this by typing echo $UID at the terminal on any JASMIN machine. The information you provide to the Met Office will be treated in accordance with the [Met Office Privacy Policy](https://www.metoffice.gov.uk/about- us/legal/privacy), and your use of the service will be subject to the [Terms and Conditions of Use](https://metoffice.github.io/JASMIN-MASS- access/Terms_and_Conditions.html) for the service.
Step Two - Access to mass-cli1 &nbsp; Sign into your JASMIN account Select ‘JASMIN Services’ Select ‘Additional Services’ Next to ‘mass’ click ‘More information’ Select ‘Apply for access’ Within the request, please name your sponsor The direct link is: https://accounts.jasmin.ac.uk/services/additional_services/mass/
Step Three - MASS account &nbsp; When steps one and two are complete, you will be provided with a specific MASS account to use on JASMIN and emailed a MOOSE credentials file. Please see Setting up your JASMIN account for access to MASS once you have received the credentials file.
Note: If you have access to MASS on other systems you cannot copy those MOOSE credentials file/s onto JASMIN – they will not work! Please also see the External Users’ MOOSE Guide for what MOOSE commands are available on JASMIN.`}).add({id:86,tag:"en",href:"/docs/getting-started/how-to-contact-us-about-jasmin-issues/",title:"How to contact us about JASMIN issues",description:"How to contact us about JASMIN issues",content:"If you are experiencing difficulties or slow performance and are unsure why, please first consult all relevant documentation, then if needed, contact our Helpdesk using the help beacon below, but please include the following information with your initial query:\nWhat is the full name of the JASMIN server were you using? ( e.g. sci1.jasmin.ac.uk) The full path of your current working directory e.g. `/gws/nopw/j04/mygws`` Date &amp; time that the issue occurred Your JASMIN account username Your description of the issue and copy/paste any error messages from the terminal Location of code/script used - if possible, so one of the CEDA/JASMIN team can reproduce the issue A batch job ID if it relates to LOTUS jobs Please provide as much specific information as possible so that we can direct your query to the appropriate staff and deal with your enquiry efficiently. Hopefully, the time invested in solving your issue will also help other JASMIN users now and in the future."}).add({id:87,tag:"en",href:"/docs/getting-started/login/",title:"How to login",description:"How to login",content:`This article explains how to login to JASMIN.
The instructions below cover the process of logging in using a terminal client only. For a graphical linux desktop, please see alternative instructions using NoMachine NX.
Preparing your credentials: loading your SSH private key &nbsp; In order to log in using SSH, you need to present your SSH private key as your credential (instead of a username and password). Your private key should reside only on your local machine, so this process of loading your key is something that you do on that local machine. Even if you connect via a departmental server, there should be no need to upload your private key to that machine: the process of loading your key and enabling agent forwarding should ensure that the key is available to subsequent host(s) in the chain of SSH &ldquo;hops&rdquo;.
The details of how to do this can vary depending on whether your local machine runs Windows, MacOS or Linux.
Whichever system you&rsquo;re using, you will need to use an appropriate tool to load your private key so that it can be presented at the time of logging in.
Linux and MacOS users: ssh-agent can be used (see instructions below).
Windows users: we recommend the MobAgent utility within MobaXterm. MobXterm is a linux terminal emulator for Windows.
ssh-agent is a utility that stores private keys and makes them available to other software that use the SSH protocol to connect to remote clients.
There are two stages to loading your private key into ssh-agent: starting the agent and then loading your private key. Use the following commands to do this:
IMPORTANT: The dollar symbol &lsquo;$&rsquo; at the start of the command line in these example represents the shell prompt as displayed in your terminal - it does not need to be typed!
eval $(ssh-agent -s) ssh-add ~/.ssh/id_rsa_jasmin Enter passphrase for /home/users/jpax/.ssh/id_rsa_jasmin: Identity added: /home/users/jpax/.ssh/id_rsa_jasmin (/home/users/jpax/.ssh/id_rsa_jasmin) When you run the ssh-add command you will be prompted to enter the passphrase that you specified when generating your SSH key pair. (If you use the c shell, replace the command &ldquo;eval $(ssh-agent -s)&rdquo; with &ldquo;exec ssh-agent $SHELL&rdquo;)
You can test whether your key has been loaded by using the &ldquo;-l&rdquo; option to list the currently loaded keys in your agent:
ssh-add -l 2048 SHA256:iqX3NkPCpschVdqPxVde/ujap2cM0mYaAYYedzBGPaI /Users/jpax/.ssh/id_rsa_jasmin (RSA) This confirms that the key in id_rsa_jasmin has been loaded and is ready for use.
Notes:
The ssh-agent session should persist until killed or until system shutdown, even if you close the terminal in which you set it up. It is very important that you protect your private key with a strong passphrase, known only to you. Keys must not be shared between individuals. If you get an error when attempting the above commands please see login problems. Your public key will have been automatically propagated by the JASMIN accounts system to all the machines to which you have access rights, so should already be present in the correct place. Do not attempt to place the public key manually on any host within JASMIN: it will get automatically overwritten. Mac users (OS X Leopard onwards) can optionally benefit from linking the SSH key to Keychain, which securely stores the passphrase as well. This means that even after a reboot, your SSH key is always available in any Terminal session automatically. See man ssh-add and look for the --apple-use-keychain or --apple-load-keychain options, if available (These replace the now- deprecated -K option).
The JASMIN login servers &nbsp; See this article for a description and listing of the login servers
Logging in to JASMIN &nbsp; Assuming that you have loaded your SSH private key using one of the methods described above, then you can login to a login server as follows (do this on your own/local machine):
ssh -A &lt;user_id&gt;@&lt;login_server&gt; For example, user &ldquo;jpax&rdquo; might login to the JASMIN login server with:
ssh -A jpax@login1.jasmin.ac.uk The -A argument is important because it enables &ldquo;agent-forwarding&rdquo;. This means that your the information about your SSH private key is forwarded to your remote session on the login server so that you can use it for further SSH connections. (Windows users can enable X-forwarding in MobaXterm saved sessions).
Can&rsquo;t login? &nbsp; Check our troubleshooting guide: login problems The login message &nbsp; When you first login you will see a message that provides some useful information (see Figure 1).
The login message shown on login1.jasmin.ac.uk. Note that in this case, the -A option enabling onward connections was omitted. X-forwarding for graphical applications (within JASMIN only) &nbsp; Some applications involve displaying graphical output from a remote server, typically to display plots or interace with a user interface. You can instruct your SSH connection to enable forwarding of X-server capability by adding the -X argument to the ssh command, as follows:
ssh -X &lt;user&gt;@&lt;hostname&gt; Note that the -X argument can be used in conjunction with the agent- forwarding-A argument. In some cases the -Y option may be needed instead of -X.
Please note that this arrangement sends your graphical output back to your desktop machine over the network, so should only be used within JASMIN, not to your local desktop machine. A solution has been put in place for a graphical linux desktop environment within JASMIN using NoMachine NX, removing the need to send X11 graphics over the wide-area network. You are strongly advised to use NX for any situation which involves graphical output on JASMIN. Using X11 graphics over the wide-area network outside of JASMIN is not supported: you will not get good performance and this makes inefficient use of shared resources which can impair performance for other users. Please use NX instead. Of course, you may still need to use X11 graphics to send graphical output back to your JASMIN-side graphical desktop within JASMIN, but this is OK as it is all within the JASMIN network.
Where next? &nbsp; Having been through all the steps and logged in to JASMIN (well done!) you will be keen to do some real work. You could try the general purpose scientific analysis servers to get started. Use the list presented on the login screen to select a sci server which is not under heavy usage.
For example, from the JASMIN login server, you might choose to login to sci1:
ssh &lt;user&gt;@sci1.jasmin.ac.uk If you are asked for a password when trying to login to this second machine, it indicates that your ssh key is not being forwarded. Please check that you have used the -A option in your initial connection to the login server, or set up agent forwarding permanently in your SSH client configuration on your local machine.
There is no point in trying to enter a password (or even the passphrase associated with your key) as only an ssh key presented in the way described above is accepted.
Note that once you are logged into a login server then you can omit the &lt;user_id&gt;@ prefix before the server name for the onward connection, since your username will be the same on both systems. But there is no harm in including it anyway, to ensure that you connect as the correct user. As shown above, the -A option is not needed for the onward connection, although there is no harm in including it.
Remember to log out of the login server in addition to the sci server when you have finished your work, to get back to your own (local) machine:
exit logout Connection to sci1.jasmin.ac.uk closed. exit logout Connection to login1.jasmin.ac.uk closed. # back on your own/local machine now`}).add({id:88,tag:"en",href:"/docs/batch-computing/how-to-monitor-slurm-jobs/",title:"How to monitor Slurm jobs",description:"How to monitor Slurm jobs",content:`Job information &nbsp; Information on all running and pending batch jobs managed by Slurm can be obtained from the Slurm command squeue. Note that information on completed jobs is only retained for a limited period. Information on jobs that ran in the past is via sacct. An example of the output squeue is shown below.
squeue JOBID PARTITION NAME USER ST TIME NODES NODELIST(REASON) 18957 short-ser mean user1 R 0:01 1 host147 18956 short-ser calc user2 R 48:38 1 host146 18967 test wrap user1 R 14:25 1 host146 where the field ST is the job state and the TIME is the time used by the job.
A batch job evolves in several states in the course of its execution. The typical job states are defined in Table 1
Table 1: Job states
Symbol Job state Description PD Pending The job is waiting in a queue for allocation of resources R Running The job currently is allocated to a node and is running CG Completing The job is finishing but some processes are still active CD Completed The job has completed successfully F Failed Failed with non-zero exit value TO Terminated Job terminated by Slurm after reaching its runtime limit S Suspended A running job has been stopped with its resources released to other jobs ST Stopped A running job has been stopped with its resources retained Slurm commands for monitoring jobs &nbsp; A list of the most commonly used commands and their options for monitoring batch jobs are listed in Table 2, below:
Table 2. List of important Slurm commands and their options for monitoring jobs
Slurm Command Description squeue To view information for all jobs running and pending on the cluster squeue --user=username Displays running and pending jobs per individual user squeue --states=PD Displays information for pending jobs (PD state) and their reasons squeues --states=all Shows a summary of the number of jobs in different states scontrol show job JOBID Shows detailed information about your job (JOBID = job number) by searching the current event log file sacct -b Shows a brief listing of past jobs sacct -l -j JOBID Shows detailed historical job information of a past job with jobID Inspection of job output files &nbsp; An example of the job output file from a simple job submitted to Slurm:
sbatch -p test --wrap=&#34;sleep 2m&#34; Submitted batch job 18973 scontrol show job 18973 JobId=18973 JobName=wrap UserId=fchami(26458) GroupId=users(26030) MCS_label=N/A Priority=1 Nice=0 Account=jasmin QOS=normal JobState=RUNNING Reason=None Dependency=(null) Requeue=1 Restarts=0 BatchFlag=1 Reboot=0 ExitCode=0:0 RunTime=00:00:08 TimeLimit=01:00:00 TimeMin=N/A SubmitTime=2020-05-20T14:10:28 EligibleTime=2020-05-20T14:10:28 AccrueTime=2020-05-20T14:10:28 StartTime=2020-05-20T14:10:32 EndTime=2020-05-20T15:10:32 Deadline=N/A SuspendTime=None SecsPreSuspend=0 LastSchedEval=2020-05-20T14:10:32 Partition=test AllocNode:Sid=sci2-test:18286 ReqNodeList=(null) ExcNodeList=(null) NodeList=host147 BatchHost=host147 NumNodes=1 NumCPUs=1 NumTasks=1 CPUs/Task=1 ReqB:S:C:T=0:0:*:* TRES=cpu=1,mem=128890M,node=1,billing=1 Socks/Node=*NtasksPerN:B:S:C=0:0:*:* CoreSpec=* MinCPUsNode=1 MinMemoryNode=128890M MinTmpDiskNode=0 Features=(null) DelayBoot=00:00:00 OverSubscribe=OK Contiguous=0 Licenses=(null) Network=(null) Command=(null) WorkDir=/home/users/fchami StdErr=/home/users/fchami/slurm-18973.out StdIn=/dev/null StdOut=/home/users/fchami/slurm-18973.out Power= History of jobs &nbsp; sacct JobID JobName Partition Account AllocCPUS State ExitCode ------------ ---------- ---------- ---------- ---------- ---------- -------- 18963 wrap par-single jasmin 1 COMPLETED 0:0 18964 wrap short-ser+ jasmin 1 COMPLETED 0:0 18965 wrap par-single jasmin 1 COMPLETED 0:0 18966 wrap short-ser+ jasmin 1 COMPLETED 0:0`}).add({id:89,tag:"en",href:"/docs/batch-computing/how-to-submit-a-job/",title:"How to submit a job",description:"How to submit a job to Slurm",content:`This article explains how to submit a batch job to the new scheduler Slurm.
What is a batch job? &nbsp; A batch job is controlled by a script written by the user who submits the job to the batch system Slurm. The batch system then selects the resources for the job and decides when to run the job. Note: the term &ldquo;job&rdquo; is used throughout this documentation to mean a &ldquo;batch job&rdquo;.
There are two ways of submitting a job to Slurm:
Submit via a Slurm job script - create a bash script that includes directives to the Slurm scheduler Submit via command-line options - provide directives to Slurm via command-line arguments Both options are described below.
Which servers can you submit jobs from? &nbsp; Jobs can be submitted to Slurm from the following Sci machines:
sci1.jasmin.ac.uk sci2.jasmin.ac.uk sci3.jasmin.ac.uk sci4.jasmin.ac.uk sci5.jasmin.ac.uk sci6.jasmin.ac.uk sci8.jasmin.ac.uk Method 1: Submit via a Slurm job script &nbsp; The Slurm job submission command is:
sbatch myjobscript The job script is a Bash script of user&rsquo;s application and includes a list of Slurm directives, prefixed with #SBATCH as shown in this example:
#!/bin/bash #SBATCH --partition=short-serial #SBATCH -o %j.out #SBATCH -e %j.err #SBATCH --time=05:00 # executable sleep 5mFor job specification of resources please refer to Table 2 of the help article LSF to Slurm quick reference
Method 2: Submit via command-line options &nbsp; If you have an existing script, written in any language, that you wish to submit to LOTUS then you can do so by providing Slurm directives as command- line arguments. For example, if you have a script &ldquo;my-script.py&rdquo; that takes a single argument &ldquo;-f &rdquo;, you can submit it using &ldquo;sbatch&rdquo; as follows:
sbatch -p short-serial -t 03:00 -o job01.out -e job01.err my-script.py -f myfile.txtThis approach allows you to submit jobs without writing additional job scripts to wrap your existing code.
Method 3: Submit an interactive session via salloc &nbsp; Testing a job on LOTUS can be carried out in an interactive manner by obtaining a Slurm job allocation or resources (a set of nodes) via the Slurm command salloc . The code/application is executed and the allocation are released after a specific time -default 1 hour - when the testing is finished. There are two ways:
Interactive execution with pseudo-shell terminal on the compute LOTUS node &nbsp; The job is executed on the LOTUS compute node by invoking the Slurm command srun after allocating resources with salloc. See example below.
salloc -p par-single --ntasks-per-node=2 salloc: Pending job allocation 23506 salloc: job 23506 queued and waiting for resources salloc: job 23506 has been allocated resources salloc: Granted job allocation 23506The job allocation ID 23506 has 2 CPUs on the compute node host580 as shown below:
squeue -u train001-o&#34;%.18i %.9P %.11j %.8u %.2t %.10M %.6D %.6C %R&#34; JOBID PARTITION NAME USER ST TIME NODES CPUS NODELIST(REASON) 23506 par-singl interactive usertest R 1:32 1 2 host580To launch an interactive shell session on the compute node host580, use the following srun command (from a sci server).
srun --pty /bin/bash @host580 ~]$ Interactive execution with no shell &nbsp; A code/application can be executed on the LOTUS compute node without a shell session on the node itself. For example the command &lsquo;hostname&rsquo; is executed twice as there are 2 CPUs and this outputs the name of the node
srun hostname host580.jc.rl.ac.uk host580.jc.rl.ac.uk Job array submission &nbsp; Job arrays are groups of jobs with the same executable and resource requirements, but different input files. Job arrays can be submitted, controlled, and monitored as a single unit or as individual jobs or groups of jobs. Each job submitted from a job array shares the same job ID as the job array and is uniquely referenced using an array index. This approach is useful for ‘high throughput&rsquo; tasks, for example where you want to run your simulation with different driving data or run the same processing task on multiple data files.
Important note: The maximum job array size that Slurm is configured for is MaxArraySize = 10000. If a Job array of size is greater than 10000 is submitted, Slurm will reject the job submission with the following error message: &ldquo;Job array index too large. Job not submitted.&rdquo;
Taking a simple R submission script as an example:
#!/bin/bash #SBATCH --partition=short-serial #SBATCH --job-name=myRtest #SBATCH -o %j.out #SBATCH -e %j.err #SBATCH --time=30:00 module add jasr Rscript TestRFile.R dataset1.csvIf you want to run the same script TestRFile.R with input file dataset2.csv through to dataset10.csv, you could create and submit a job script for each dataset. However, by setting up an array job, you could create and submit a single job script.
The corresponding job array script to process 10 input files in a single job submission would look something like this:
#!/bin/bash #SBATCH --partition=short-serial #SBATCH --job-name=myRarray #SBATCH -o %A_%a.out #SBATCH -e %A_%a.err #SBATCH --time=30:00 #SBATCH --array=1-10 module add jasr Rscript TestRFile.R datset$Slurm_ARRAY_TASK_ID.csvHere the important differences are :
The array is created by Slurm directive --array=1-10 by including elements numbered [1-10]to represent our 10 variations The error and output file have the array index %a included in the name and %A is the job ID. The environment variable $Slurm_ARRAY_TASK_ID in the Rscript command is expanded to give the job index When the job is submitted, Slurm will create 10 tasks under the single job ID. The job array script is submitted in the usual way:
sbatch myRarray.sbatchIf you use the squeue -u &lt;username&gt; command to list your active jobs, you will see 10 tasks with the same Job ID. The tasks can be distinguished by the [index] e.g. jobID_index. Note that individual tasks may be allocated to a range of different hosts on LOTUS.`}).add({id:90,tag:"en",href:"/docs/batch-computing/how-to-submit-an-mpi-parallel-job/",title:"How to submit an MPI parallel job",description:"How to submit an MPI parallel job",content:`This article explains the submission of an MPI parallel job to Slurm/ LOTUS.
What is an MPI parallel job? &nbsp; An MPI parallel job runs on more than one core and more than one host using the Message Passing Interface (MPI) library for communication between all cores. A simple script, such as the one given below &ldquo;my_script_name.sbatch &quot;
#!/bin/bash #SBATCH -p par-multi #SBATCH -n 36 #SBATCH -t 30 #SBATCH -o %j.log #SBATCH -e %j.err # Load a module for the gcc OpenMPI library (needed for mpi_myname.exe) module load eb/OpenMPI/gcc/4.0.0 # Start the job running using OpenMPI&#39;s &#34;mpirun&#34; job launcher mpirun ./mpi_myname.exe-n refers to the number of processors or cores you wish to run on. The rest of the #SBATCH input options, and many more besides, can be found in the sbatch manual page or in the related articles. You must only use the par- multi queue for parallel jobs using MPI.
For those familiar with LOTUS running Platform MPI and Platform LSF, please note that the job is started using the OpenMPI native &ldquo;mpirun&rdquo; command not the &ldquo;mpirun.lotus&rdquo; wrapper script that was previously required. We have provided an mpirun.lotus script for backward compatiblity but it just runs the native mpirun
To submit the job, do not run the script, but rather use it as the standard input to sbatch, like so:
sbatch --exclusive my_script_name.sbatchThe --exclusive flag is used to group the parallel jobs onto hosts which are allocated only to run this job. This ensures the best MPI communication consistency and bandwidth/latency for the job and ensures no interference from other users&rsquo; jobs that might otherwise be running on those hosts.
MPI implementation and Slurm &nbsp; The OpenMPI library is the only supported MPI library on the cluster. OpenMPI v3.1.1 and v4.0.0 are provided which are fully MPI3 compliant. MPI I/O features are fully supported only on the LOTUS /work/scratch-pw* volumes as these use a Panasas fully parallel file system. The MPI implementation on CentOS7 LOTUS/Slurm is available via the module environment for each compiler as listed below:
eb/OpenMPI/gcc/3.1.1 eb/OpenMPI/gcc/4.0.0 eb/OpenMPI/intel/3.1.1Note: OPenMPI Intel compiler is due shortly as is 4.0.3
Parallel MPI compiler with OpenMPI &nbsp; Compile and link to OpenMPI libraries using the mpif90, mpif77, mpicc, mpiCC wrapper scripts which are in the default unix path. The scripts will detect which compiler you are using (Gnu, Intel) by the compiler environment loaded and add the relevant compiler library switches. For example:
module load intel/20.0.0 module load eb/OpenMPI/intel/3.1.1 mpif90will use the Intel Fortran compiler ifort and OpenMPI/3.1.1. Whereas
module load eb/OpenMPI/gcc/3.1.1 mpiccwill call the GNU C compiler gcc and OpenMPI/3.1.1.
The OpenMPI User Guides can be found at https://www.open-mpi.org/doc/.`}).add({id:91,tag:"en",href:"/docs/data-transfer/hpxfer-access-role/",title:"hpxfer access role",description:"Access to certain high-performance data transfer methods",content:`This article explains about access to high-performance data transfer services.
Applying for access &nbsp; Some data transfer services are hosted in the JASMIN Data Transfer Zone (a special area of JASMIN&rsquo;s network, located optimally for connections to the outside world via JANET&nbsp; ) for increased performance. However, to maintain security in this zone, access to some services is controlled via an additional access role hpxfer. If you have a login account already, you can apply here for this additional role:
Apply for hpxfer&nbsp; &nbsp; &nbsp; Additional information required &nbsp; If you will be connecting from your home institution directly via ssh or ssh- based gridftp to one of the servers in the JASMIN Data Transfer Zone, the specific IP address of your machine will need to be added to an allow-list. Please supply this as part of the application process above.
However, this should not be necessary if you are accessing the server from a remote server which is already allowed.
&nbsp; If your only reason for applying for hpxfer is in order to use the Globus service on JASMIN, this is no longer required. You only need this role for accessing the hpxfer servers or for using certificate-based gridftp with the globus-url-copy command. Inward pulls of data (to JASMIN) are possible by logging in to hpxfer[1,2].jasmin.ac.uk via the login servers and pulling data from external data sources. So if you&rsquo;re not sure what IP address to use when applying for access above, it is OK to quote the IP address of login1.jasmin.ac.uk, i.e. 130.246.130.28 as a &ldquo;dummy&rdquo; value if you will only be accessing them via this route, and not directly from outside.`}).add({id:92,tag:"en",href:"/docs/software-on-jasmin/idl/",title:"IDL",description:"IDL",content:`This article explains how to:
use the IDL software on JASMIN run these tools on the scientific analysis servers and LOTUS make efficient use of the IDL licences What is IDL? &nbsp; IDL stands for Interactive Data Language. It is a licensed data manipulation toolkit made available on JASMIN.
Availability of IDL on JASMIN &nbsp; IDL is available on all scientific analysis servers and LOTUS.
&nbsp; The related software MIDL is no longer available on JASMIN To get started with IDL, login to one of scientific analysis servers and do as follows:
module load idl idl IDL Version 8.5 (linux x86_64 m64). (c) 2015, Exelis Visual Information Solutions, Inc., a subsidiary of Harris Corporation. Installation number: 406672. Licensed for use by: Science &amp; Technology Facilitie You can then type commands at the IDL prompt
print,1+4 5 exit For help on the idl module you can type the following :
module help idl ----------- Module Specific Help for &#39;idl/8.2&#39; -------------------- Adds IDL 8.2 to your environment variables, Making efficient use of IDL development licences &nbsp; We have a large pool of run-time licences but a much more limited pool of development licences. In each case, these consist of floating licences shared between JASMIN sci machines and the LOTUS cluster.
Users are welcome to run multiple instances of IDL code, but for that purpose please make use of the run-time licences by compiling your code using a single development session and then running the pre-compiled code using the -rt flag. An example of this is shown in the next section (below).
Please try not to run more than one or two simultaneous IDL development sessions. However, for licence purposes, each unique combination of username, hostname, and $DISPLAY variable counts as a single session. So for example, if you run idl (development mode) in one window, then suspend it with CTRL-Z and start another development session in the same window, this still is only counted as one session by the licence server because the username, hostname, and $DISPLAY are all identical between the two processes. But if you &ldquo;ssh&rdquo; in on two different windows, probably the $DISPLAY will differ between the two windows (e.g. localhost:10 and localhost:11), so if you start idl development sessions in each window they will require separate licences.
To see what licences you and others are using, you can use the following sequence of commands:
module add idl/8.2 lmstat -a When interpreting the numbers, note that a single session is counted as 6 licences.
Using IDL on LOTUS (via the run-time Licences) &nbsp; IDL run-time licences are available for use on the LOTUS cluster. In order to specify use of the run-time licences please follow the instructions here. You need to compile your IDL code in order to run in run-time mode.
Example program &nbsp; The example program, &ldquo;foo&rdquo;, depends on some other functions.
======== foo.pro ======= pro foo print, doubleit(10) end ======================== ===== doubleit.pro ===== function doubleit, n return, two() * n end ======================== ======= two.pro ======== function two return, 2 end ========================You must save a compiled version of the code in order to run it.
1. Compile the program:
Compiles top-level routine only
.compile foo % Compiled module: FOO. 2. Use resolve_all to compile routines it depends on:
Recursively search for and compile modules called
resolve_all % Compiled module: DOUBLEIT. % Compiled module: TWO. 3. Save all compiled routines to a file:
save, /routines, file=&#39;foo.sav&#39; 4. To run the program, using a run-time licence only:
idl -rt=foo.sav IDL Version 8.4 (linux x86_64 m64). (c) 2014, Exelis Visual Information Solutions, Inc. Installation number: 406502. Licensed for use by: Science &amp; Technology Facilities 20 &nbsp; Using -vm= instead of -rt= opens the save file in the IDL virtual machine. No run-time licence is required, but a splash screen must be dismissed interactively, so it is not suitable for queues on the cluster. To see what routines are present in the save file:
.reset_session &lt;=== removes any existing compiled modules help &lt;=== show compiled modules (and variables); there shouldn&#39;t be any #% At $MAIN$ #Compiled Procedures: #$MAIN$ #Compiled Functions: restore,&#39;foo.sav&#39; &lt;=== load contents of save file help % At $MAIN$ Compiled Procedures: $MAIN$ FOO &lt;=== this was loaded from foo.sav Compiled Functions: DOUBLEIT TWO &lt;=== so were these Passing arguments &nbsp; You can also pass arguments in to your code as follows:
In your code, use function command_line_args, for example:
argsarray = command_line_args(count = nparams)Call the code with -args flag:
idl -rt=foo.sav -args 10 20 30 command_line_args returns a string array, so convert type as required, e.g. n = fix(argsarray[0]) Further reading &nbsp; Vendor documentation: Using IDL&nbsp; (although may be for a newer version than on JASMIN)`}).add({id:93,tag:"en",href:"/tags/import/",title:"Import",description:"",content:""}).add({id:94,tag:"en",href:"/docs/short-term-project-storage/install-xfc-client/",title:"Install XFC client",description:"Install XFC client",content:`XFC client install &nbsp; In order to initiate and manage your usage of the XFC (transfer cache) service, you need to use the XFC client.
Once set up, you don&rsquo;t need to use this client to read/write data to XFC storage itself, but you can use it to interrogate the system to find out what data you have stored and how much of your quota(s) you are using.
The following steps should be used to create a python virtual environment and pip to install the xfc client:
NOTE: do these steps on one of the sci (not xfer) servers:
Log into one of the sci machines: e.g. sci1.jasmin.ac.uk (1 - 8 is available) The xfc client can be used with Python 3 using jaspy. module load jaspy Setup a virtual environment in your home directory:
python -m venv ~/xfc_venv The following steps for Python 2 and Python 3 are now the same. Activate the virtual environment: source ~/xfc_venv/bin/activate Download the client software using git to your home directory: git clone https://github.com/cedadev/xfc_client.git pip install the xfc client pip install -e ~/xfc_client Use xfc on the command line xfc -h Users who already have a Python virtual environment can skip step 2 and install into an existing virtual environment.
The recommendation for users using NLA, XFC and JDMA is to create a single virtual environment to install all 3 client applications into.
The xfc client can be used without activating the python virtualenv by adding the path to the xfc client to the $PATH$ environment variable:
export PATH=&#34;$PATH:~/xfc_venv/bin&#34; \` echo &#39;export PATH=&#34;$PATH:~/xfc_venv/bin&#34;&#39; &gt;&gt; &#34;$HOME/.bashrc&#34; The xfc client can now be used by invoking xfc from the command line without activating the virtualenv. Python 3 users load jaspy using the command module load jaspy
For instructions on how to use the xfc client, see the article JASMIN Transfer Cache (XFC).`}).add({id:95,tag:"en",href:"/tags/intel/",title:"Intel",description:"",content:""}).add({id:96,tag:"en",href:"/docs/interactive-computing/",title:"Interactive computing",description:"How to use interactive computing resources",content:""}).add({id:97,tag:"en",href:"/docs/interactive-computing/interactive-computing-overview/",title:"Interactive computing overview",description:"Interactive computing overview",content:`This article introduces the resources on JASMIN available for interactive computing (as opposed to batch computing). It covers:
Login servers Scientific Analysis servers Data Transfer Servers Project Specific Servers Login Severs &nbsp; The login (also known as gateway or bastion) servers provide external* users with access to services inside of JASMIN.
*external = outside of the STFC/RAL firewall.
Scientific Analysis Servers &nbsp; The scientific analysis servers are the main resource for most users&rsquo; everyday work. They have a standardised software environment and are ideal for development and testing of processing tasks which can then be submitted to the LOTUS batch processing cluster for larger processing runs.
Data Transfer Servers &nbsp; General data transfer servers are provided for simple or smaller data transfer tasks. For larger data flows or where high performance is required, more sophisticated tools and services are available. Please read the guides in consult the data transfer category for more details.
Project-Specific Servers &nbsp; In some cases in the past, project requirements were not met by the general resources provided above and project-specific servers were provided. However these are now deprecated as in most cases, a tenancy in the JASMIN Cloud should provide what&rsquo;s needed.`}).add({id:98,tag:"en",href:"/training/intermediate/",title:"Intermediate",description:"Training exercises on intermediate topics",content:`Watch this space &nbsp; We&rsquo;ll be adding more content soon, as we reorganise the JASMIN help content further.
For now, please see JASMIN Training Workshop materials&nbsp; .`}).add({id:99,tag:"en",href:"/docs/for-cloud-tenants/introduction-to-the-jasmin-cloud/",title:"Introduction to the JASMIN Cloud",description:"Introduction to the JASMIN Cloud",content:`In addition to the traditional batch computing (LOTUS) and storage (Group Workspaces) services, JASMIN also provides a cloud computing service.
Many users will already be familiar with cloud services through the use of one of the large public providers (e.g. Amazon AWS or Microsoft Azure). The JASMIN Cloud is similar in that it allows an institution or project to consume compute resources as a utility, with no need to provision and maintain the associated physical infrastructure. Users can provision their own virtual machines (VMs) within the JASMIN infrastructure, allowing for greater flexibility. The JASMIN Cloud also allows users to provision clusters for Identity Management, Kubernetes, and Slurm clusters amongst others (see Cluster-as-a-Service).
The thing that makes the JASMIN Cloud unique is its colocation with the CEDA Archive and Group Workspaces. The JASMIN Cloud is ideally suited to projects that work with such data, and can enable novel solutions for the manipulation and presentation of data to end-users.
Cloud terminology &nbsp; Different cloud providers have different terms for the users within their cloud and the chunks of resource they have been allocated. In the JASMIN Cloud documentation, we will use the following terminology:
Tenancy: An allocation of resources, i.e. virtual CPUs, RAM and block storage, within the cloud. Tenant: A group (institution or project) that has been allocated a tenancy in the cloud. Tenancy Admin(istrator): The person designated as the administrator of a tenancy. There would usually also be a deputy administrator. JASMIN Cloud Architecture &nbsp; In order to provide as much flexibility as possible for tenants while preserving the security of the system, the JASMIN Cloud is split into two parts (see the schematic below). Both parts of the JASMIN Cloud are administered through the same self-service portal, allowing tenancy admins to provision VMs as required, within the quota of their tenancy.
jasmin cloud achitecture The JASMIN External Cloud is an Infrastructure-as-a-Service (IaaS) offering, and sits outside of the main JASMIN firewall. Tenants are allowed root access and have complete responsibility for all system administration tasks. This means that tenants are able to provision their own infrastructure (e.g. web portals, remote desktop services), but it also means that tenants are responsible for the security of their machines (e.g. patching, firewall configuration) and for managing their own users. Because it is outside of the JASMIN firewall, tenancies in the External Cloud cannot directly access the JASMIN storage (including PFS, and SOF), and so there is no filesystem level access to the CEDA Archive or Group Workspaces - all access to these data is via the usual external interfaces (i.e. the Object Store, FTP, OpenDAP, HTTP). We also have our Cluster-as-a-Service available to external cloud tenants which is a Platform-as-a-Service offering that tenants can use to deploy clusters including, an identity cluster, storage cluster (NFS), and a Kubernetes cluster.
External Cloud patching policy &nbsp; &nbsp; We expect tenants to react in a timely manner to any security vulnerabilities. This means critical vulnerabilities are patched within 7 days, and high vulnerabilities are patched within 14 days. This is following UKRI security policy. Failure to comply may result in tenancy access being revoked and machines powered down. By contrast, the JASMIN Managed Cloud is a Platform-as-a-Service (PaaS) offering, sitting inside the main JASMIN firewall, meaning it can reach the JASMIN storage. In order to preserve security, this means that tenants are not allowed root access, and can only deploy VMs from a limited set of pre- approved templates. However, tenants are not responsible for the security of these machines, and users on VMs within the tenancy are JASMIN users. Currently, only two templates are available - an SSH bastion, or login machine, and a Scientific Analysis server with a similar configuration to the shared JASMIN Scientific Analysis servers. The Scientific Analysis servers have the CEDA Archive and Group Workspaces mounted.
Both offerings have a similar network structure. Each tenancy has its own local network, where machines have addresses in the 192.168.3.0/24 range - all machines in the tenancy can talk to each other on this network. In addition, each tenancy has an &ldquo;edge device&rdquo;, which is effectively a virtual router. Similarly to your home broadband router, this allows machines within the tenancy to talk to machines outside the tenancy, and ensures packets coming back into the tenancy are forwarded to the correct machine. These &ldquo;edge devices&rdquo; also provide a Network Address Translation (NAT) facility, which allows machines to be allocated an IP address that is visible outside of the tenancy. In the Managed Cloud, this translates to an IP address that is visible on the JASMIN network. In the External Cloud, it translates to an IP address that is visible on the public internet.
External vs. Managed - pros and cons &nbsp; Attribute Managed Cloud External Cloud Self-service provisioning Yes Yes Filesystem level access to JASMIN Storage (PFS, SOF) Yes No Root access No Yes Provision custom infrastructure SSH bastion or Scientific Analysis server only Build from generic Ubuntu or CentOS templates Security and patching Handled by infrastructure team Tenant&rsquo;s responsibility User management JASMIN users Tenant&rsquo;s responsibility Visibility to public internet No Yes (limited number of external IPs) Ability to provision Cluster-as-a-Service No Yes Getting a JASMIN Cloud Tenancy &nbsp; To start a conversation with us about getting a JASMIN Cloud Tenancy for your project, please contact JASMIN Support.`}).add({id:100,tag:"en",href:"/tags/jap/",title:"Jap",description:"",content:""}).add({id:101,tag:"en",href:"/tags/jasmin/",title:"JASMIN",description:"",content:""}).add({id:102,tag:"en",href:"/docs/for-cloud-tenants/jasmin-cloud-portal/",title:"JASMIN Cloud Portal",description:"JASMIN Cloud Portal",content:`The JASMIN Cloud Portal&nbsp; is a web interface that enables the self-service provisioning of virtual machines in the JASMIN Cloud.
Currently, it is built on top of VMware VIO Horizon. Horizon is a powerful tool for provisioning cloud tenancies but is easy to misconfigure. The JASMIN Cloud Portal focuses on simplicity, allowing users to quickly provision the machines they require.`}).add({id:103,tag:"en",href:"/docs/uncategorized/jasmin-conditions-of-use/",title:"JASMIN Conditions of Use",description:"JASMIN Conditions of Use",content:"Please refer to the JASMIN Terms and Conditions of Access"}).add({id:104,tag:"en",href:"/",title:"JASMIN Help site",description:"Documentation and training resources for JASMIN - the UK's data analysis facility for environmental science.",content:""}).add({id:105,tag:"en",href:"/docs/interactive-computing/jasmin-notebooks-service/",title:"JASMIN Notebooks Service",description:"Jupyter Notebooks service on JASMIN",content:`The JASMIN Notebooks Service provides access to Jupyter Notebooks in the web browser.
What is a Jupyter Notebook? &nbsp; A Jupyter Notebook is an interactive document containing live code and visualisations that can be viewed and modified in a web browser. These documents can be shared, often using GitHub, and many projects distribute example code as Jupyter notebooks. Users interact with their notebooks using the open-source Jupyter Notebook server application.
Jupyter has support for many languages including Python, R, Scala and Julia, which are implemented by plugins known as &ldquo;kernels&rdquo;. The JASMIN Notebook Service currently provides one kernel - Python 3.10 with the latest Jaspy software environment installed. This environment is active by default, so there is no need for the module commands described in the linked article. You can also install and use your own Python environments as explained below.
The JASMIN Notebook Service uses JupyterHub to manage multiple Jupyter Notebook servers. After authenticating with a JASMIN account (with the correct access), a user gets access to their own notebook server. The notebook server runs as the authenticated user, and the user can access their home directory, Group Workspaces and CEDA Archive data as they would from a scientific analysis server.
Getting access to the JASMIN Notebook Service &nbsp; In order to access the JASMIN Notebook service, first, follow the steps in Getting started with JASMIN to get a JASMIN account and the jasmin-login service.
&nbsp; From 16/6/2021, access to the JASMIN Jupyter Notebook service is controlled simply by having a valid jasmin-login grant. 2-step verification is still required as shown below, but it is no longer necessary to apply for and be granted the additional jupyter-notebooks role, which is now deprecated. Using the JASMIN Notebook Service &nbsp; To use the JASMIN Notebook Service, navigate to https://notebooks.jasmin.ac.uk. This will redirect you to the JASMIN Accounts Portal, where you should sign in with your JASMIN Account. If you have previously accessed the notebook service from the computer you are using, this may happen automatically.
The first time you access the JASMIN Notebook Service from a new computer or browser, you will be asked to verify your email address after signing in. To do this, make sure the &ldquo;Email&rdquo; method is selected and click &ldquo;Send me a code&rdquo;:
Sign in with 2-factor authentication This will result in an email being sent to your registered email address containing a six-digit verification code. Enter this code and press &ldquo;Verify code&rdquo;. Each code lasts between 15 and 30 minutes.
Upon successfully signing in and verifying your email if required, you will be redirected back to the JASMIN Notebook Service. The service will then create a notebook server for you to use, and you will see a loading page:
Loading page After a few seconds, or in some rare cases a minute or two, you will be taken to the JupyterLab interface:
JupyterLab interface The folder shown in the left-hand panel will be your home directory on JASMIN, exactly as if you had logged in to a scientific analysis server. Any changes made in JupyterLab will be immediately reflected on the scientific analysis servers and LOTUS, and vice-versa. You can then launch, edit and run Python notebooks using the JupyterLab interface. Notebooks can access files from the CEDA Archive, and also have read-only access to group workspaces. For example, this notebook reads a file belonging to the CCI project from the CEDA Archive and plots the data on a map:
Example notebook A full discussion of the power of the JupyterLab interface is beyond the scope of this documentation, but the JupyterLab documentation is excellent, and there are many tutorials available on the internet.
Intended usage and limitations &nbsp; The JupyterLab environment provided by the JASMIN Notebooks Service is powerful, but it has some limitations that reflect the type of usage that we want to encourage.
The JASMIN Notebooks Service is primarily intended for interactively producing visualisations of existing data, not for processing vast amounts of data. As such, the resources made available to each notebook server are limited.
For larger processing tasks with Notebooks, users should consider using the JASMIN Dask Gateway service&nbsp; , which provides an easy way for processing managed from within a Jupyter Notebook to be scaled out to multiple LOTUS jobs in parallel.
Alternatively, use the LOTUS batch processing cluster separately, before using the notebooks service to visualise the output.
Doing this means that the bulk of the resource usage will be shared by the LOTUS cluster rather than the Notebooks service itself.
&nbsp; Although it was previously the case that Group Workspaces were only available in Notebooks read-only, this is no longer the case (as of 2023), so you should have full read-write access to any group workspace volume. Common issues and questions &nbsp; I get &ldquo;403 forbidden&rdquo; when I try to access the JASMIN Notebook Service &nbsp; This error occurs when you do not have the correct permissions to access the JASMIN Notebook service. Please ensure you have been granted the jasmin-login and allow some time for the changes to propagate through the system.
Which software environment is used by the Notebook Service? &nbsp; The JASMIN Notebook Service currently uses the default Jaspy environment listed on the Jaspy page.
Can I install additional packages? &nbsp; The recommended way to do this is to create your own virtual environment in the notebooks service and install additional packages into that. You can make that virtual environment persist as a kernel to use again next time you use the Notebooks service.
If you believe that the package is more widely applicable, you can request an update to Jaspy.
Can I use a different software environment? &nbsp; Yes, the article linked above also describes how to use Conda to create your own custom environment.
I get &ldquo;503 service unavailable&rdquo; when I try to access the JASMIN Notebook &nbsp; Service
This error occurs when your notebook server is unable to start. By far the most common cause of this error is when you are over your quota in your home directory. As part of starting up, Jupyter needs to create some small files in your home directory in order to track state. When it is unable to do this because you are over your quota, you will see the &ldquo;503 service unavailable&rdquo; error.
If you see this error, try connecting to JASMIN using SSH and checking your home directory usage. After clearing some space in your home directory, your notebook server should be able to start again.
I get the following message when my notebook is queued for spawning &nbsp; Error message The message above indicates that the Notebook service is oversubscribed -busy- and there are no resources available to start your Notebook server. Please try again later!
Please use the scientific analysis server and LOTUS for processing and Jupyter Notebook for lighter visualisation.
Example Notebooks &nbsp; In support of the JASMIN Notebook Service, we have developed a GitHub repository with a collection of Notebooks that demonstrate some of the important features of the service. The following provides a general introduction:
https://github.com/cedadev/ceda-notebooks/blob/master/notebooks/training/intro/notebook-tour.ipynb
Other Notebooks can be found within the repository, under:
https://github.com/cedadev/ceda-notebooks/tree/master/notebooks
Webinar / video tutorial &nbsp; A CEDA webinar on 16th June 2020 demonstrated how to use the service. A recording of the event is available:
Further info &nbsp; Here are a set of links to learn more about Jupyter Notebooks and the JASMIN Notebook Service:
The JASMIN Notebook Service Intro to Jupyter Lab Try a Jupyter Lab Notebook in your browser (this link does not use the JASMIN Notebook Service) Tour of the JASMIN Notebook Service - set of notebooks highlighting different features Intro to the JASMIN Notebook Service - video of a webinar from June 2020 Instructions to create a Python virtual environment - example notebook Instructions to create a Conda environment for use with the Notebook Service - example notebook`}).add({id:106,tag:"en",href:"/docs/software-on-jasmin/software-migration-2020/",title:"JASMIN software changes: migration to CentOS7 (2020)",description:"JASMIN software changes: migration to CentOS7 (2020)",content:`&nbsp; This article is now out of date, but a similar exercise is about to get underway for the migration of the JASMIN platform from CentOS7 operating system (end of life June 2024) to Rocky Linux 9. Look out for futher details in due course. Introduction &nbsp; This article explains the changes in the provision of common software on JASMIN (&ldquo;sci&rdquo; servers and LOTUS) when upgrading to main operating system from RedHat Enterprise Linux 6 (RHEL6) to CentOS7. It answers for the following questions:
What is changing? &nbsp; The upgrade from RHEL6 to introduces a new way of working with software environments on JASMIN.
The previous system involved installations via RPM using a collection of packages known as the &ldquo;JASMIN Analysis Platform&rdquo; (JAP).
The current system uses two approaches to providing software environments and packages:
Jaspy environments – a collection of software environments that you can &ldquo;activate&rdquo; for use. &ldquo;jasmin-sci&rdquo; environment – a single set of software packages installed separately because they were difficult to include in Jaspy. Which systems are affected? &nbsp; This change applies to all generally available JASMIN servers and the LOTUS cluster. These include:
jasmin-sci* cems-sci* jasmin-cylc cron All LOTUS nodes (accessed via LSF) Why is it changing? &nbsp; The reason for moving away from the JAP was to provide a system that could support multiple versions of software packages, and environments, on a single platform. From the perspective of reproducible science, the Jaspy approach is more useful because it:
keeps previous environments on the system when a new version of an environment is launched includes a listing of all packages (and their versions) that are provided in each date-stamped software environment From a management point-of-view, Jaspy builds on the packaging tool &ldquo;conda&rdquo; and the community repositories known as &ldquo;conda-forge&rdquo;. These tools are widely used in the scientific community and provide many components that are re-used in Jaspy.
Comparison of packages in old JASMIN Analysis Platform and new Jaspy/&ldquo;jasmin-sci&rdquo; environments &nbsp; Most packages that were previously provided as part of the JASMIN Analysis Platform (JAP) are now included in Jaspy environments or the &ldquo;jasmin-sci&rdquo; environment. Some packages have however been dropped. The treatment of certain packages is documented on the &ldquo;extra-sci- packages&rdquo; GitHub repository. A full table of packages that were in JAP and their mappings to Jaspy/&ldquo;jasmin- sci&rdquo; is provided below.
How do I get started (quickly)? &nbsp; If you want to access most of the packages you can find them in the most recent Jaspy environment. This can be activated using:
module load jaspyIf you need packages that are provided in the &ldquo;jasmin-sci&rdquo; environment then you can activate it using:
module load jasmin-sci Full table of packages from JAP &nbsp; Here is a full table of packages that were provided via JAP, and how they are provided for use on CentOS7 machines (as of initial release).
In the summary column:
C - package is provided via Conda environment (i.e. Jaspy) R - package is provided via an RPM (as part of the base OS or via jasmin-sci) CR - package is provided both via Jaspy and via an RPM. The version in Jaspy is recommended for use with user code; the RPM version is also installed in order to satisfy an RPM dependency only, and may be subject to change. N - not provided (mostly these have been deprecated by the third-party sources) NAME (in JAP) Version in Jaspy 3.7 (conda) Version in Jaspy 2.7 (conda) Version in RPMs (base or jasmin-sci SCL) Summary: (C)onda/ (R)PM / (N)one Comments arpack 3.6.3 3.6.3 C atlas 3.8.4 3.10.1 R atlas-devel 3.8.4 3.10.1 R bbcp N deprecated bbcp-config N deprecated blas 1.1 1.0 C boost-devel 1.70.0 C cdo 1.9.5 C cmip6-cmor-tables N groups advised to maintain own CMOR cmor-libs N groups advised to maintain own CMOR coda 0.19_1 C ddd 3.3.12 R diffuse 0.4.8 R dvipng 1.14 R package texlive-dvipng-svn26689 eccodes 2.9.2 C eccodes-devel 2.9.2 C eccodes-fortran 2.9.2 C eccodes-python27 2.9.2 C emacs 26.1 24.3 R emacs is broken in jaspy 2.7 - /usr/bin/emacs may be required to override emacs-common-ess N might provide later emacs-ess N might provide later emacs-ess-el N might provide later emacs-gnuplot 4.6.2 R emos N deprecated esmf 7.1.0r 7.1.0r C esmf-doc N See here and ESMF_refdoc esmf-python27 7.1.0r 7.1.0r C ferret 7.5.0 R fftw 3.3.8 3.3.8 C fftw-devel 3.3.8 3.3.8 C firefox N flex-devel 2.6.4 C gcc-gfortran 4.8.5 R gdal 2.2.4 2.0.0 C gdal-devel N gdal provided as &ldquo;gdal&rdquo; gdal-doc N gdal provided as &ldquo;gdal&rdquo; gdal-java N gdal-javadoc N gdal-libs N gdal-perl N gdal-python27 2.2.4 2.0.0 C geany 1.31 R geos 3.6.2 3.7.1 C geos-devel 3.6.2 3.7.1 3.4.2 R git 2.20.1 2.20.1 C gitk 1.8.3.1 R glibc-static 2.17 R gnuplot 4.6.2 R grads 2.0.2 R GraphicsMagick-c++ 1.3.32 R graphviz 2.38.0 2.38.0 C graphviz-gd N graphviz-python27 2.38.0 2.38.0 C grass 6.4.4 R grass-devel 6.4.4 R grass-libs 6.4.4 R grib_api N deprecated - use eccodes grib_api-devel N deprecated - use eccodes grib_api-fortran N deprecated - use eccodes grib_api-python27 N deprecated - use eccodes gsl 2.2.1 2.5 C gsl-devel 2.2.1 2.5 C gsl-static 2.2.1 2.5 C gtk2 2.24.31 C gtk2-devel 2.24.31 C gv 3.7.4 R hdf 4.2.13 4.2.13 C hdf-devel 4.2.13 4.2.13 C hdf5 1.10.3 1.10.1 C hdf5-devel 1.10.3 1.10.1 C hdfeos2 2.2 2.20 20.1.00 CR hdfeos5 5.1.16 5.1.16 C ImageMagick 7.0.8_16 7.0.8_10 C JAGS N available as &ldquo;rjags&rdquo; jasper-devel 1.900.1 2.0.14 C ksh 20120801 R lapack 3.6.1 3.6.1 C lapack-devel 3.6.1 3.6.1 C leafpad 0.8.18 R libcdms 3.1.0 3.0.1 C libcrayutil 20121128 R libcurl-devel 7.29.0 R libdrs 3.1.0 3.1.0 3.1.2 CR libuuid-devel 2.32.1 2.32.1 2.23.2 CR llvm-devel 3.3 C lxterminal 0.3.2 R mercurial 4.9.1 2.6.2 R mo_unpack 2.0.1 R mtk 1.4.5 R mtk-devel 1.4.5 R mtk-python27 N see build instructions for user ncBrowse N deprecated nccmp 1.8.3.1 R ncl 6.5.0 C nco 4.7.8 C nco-devel 4.7.8 C ncview 2.1.2 R nedit 5.7 R netcdf 4.6.1 4.6.1 4.3.3.1 CR called libnetcdf in conda netcdf-c++ 4.2.1 4.3.0 C called netcdf-cxx4 in conda netcdf-c++-devel 4.2.1 4.3.0 C called netcdf-cxx4 in conda netcdf-devel 4.6.1 4.6.1 4.3.3.1 CR called libnetcdf in conda netcdf-fortran 4.4.4 4.4.4 4.2 CR netcdf-fortran-devel 4.4.4 4.4.4 4.2 CR octave 3.8.2 R octave-devel 3.8.2 R octave-doc N docs are on https://octave.org/doc/ octave-netcdf 1.0.6 R octave-octcdf N deprecated p7zip 16.02 R parallel 20190522 C pdftk N discontinued perl-core 5.16.3 R perl-devel 5.16.3 R perl-Image-ExifTool 11.7 R perl-XML-Parser 2.44_01 C postgresql-devel 9.2.24 R proj 4.9.3 5.2.0 4.8.0 CR called proj4 in conda proj-devel 4.9.3 5.2.0 4.8.0 CR called proj4 in conda proj-epsg 4.9.3 5.2.0 4.8.0 CR called proj4 in conda proj-nad 4.9.3 5.2.0 4.8.0 CR called proj4 in conda proj-static 4.9.3 5.2.0 4.8.0 CR called proj4 in conda python27 3.7.1 2.7.15 C python27-alabaster 0.7.12 0.7.12 C python27-astral 1.9.2 C python27-Babel 2.6.0 2.7.0 C python27-backports-common 1.0 C python27-backports-functools_lru_cache 1.5 C python27-backports-ssl_match_hostname 1.0 C python27-basemap 1.2.0 1.2.0 C python27-biggus 0.15.0 C python27-boto3 1.9.67 1.9.188 C python27-botocore 1.12.68 1.12.188 C python27-cartopy 0.17.0 0.16.0 C python27-ccplot P python27-cdat_lite N deprecated python27-cerbere N python27-certifi 2018.11.29 C python27-cf 2.3.6 C called cf-python in conda python27-cf-checker 3.1.1 C python27-cf-plot 2.4.10 C python27-cf-units 2.0.2 2.1.1 C python27-cf-view N no longer supported python27-cftime 1.0.3.4 1.0.1 C python27-chardet 3.0.4 3.0.4 C python27-cis 1.6.0 C python27-cloudpickle 0.6.1 1.2.1 C python27-cmor N groups advised to maintain own CMOR python27-cycler 0.10.0 0.10.0 C python27-Cython 0.29.2 0.29.12 C python27-dask 1.0.0 1.2.2 C python27-dateutil C As &ldquo;dateutil&rdquo; python27-descartes 1.1.0 1.1.0 C python27-docutils 0.14 0.14 C python27-ecmwf-api-client N To be added soon. python27-emcee 2.2.1 2.2.1 C python27-enum34 1.1.6 C python27-eofs 1.3.1 1.4.0 C python27-esgf-pyclient 0.1.8 C python27-filelock 3.0.10 3.0.10 C python27-Fiona 1.7.13 C python27-geopandas 0.4.0 C python27-h5py 2.8.0 2.8.0 C python27-httplib2 0.13.0 C python27-idna 2.8 2.8 C python27-ilamb 2.3.1 C python27-ImageHash 4.0 4.0 C python27-imagesize 1.1.0 1.1.0 C python27-ipython 7.2.0 5.8.0 C python27-iris_sample_data 2.1.0 2.1.0 C python27-iris-grib 0.12.0 C python27-jinja2 2.1 2.10.1 C python27-jmespath 0.9.3 0.9.4 C python27-joblib 0.13.0 0.13.2 C python27-Jug 1.6.7 1.6.8 C python27-kiwisolver 1.0.1 1.1.0 C python27-latexcodec 1.0.5 1.0.7 C python27-locket 0.2.0 0.2.0 C python27-MarkupSafe 1.1.0 1.1.1 C python27-matplotlib 3.0.2 2.2.2 C python27-mo_pack 0.2.0 0.2.0 C python27-mock 2.0.0 3.0.5 C python27-mpi4py-mpich 3.0.1 C python27-mpmath 1.1.0 1.1.0 C python27-nappy 1.1.4 1.2.1 C python27-nc-time-axis 1.1.0 1.1.0 C python27-netCDF4 1.4.2 1.3.1 C python27-nose 1.3.7 1.3.7 C python27-numpy 1.15.4 1.15.4 C python27-packaging 18.0 19.0 C python27-pandas 0.23.4 0.24.2 C python27-partd 0.3.9 1.0.0 C python27-patsy 0.5.1 0.5.1 C python27-pep8 1.7.1 1.7.1 C python27-Pillow 5.3.0 5.2.0 C python27-psutil 5.4.8 5.6.3 C python27-psycopg2 2.7.6.1 2.7.7 C python27-pybtex 0.22.0 0.22.2 C python27-pycairo 1.18.0 1.16.3 C python27-pycodestyle 2.4.0 2.5.0 C python27-Pydap 3.2.2 3.2.2 C python27-pygeode 1.2.2 C python27-Pygments 2.3.1 2.4.2 C python27-pygobject2 3.28.3 C pygobject in conda python27-pygrib 2.0.3 2.0.2 C python27-pygtk2 C python27-pygtk2-libglade N python27-pyhdf 0.9.10 0.10.1 C python27-pyke 1.1.1 1.1.1 C python27-pyparsing 2.3.0 2.4.0 C python27-pyproj 1.9.5.1 1.9.6 C python27-pyshp 2.0.0 2.1.0 C python27-pyside 5.6.0a1 C python27-pyspharm 1.0.9 1.0.9 C python27-pystan 2.17.1.0 2.17.1.0 C python27-pytz 2018.7 2019.1 C python27-pyugrid 0.3.1 0.3.1 C python27-PyYAML 3.13 5.1.1 C python27-pyzmq 17.1.2 18.0.2 C python27-requests 2.21.0 2.22.0 C python27-rpy2 2.9.4 2.8.5 C python27-s3transfer 0.1.13 0.2.1 C python27-ScientificPython N only available in Python2.7 python27-scikit-image 0.14.2 C python27-scikit-learn 0.20.1 0.20.3 C python27-scipy 1.1.0 1.1.0 C python27-scitools-iris 2.2.0 1.13.0 C python27-seaborn 0.9.0 C python27-setuptools 40.6.3 41.0.1 C python27-Shapely 1.6.4 1.6.4 C python27-singledispatch 3.4.0.3 C python27-six 1.12.0 1.12.0 C python27-snowballstemmer 1.2.1 1.9.0 C python27-Sphinx 1.8.2 1.8.5 C python27-sphinxcontrib-websupport 1.1.0 1.1.2 C python27-statsmodels 0.9.0 0.10.0 C python27-sympy 1.3 1.4 C python27-Theano 1.0.3 1.0.4 C python27-toolz 0.9.0 0.10.0 C python27-tornado 5.1.1 5.1.1 C python27-tqdm 4.28.1 4.32.2 C python27-typing 3.7.4 C python27-urllib3 1.24.1 1.25.3 C python27-virtualenv 16.0.0 16.0.0 C python27-WebOb 1.8.4 1.8.5 C python27-windspharm 1.7.0 1.7.0 C python27-wxPython 4.0.3 4.0.3 C python27-xarray 0.11.0 0.11.3 C qt-devel 4.8.7 R R 3.5.1 3.4.1 C R-devel 3.5.1 3.4.1 C R-ncdf4 1.16 1.16 C redhat-lsb 4.1 R rjags 4_6 C sqlite-devel 3.7.17 R subversion 1.8.17 R subversion-devel 1.8.17 R subversion-tools 1.8.17 R tcl-devel 8.5 R tcl-devel 8.5.13 R tcsh 6.18.01 R thea N discontinued tk 8.6.9 8.6.9 8.5.13 CR tk-devel 8.6.9 8.6.9 8.5.13 CR tkdiff 4.3.5 R tmux 2.7 2.7 C tree 1.6.0 R udunits-devel 2.2.27.6 2.2.27.6 2.2.20 R called udunits2-devel umutil 20130102 R umutil-lib 20130102 R uuid 1.6.2 R uuid-devel 1.6.2 R valgrind 3.15.0 C vim-enhanced 7.4.629 R wxGTK-devel 2.8.12 R xconv 1.94 R xemacs 21.5.34 R xorg-x11-util-macros 1.19.0 R xpdf 3.04 R`}).add({id:107,tag:"en",href:"/docs/software-on-jasmin/jasmin-software-faqs/",title:"JASMIN software FAQs",description:"JASMIN software FAQs",content:`Why do I have to load/activate a software environment? We have a range of different users on JASMIN who work on many different projects. Each project has its own software requirements and timeline. By providing multiple software environments (such as Python2.7 and Python3.7) we can support a wider range of users on the same platform. Since we do not assume a &ldquo;standard&rdquo; environment it is up to the user to &ldquo;load&rdquo; (or &ldquo;activate&rdquo;) a software environment before usage. This is typically done by using:
module load &lt;environment&gt; See the overview page for more details.
How do I set the Jaspy environment as my default? If you want your JASMIN sessions to automatically use the default &ldquo;jaspy&rdquo; environment then append this line to the end of your &ldquo;$HOME/.bashrc&rdquo; file:
module load jaspy How do I set the \`jasmin-sci\` environment as my default? If you want your JASMIN sessions to automatically know about the packages in the &ldquo;jasmin-sci&rdquo; environment then add this line to the end of your &ldquo;$HOME/.bashrc&rdquo; file:
module load jasmin-sci How do I activate a combination of Jaspy and \`jasmin-sci\` environments together? If you want to activate (or load) both the current Jaspy and the &ldquo;jasmin-sci&rdquo; environments at the same time, use:
module load jasmin-sci module load jaspy What is the plan for the future of Jaspy and \`jasmin-sci\` environments? We have moved over to using Conda as the primary tool for building and deploying software environments. The Jaspy environments are all Conda-based and make use of the significant community efforts supporting scientific computing such as the &ldquo;conda-forge&rdquo; repositories. For some packages, not available through Conda, we have also created the &ldquo;jasmin-sci&rdquo; environment. Ideally, we would like to move to a Conda-only solution in order to simplify both the management and user perspectives. Can I install my own Conda environment? If you need to install a set of packages that are not provided in Jaspy or the &ldquo;jasmin-sci&rdquo; environment then you can create your own Conda installation. It is important to note that this will not be compatible with the Jaspy environments and please take note of the FAQ below: &ldquo;Where should I install software environments on JASMIN?&rdquo;. Where should I install software environments on JASMIN? If you need to install your own software environment(s) on JASMIN then we strongly advise that you install it on one of the SSD file systems:
Under your $HOME directory - if you are the only user who needs access. Within a &ldquo;small files&rdquo; Group Workspace - if you wish to share the environment with other JASMIN users. Is MATLAB available on JASMIN? No, MATLAB is not one of our supported software packages and is not installed on JASMIN for general use. As a result, we are not able to provide support for MATLAB-related issues.
An alternative is Gnu Octave, which is a ‘drop-in’ replacement for MATLAB, and can be used on LOTUS without license restrictions.
Some users/groups have arranged their own MATLAB license to be available for use in certain locations on JASMIN, but this is something which users/groups would need to arrange for themselves with the vendor, Mathworks.
If you do have your own license, please be aware that any installation of MATLAB would need to be done in a location that meets the terms of the license, and the installation would normally need to be carried out with regular user permissions (JASMIN users do not have root or sudo permissions).
There are 2 places where it would be OK to install MATLAB in this case:
Within a group workspace, with access restricted to members of the group, but available for use on one of the shared sci machines (but see note below) On a tenancy sci machine: this is a special type of sci server deployed within a JASMIN Cloud tenancy, for exclusive use by members of that tenancy. The manager of the tenancy should do the installation. Safe use of temporary directories if using MATLAB on JASMIN
By default, Matlab makes use of the local /tmp area on the machine where it is being used, so if this is on a shared machine, it can fill up the /tmp area and cause issues for all other users of the machine. You are therefore advised to create and use a subdirectory of a group workspace instead of /tmp for your own TMPDIR area. To do this, please do the following (or similar):
The following lines added to your $HOME/.bashrc file will set an environment variable TMPDIR, and create the corresponding directory if it does not already exist:
export TMPDIR=/gws/&lt;path_to_your_group_workspace&gt;/&lt;your_username&gt;/tmp [ -d $TMPDIR ] || mkdir -p $TMPDIRThis should get automatically set at login, or can be manually invoked with:
. ~/.bashrc But please note that we are not able to help with MATLAB queries beyond the information provided here.`}).add({id:108,tag:"en",href:"/docs/getting-started/jasmin-status/",title:"JASMIN status",description:"JASMIN status",content:`This article lists sources of information about the status of JASMIN services.
CEDA Status page &nbsp; The CEDA Status page&nbsp; is updated regularly to announce or track current and upcoming incidents which may affect JASMIN and CEDA services. Please check for known incidents or announced shceduled maintenance before contacting the helpdesk.
JASMIN dashboard &nbsp; The JASMIN metrics dashboard&nbsp; has been redeveloped and is now available again.
Please read the introductory information on that page.
Currrently it provides:
GWS Dashboard view of all the volumes in a group workspace across different storage types, showing quota and usage LOTUS Dashboard showing pending and running jobs per partition (queue) and other useful metrics Power Dashboard showing power consumption of the various components of JASMIN Tape dashboard showing summary information on tape usage by consortium This is still under active development and further dashboards may be added in due course.
Please also keep an eye on:
JASMIN-USERS email list (all users should be on this list. If not, please ask) CEDA News&nbsp; articles on the CEDA website @cedanews on X (formerly Twitter)&nbsp;`}).add({id:109,tag:"en",href:"/docs/getting-started/jasmin-training-accounts/",title:"JASMIN training accounts",description:"JASMIN training accounts",content:`What are training accounts? &nbsp; JASMIN training accounts are TEMPORARY accounts that provide a person with access to JASMIN for a specific event (such as a training workshop) organised in advance.
The benefits of using these accounts are:
permissions/services are consistent across all training accounts these permissions include (but are limited to) those normally anticipated for use within training/hackathon events they provide access to someone who may not be eligible for a full account - setting up access for multiple users in advance of an event is more efficient for all involved than the usual registration process When should they be used? &nbsp; By participants of training events led by the JASMIN team (By special arrangement with the event organiser) by participants of other events such as training workshops or hackathons which require temporary access to JASMIN In both cases, use of the training accounts is only for the duration of the event. Use beyond the event requires the normal registration process.
Who can request these accounts? &nbsp; Organisers of training events / hackathons, by contacting the JASMIN team. For event organisers &nbsp; How to request training accounts for your event &nbsp; If you think these accounts could be useful for you, please contact the helpdesk with the following information:
Name/date of event
Estimated number of attendees (note: we only have 150 such accounts, and events sometimes overlap)
What services the accounts will need access to e.g. sci machines, GWS, CEDA Archive, Notebook Service, Transfer Servers, LOTUS, or any other special services on JASMIN
Any special requests for accessing resources
By default, the training accounts have access to the following services. Any request for other services beyond these would need to be considered by the JASMIN team: Login, nx-login, sci and xfer servers hpxfer service workshop group workspace (/gws/pw/j07/workshop) use of LOTUS via the workshop Slurm queue Jupyter Notebooks service (requires users to set password) Once the JASMIN team have confirmed that we can support your event, you will need to collect and supply the following at least 2 weeks before your event:
Email addresses for all attendees who need a training account. These addresses cannot already be associated with an existing JASMIN account. They must be different. Please note that we cannot guarantee the following during your event:
no login problems uptime of services no problems due to usage at scale (particularly for use of sci servers and/or Notebook Service) What to tell your event attendees &nbsp; The JASMIN team will set up the accounts and send credentials to attendees approximately 1 week before your event.
Please ensure you have given the following information to attendees:
A link to this help page. Tell them all information they need is under the &lsquo;for event attendees&rsquo; section. Tell users what services they have been granted access to (see above) and any additional information e.g. full path to any GWSs, whether they will need to use the JASMIN Notebook Service or accounts portal. Tell the users when the training accounts will be closed down. This is usually within 24 hours of the end of the event. They would be responsible for copying any important data and/or code elsewhere if it is important that these are not lost when the accounts are wiped. For event attendees &nbsp; How to set up your temporary account &nbsp; Training account credentials will be emailed to you via OneDrive. Sometimes the OneDrive email ends up in junk/spam folders, please check here. If you still can&rsquo;t find the email, please contact the helpdesk ASAP. To access the training account credentials, you must: Click on the OneDrive link. Enter your email address (if you already have a JASMIN account, this will be the alternative email address you provided). If you are having difficulty opening the link, please sign out of any alternative OneDrive accounts and then try again. You will then be emailed a verification code. Enter this code on OneDrive. Download the files. These contain your training account credentials. Next, you need to use these training account credentials to set up your own machine for accessing JASMIN. Follow the instructions in Ex00. You MUST do this before your event. You may need access to the JASMIN Notebook Service and Accounts Portal. Your event organiser will let you know whether this is needed for your particular event. If you do need it, you will need to follow the steps in the section below. For the JASMIN Beginners workshop: you do not need this. For the JASMIN Advanced workshop: you do need this. Please follow the steps in the section below. Before the event, familiarise yourself with the JASMIN help documentation site. This should answer most questions you may have. If you are attending a 3rd-party-led event, we suggest taking a look at the [other JASMIN workshop training materials](https://github.com/cedadev/jasmin- workshop) - especially if you are a new user. Your event organiser should provide full details of how the training account should be used for that particular event - please contact them if you have any issues.
JASMIN Notebook Service and Accounts Portal access &nbsp; Access to these services requires a password. This is not sent in the OneDrive link. If you need access to these services, you must:
Go to the Reset Account Password function of the JASMIN Accounts portal Enter your email address (NB: the one to be used for the training account) You will then receive a password reset email (don’t forget to check your spam folder). Follow the steps to reset the password. You can now use this new password for accessing the notebook service and the accounts portal.`}).add({id:110,tag:"en",href:"/tags/jasmin-sci/",title:"Jasmin-Sci",description:"",content:""}).add({id:111,tag:"en",href:"/tags/jaspy/",title:"Jaspy",description:"",content:""}).add({id:112,tag:"en",href:"/docs/software-on-jasmin/jaspy-envs/",title:"Jaspy Software Environments (Python 3, R and other tools)",description:"Jaspy Software Environments (Python 3, R and other tools)",content:`This page provides details of the &ldquo;Jaspy&rdquo; software environments that provide access to Python 3, R and a range of other tools on JASMIN.
Overview &nbsp; Jaspy is a toolkit for managing and deploying Conda environments that include Python, R and other packages. Jaspy is used to provide software environments of common packages on the scientific analysis servers and LOTUS cluster on JASMIN.
One advantage of Jaspy is that multiple environments can co-exist on the same platform. This allows us to retain previous environments and provide new ones simultaneously. This may be particularly useful for scientists undertaking long-running studies that require a consistent software environment to ensure reproducibility and continuity.
Working with Jaspy environments &nbsp; Quickstart for Python 3 environment &nbsp; If you want to get on, you can select a Jaspy environment to &ldquo;activate&rdquo;. This means that once you have run these commands then the various tools and libraries will be available in your current session.
module load jaspy Activating the environment in scripts &nbsp; If you want a particular script to activate a Jaspy environment then add the &ldquo;module&rdquo; command to it, e.g.:
#!/bin/bash module load jaspy python do-something.py Setting your profile to always use a Jaspy environment &nbsp; If you want all your JASMIN sessions to use a particular Jaspy environment then you can add the module load jaspy command to your $HOME/.bashrc file. In order to avoid issues with using &ldquo;module load&rdquo; on unsupported servers, please wrap the call in an &ldquo;if&rdquo; clause, such as:
if [[ $(hostname) =~ (sci[0-9]|host[0-9]|cylc) ]] ; then module load jaspy fi Discover which environments are available &nbsp; You can list the currently available Jaspy environments using:
module avail jaspy ------------------------- /apps/modulefiles ---------------------------- jaspy/2.7/r20190715 jaspy/3.7/r20200606 jaspy/3.10/r20230718 (D) jaspy/3.7/r20181219 jaspy/3.7/r20210320 jaspy/3.11/r20240302 jaspy/3.7/r20190612 jaspy/3.8/r20211105 jaspy/3.7/r20190627 jaspy/3.10/r20220721 This lists all jaspy modules (i.e. environments) that can be loaded.
Jaspy Python 3.7+ (plus other tools) environments &nbsp; The packages available in the Jaspy environments can be found by searching the GitHub repository where the Conda environment files are defined. This table lists all the Jaspy Python 3.7+ environments provided on JASMIN and specifies the current (default) version.
Jaspy Python 3.7 Environment Versioned list of software packages Default? Comments / Issues jaspy/3.11/r20240302 List of packages including versions No (will become the default on 16/04/2024) jaspy/3.10/r20220721 List of packages including versions Yes (from: 18/10/2022) NCO and NCL have now been moved to the &ldquo;jasmin-sci&rdquo; packages installation. jaspy/3.8/r20211105 List of packages including versions No (was default: 16/11/2021 - 17/102022) Known problem with NCL rendering Shapefiles (see issue). Some packages were removed in this release due to dependency problems: theano, pymc3, pystan, pyngl,pyferret (seeissue). jaspy/3.7/r20210320 List of packages including versions No (was default: 20/05/2021 - 16/11/2021) Known problem with NCL rendering Shapefiles (see issue) jaspy/3.7/r20200606 List of packages including versions No jaspy/3.7/r20181219 List of packages including versions No Jaspy Python 2.7 (plus other tools) environments &nbsp; This table lists all the Jaspy Python 2.7 environments provided on JASMIN and specifies the current (default) version.
Jaspy Python 2.7 Environment Versioned list of software packages Default? jaspy/2.7/r20190715 List of packages including versions Yes Jasr R environments &nbsp; Environments for the &ldquo;R&rdquo; programming language are packaged into separate software environments, known as &ldquo;Jasr&rdquo;. This table lists all the Jaspy R environments provided on JASMIN and specifies the current (default) version.
Jaspy R Environment (&ldquo;Jasr&rdquo;) Versioned list of software packages Default? jasr/4.3/r20240320 List of packages including versions No (will become the default on 16/04/2024) jasr/4.0/r20220729 List of packages including versions Yes (from: 18/10/2022) jasr/4.0/r20211110 List of packages including versions No (was default: 16/11/2021 - 17/10/2022) The available R environments can be listed with:
module avail jasr Understanding versioning with Jaspy/Jasr &nbsp; Jaspy environments are labelled as &ldquo;jaspy/&lt;python_version&gt;/&rdquo;. The environment is selected and activated using the &ldquo;module load&rdquo; command:
module load jaspy/3.7/r20210320 However, if you wish to get the latest environment for a given Python version you can omit the &ldquo;&rdquo;, as follows:
module load jaspy/3.7 And if you just want the most up-to-date Python you can even omit the &lt;python_version&gt;, as follows:
module load jaspy &nbsp; If you choose to omit the &lt;release&gt; and &lt;python_version&gt; components then it is important to be aware that the resulting environment may differ over time. For continuity, you ay wish to use the full environment specification. How Jaspy works: managing Python and non-Python packages using conda &nbsp; Jaspy is a framework for managing multiple Python (and other) environments simultaneously on a single platform. It was created in order to meet the requirements tabulated below.
Requirement Details Jaspy solution Further info Reproducibility 1. Generate a specific set of packages and versions from a generic set of requirements. 1. Conda has a powerful package-management workflow:
a. Begin with a minimal set of package/version requirements.
b. Generate a consistent environment.
c. Provide a detailed description of all exact packages/versions in the environment. Conda: https://docs.conda.io jaspy-manager: https://github.com/cedadev/jaspy-manager/blob/master/README.md CEDA jaspy environments: https://github.com/cedadev/ceda-jaspy-envs Documentation Provide an appropriate level of documentation detailing which software packages exist in each release. We use Conda &ldquo;environment files&rdquo; to build the environments. These list the packages and versions and are stored in public GitHub repositories, so each environment is documented as a collection of packages/versions. See: https://github.com/cedadev/jaspy-manager/blob/master/README.md Example package list: https://github.com/cedadev/ceda-jaspy-envs/blob/master/environments/py3.7/m3-4.5.11/jaspy3.7-m3-4.5.11-r20181219/packages.txt Multiple simultaneous environments Allow multiple, but separate, software environments to co-exist on a single operating system. Conda is designed to allow multiple environments to co-exist. Within jaspy it is possible to document each environment. Therefore, multiple environments can be deployed on one system. Key advantages are:
- Supporting multiple versions of Python and side-by-side.
- Releasing an update to an environment as a &ldquo;pre-release&rdquo; so that users can adapt their code and test it whilst still having access to the &ldquo;current&rdquo; (production) environment. Manageability Provide tools to easily construct, test, deploy, document and reproduce software environments. Jaspy builds upon a set of excellent Conda command-line tools that simplify the package management process. Jaspy wraps the Conda functionality so that command-line tools can be used to build, test, deploy and distribute Conda environments for use by our community. Updates and tracking of Jaspy/Jasr environments &nbsp; History of environments on JASMIN &nbsp; Please see the Jaspy Python 3.7+ (and other tools) environments section above for information about releases on JASMIN.
Which environment is &ldquo;current&rdquo;? &nbsp; Please refer to the Jaspy Python 3.7+ (and other tools) environments section above for information about the current release on JASMIN.
Citing Jaspy environments &nbsp; Can I cite a jaspy (conda) environment? &nbsp; We do not yet have an agreed approach for citing a Jaspy environment. However, you can refer to the environment description URLs given in the table above. These provide a definitive list of the software packages, their versions and other information.
Requesting updates to a Jaspy environment &nbsp; If you would like us to add a new package, or an updated version, to the Jaspy environments on JASMIN then please use one of the following approaches:
Contact the JASMIN helpdesk with the subject: &ldquo;Request for Jaspy update: &rdquo; Get a GitHub account and add an issue to the ceda-jaspy-envs repository at: 1. https://github.com/cedadev/ceda-jaspy-envs/issues/new Conda method of &ldquo;activating&rdquo; Jaspy environments &nbsp; Jaspy environments can also be activated in a more traditional way using standard the standard conda approach, for example:
export PATH=/apps/jasmin/jaspy/miniconda_envs/jaspy3.7/m3-4.6.14//bin/conda:$PATH source activate conda activate jaspy3.7-m3-4.6.14-r20210320 This has the same result as the module load approach. The naming of the environment identifiers includes the &ldquo;Miniconda&rdquo; version used to generate the environment. The module load approach is recommended as the standard method for activating Jaspy environments.
Using Jaspy beyond JASMIN &nbsp; Jaspy is a versatile and generic tool for managing multiple conda environments. The code is open source, and more information is available at:
https://github.com/cedadev/jaspy-manager`}).add({id:113,tag:"en",href:"/docs/short-term-project-storage/jdma/",title:"Joint-storage Data Migration App (JDMA)",description:"Joint-storage Data Migration App (JDMA)",content:`&nbsp; A new system called NLDS is coming very shortly (as of Feb 2023) and will eventually replace both Elastic Tape and JDMA. See the JDMA user documentation at:cedadev.github.io/jdma_client for more information about using JDMA.
The joint-storage data migration app (JDMA) is a multi-tiered storage system which provides a single API to users to allow the movement of data to a number of different storage systems, query the data they have stored on those storage systems and retrieve the data.
These interactions are carried out using a common user interface, which is a command line tool to be used interactively, a python library or a HTTP API, both to be used programmatically. The command line tool essentially provides a wrapper for calls to the python library, which in turn makes calls to the HTTP API.
JDMA was designed with the following usability criteria in mind:
The user experience for moving data, regardless of the underlying storage systems, should be identical. The user should not be responsible for maintaining the connection to the storage system in the case of asynchronous transfers. User and group ownership and permissions should be preserved and restored on downloading the data The user should receive notifications when the transfers are complete. Users should be able to transfer data from one storage system to another JDMA is only a request and query layer. Any cataloguing of data should be carried out by the backend system. So that, if JDMA fails, then the data is still available independently of JDMA, from the storage backend. See the JDMA user documentation at:cedadev.github.io/jdma_client/ for more information about using JDMA.
JDMA was development under a Horizon 2020 grant from the EU Commission. A report submitted to the EU Commission can be found in the repository at: [github.com/cedadev/django-jdma_control/blob/master/doc/ESiWACE- Milestone-8_final.pdf](https://github.com/cedadev/django- jdma_control/blob/master/doc/ESiWACE-Milestone-8_final.pdf)
The JDMA client github is at: github.com/cedadev/jdma_client
Quick guide to installing the JDMA client on JASMIN &nbsp; If you are working on JASMIN and you wish to use the JDMA client, then you can install it as follows on a sci server:
module load jaspy python -m venv ~/venvs/jdma-venv source ~/venvs/jdma-venv/bin/activate pip install git+https://github.com/cedadev/jdma_client You should then have the jdma command-line tool available in your terminal session.`}).add({id:114,tag:"en",href:"/tags/jules/",title:"JULES",description:"",content:""}).add({id:115,tag:"en",href:"/tags/jupyter/",title:"Jupyter",description:"",content:""}).add({id:116,tag:"en",href:"/tags/login/",title:"Login",description:"",content:""}).add({id:117,tag:"en",href:"/docs/interactive-computing/login-problems/",title:"Login problems",description:"Login problems?",content:`Having problems connecting to a host on JASMIN? Details of how to login to JASMIN can be found here, but this article may help to resolve login problems. It provides information for the following issues:
Unable to login to a login server e.g. login1.jasmin.ac.uk Can login to login server but can&rsquo;t login to a subsequent server ssh-add command gives error: &ldquo;Could not open a connection to your authentication agent.&rdquo; Errors when trying to connect with MobaXterm Unable to login to login server &nbsp; If you are unable to login to a login server e.g. login1.jasmin.ac.uk then look carefully at any error messages displayed as this can help diagnose what is wrong:
1) &ldquo;Connection reset by peer&rdquo;
This suggests a problem with the configuration of your machine or local network. Connections to JASMIN login servers are allowed from a specific set list of network domains (the domain is the part after the host name e.g. myhost. mylocalnetwork.ac.uk ). For this to happen, 2 things need to be in place:
the IP address of your machine needs to resolve to a full-qualified host name (so that it can be checked against the list) the domain part of the hostname needs to be on JASMIN&rsquo;s allow list. Use the tool provided on the JASMIN accounts portal to check that your IP address does indeed resolve:
Visit https://accounts.jasmin.ac.uk/services/reverse_dns_check/ with your browser, or do the following at the command line, on the machine from which you&rsquo;re trying to connect:
curl https://accounts.jasmin.ac.uk/services/reverse_dns_check Depending on your system, this will either provide output to the terminal (via stdout) or on some systems this might save the output in the file &ldquo;reverse_dns_check&rdquo;. You may need to look in that file for the result.
See check network details for further information on how to interpret the result from this.
Most institutional networks for UK universities and partner organisations are on our allow list, which is updated on request. However if you are trying to connect from your home broadband, then please be aware that this is not the the preferred route, for security reasons. If you connect from home, please be aware that:
The IP address which you are allocated by your internet service provider (ISP) may not resolve to a full hostname That domain name is unlikely to be on the allow list. One solution is to connect via your VPN to your institution first. This assigns you another IP address belonging to that institution, but you need to repeat the checks above to make sure that address resolves (not all do).
Another option, if you have SSH terminal access to a machine at your institution from where you can also make outgoing SSH connections, is that you connect from your local machine to the machine at your institution, then make the outward SSH connection to JASMIN from there. In this case, you need to have your JASMIN SSH key loaded on your local machine first, and remember to include the -A flag for &ldquo;agent forwarding&rdquo; for ALL the intermediate steps.
If all else fails, you can use the &ldquo;contingency route&rdquo; provide by login2.jasmin.ac.uk (see article for further details), but you will be limited in what you can do / connect to within JASMIN as a result. We prefer all users to connect from their institutional network.
2) &ldquo;Permission denied&rdquo;
Here, the most likely cause is that the SSH key which your client is presenting does not match the one in your JASMIN account. This can be for a number of reasons:
You have omitted to specify the username in your SSH connection In this case, you will be attempting to connect with the username you have on your local machine, which may not be the same. You have only recently uploaded your SSH key (it can take 20 to 60 minutes before the key propagates to all the places it needs to on JASMIN). Try waiting a few minutes before trying again. You don&rsquo;t have your key loaded in your local authentication agent (e.g. ssh-agent). Check that you are following the method suitable for your operating system
The article &ldquo;How to login&rdquo; has instructions for linux, mac and windows. Note that connections using NoMachine NX don&rsquo;t require an authentication agent: this can be a good alternative if you&rsquo;re having problems.
You have not yet been granted jasmin-login access or your access has expired. To check, go to List my services on the JASMIN accounts portal and check that &ldquo;Login services: jasmin-login&rdquo; is listed. If not then you either need to apply for jasmin-login access, or if you have already done this recently you may simply need to wait for it to be approved. Note that if you have applied for access to a group workspace you still need jasmin-login access in order to connect to jasmin machines. 3) &ldquo;The authenticity of host &rsquo;nnnn ( )&rsquo; can&rsquo;t be established.&rdquo; or &ldquo;key for host nnnn has changed&rdquo;
Your local computer stores a list of all the other SSH hosts which it has successfully connected to in the past. If you use an intermediate host like a login server to make onward connections to a sci machine, the login host will maintain another such list. In both cases there should be a file~/.ssh/known_hosts (so one in your local home directory on your own machine, and one in your JASMIIN home directory)
When the SSH client first contacts the host for the SSH connection, it checks to see if the remote host is one that it recognises. If this check fails, you may get a message like the following:
Message 1:
The authenticity of host &#39;nnnn (&lt;ip address&gt;)&#39; can&#39;t be established. ECDSA key fingerprint is SHA256:8QY9iBcOQFyEYkpOtBUU8WQGeADb0DyMff01BRuvYls. ECDSA key fingerprint is MD5:f9:19:c4:5f:2b:fa:ed:aa:34:86:c9:23:dd:1c:44:30. Are you sure you want to continue connecting (yes/no)? Message 2:
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@ @ WARNING: POSSIBLE DNS SPOOFING DETECTED! @ @@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@ The ECDSA host key for nnnn has changed, and the key for the corresponding IP address &lt;IP address&gt; has a different value. This could either mean that DNS SPOOFING is happening or the IP address for the host and its host key have changed at the same time. Offending key for IP in /home/users/username/.ssh/known_hosts:62 @@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@ @ WARNING: REMOTE HOST IDENTIFICATION HAS CHANGED! @ @@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@ IT IS POSSIBLE THAT SOMEONE IS DOING SOMETHING NASTY! Someone could be eavesdropping on you right now (man-in-the-middle attack)! It is also possible that a host key has just been changed. The fingerprint for the ECDSA key sent by the remote host is SHA256:Evr7U40sEGSLVypfafLYtbF2oYvGDuBxTyrALdx11pk. Please contact your system administrator. Add correct host key in /home/users/username/.ssh/known_hosts to get rid of this message. Offending ECDSA key in /home/users/username/.ssh/known_hosts:115 ECDSA host key for nnnn has changed and you have requested strict checking. Host key verification failed. This can happen when:
machines are re-installed (as part of maintenance by the JASMIN team) when you modify your ~/.ssh/known_hosts file when you access a &ldquo;known&rdquo; host but via a different name (e.g. sci1 vs sci1.jasmin.ac.uk) Message 1 means that you don&rsquo;t have an entry for that host in your ~/.ssh/known_hosts file. In most cases, you can safely reply &ldquo;yes&rdquo; and the SSH connection should proceed as normal from then on.
If you get message 2, and are confident that the change is for a legitimate reason, the solution is to modify your ~/.ssh/known_hosts file, removing the entries for that host (there may be more than one, as above for sci1 vs sci1.jasmin.ac.uk) by deleting those lines. Next time you try and connect, you will get message 1, but can reply &ldquo;yes&rdquo; and the SSH connection should proceed as normal.
Note: If you&rsquo;re using a graphical SFTP or SCP client for data transfers, the error messages above may be hidden and so it can be harder to establish the reason for failure. Using a terminal session (in MobaXterm on Windows, or Mac/Linux terminal) to the problem host will likely reveal the messages and enable you to follow the steps above to solve the problem.
Can login to login server but can&rsquo;t login to a subsequent host &nbsp; Here, there are 3 main possibilities:
1) You have not set up agent forwarding correctly on your local machine.
****This allows your ssh key to be used for logging in from login1.jasmin.ac.uk to other machines. To check, run the following command on the login server:
echo &#34;$SSH_AUTH_SOCK&#34; This should display something that looks similar to (but not identical to)
/tmp/ssh-RNjiHr2844/agent.2844 If nothing is displayed then it indicates that agent forwarding is not working. Please read how to login and make sure you are running ssh-agent (or similar), have loaded your private key and are using the -A option on your ssh command for the connection to the login server. NX users should make sure that the &ldquo;agent forwarding&rdquo; option is ticked when setting up a connection profile.
2) Some hosts within JASMIN are restricted to particular (groups of) users.
The &ldquo;sci&rdquo; servers (e.g. sci1.jasmin.ac.uk) and &ldquo;xfer&rdquo; machines (e.g. xfer1.jasmin.ac.uk) should be available to all with jasmin-login access (see above). However, some other machines are restricted to particular project participants and require special permission to use. For example, the high- performance transfer servers hpxfer[12].jasmin.ac.uk requires the hpxfer access role, which can be applied for at the JASMIN accounts portal, as can most roles currently in use.
3) There is a problem with the host you are trying to connect to.
Occasionally there may be problems with the host (machine) which you are trying to connect to. The sci servers (particularly the high-memory host jasmin-sci3) experience very high usage loads and occasionally run out of resources. This may prevent you from logging in. In some circumstances ask you for a password: this is normally a sign that something is wrong with the machine, since passwords are not used for host logins on JASMIN, so there is no point in trying to enter your account password or SSH passphrase at this point. In this case please contact us using the help beacon below.
If you still have problems then please contact us using the help beacon below. It would be helpful if you can include as much of the following information as possible:
The IP address and full hostname of the machine you are trying to connect from. The date and time that you tried connecting (to the nearest minute if possible). This will help us to identify any relevant messages in any log files. The exact command you were using Add &ldquo;-vvv&rdquo; to your SSH command and send us the the output (please include the SSH command itself) List the SSH keys directory on your local machine. On a linux machine this can be done with the command: ls -l ~/.ssh ssh-add command gives error: &ldquo;Could not open a connection to your authentication agent.&rdquo; &nbsp; On some terminal sessions the usual instructions for starting the ssh-agent session and adding the key may give the following error:
ssh-add ~/.ssh/id_rsa_jasmin Could not open a connection to your authentication agent. If you get this message, please try either:
modifying the method you use to start the ssh-agent, to:
eval $(ssh-agent -s) (and then trying to load the key again)
or see below (if using MobaXterm) which now has a better way of loading the SSH key.
Errors when connecting with Mobaxterm &nbsp; Please follow the instructions for MobaXterm (which include a video to show how to load your key into its own ssh-agent, MobAgent).
These instructions have changed with more recent versions of MobaXterm, and replace the need to use the ssh-add command, so please make sure that both the version you are using, and your method, are up to date!
Please note that even if your initial connection to (for example) your university host does not require your JASMIN SSH key, you should still load the key AND enable agent forwarding, for your initial connection to that host, so that the key can be used for the subsequent connection to the JASMIN login host. This actually applies to any connection method, not just MobaXterm.`}).add({id:118,tag:"en",href:"/docs/interactive-computing/login-servers/",title:"Login servers",description:"Login servers",content:`Available login servers &nbsp; There are three login servers available to access resources within JASMIN. Users with the jasmin-login access role can access the following servers via SSH:
Login server name details login1.jasmin.ac.uk best for use from university networks (requires fwd/reverse DNS lookup to domain in allow-list) login2.jasmin.ac.uk Contingency config, see notes below login3.jasmin.ac.uk as per login1 login4.jasmin.ac.uk as per login1 See also How to login and other articles in the Getting started category.
See also NoMachine NX service which provides login to a graphical Linux desktop, rather than a single terminal window.
Features of login servers &nbsp; Login servers have minimal resources and software installed. They provide:
Access to your home directory (/home/users/&lt;username&gt;). Access via SSH to other hosts within JASMIN (inside the RAL firewall) No analysis software is installed on the login servers. No access to group workspaces or other volumes. &ldquo;Contingency&rdquo; login servers &nbsp; There are requirements on your local network which apply to accessing the login servers and the transfer servers via SSH. If you cannot meet these requirements, even after discussion with your local network admin team, a contingency route is provided in the form of login server login2.jasmin.ac.uk
However, you will be limited in what you can access within JASMIN from this server. Specifically:
You will not be able to access the transfer servers xfer[1,2].jasmin.ac.uk via SSH directly from an external host. You can access these via SSH from login2, but can then only initiate an inward pull of data from an external SSH server, if available at your institution. You cannot push data directly to xfer[1,2].jasmin.ac.uk via SSH from outside in this case. Instead, an alternative transfer server xfer3.jasmin.ac.uk is provided with equivalent configuration to login2. This should provide what you need for direct SSH transfers from outside, but you will need the additional &quot;xfer-sp&quot; access role in in this case: see here for further details. How to use the login servers &nbsp; For full details of how to log in, including making onward connections to other machines, please see the article &ldquo;How to login&rdquo;.
&nbsp; Users are not permitted to execute commands which require administrative privileges. This applies to all hosts in the managed part of JASMIN where users have SSH login access (for example login, nx-login, sci, xfer and hpxfer machines).
In other words, the use of su and sudo is not permitted.
Please be careful when typing commands, particularly if you have multiple terminal windows open on your own computer, that you do not accidentally attempt sudoon a JASMIN machine: expect some follow-up from the JASMIN team if you do!`}).add({id:119,tag:"en",href:"/docs/long-term-archive-storage/",title:"Long-term archive storage",description:"How to use data in archive(s) from within JASMIN",content:""}).add({id:120,tag:"en",href:"/tags/lotus/",title:"Lotus",description:"",content:""}).add({id:121,tag:"en",href:"/docs/batch-computing/lotus-cluster-specification/",title:"LOTUS cluster specification",description:"LOTUS cluster specification",content:`Current cluster specification &nbsp; LOTUS is a cluster of over 300 nodes/hosts and 19000 CPU cores. A node/host is an individual computer in the cluster with more than 1 processor. Each node/host belongs to a specific host group. The number of processors (CPUs or cores) per host is listed in Table 1 with the corresponding processor model and the size of the physical memory RAM available per node/host.
Table 1. LOTUS cluster specification
Current host groups
Host group name Number of nodes/hosts Processor model CPUs per host RAM broadwell256G 37 Intel Xeon E5-2640-v4 &ldquo;Broadwell&rdquo; 20 256 GB skylake348G 151 Intel Xeon Gold-5118 &ldquo;Skylake&rdquo; 24 348 GB epyctwo1024G 200 AMD 48 1024 GB Selection of specific processor model &nbsp; To select a node/host with a specific processor model and memory, add the following Slurm directive to your job script
#SBATCH --constraint=&#34;&lt;host-group-name&gt;&#34;For example
#SBATCH --constraint=&#34;skylake348G&#34; &nbsp; Further notes
intel and amd node types are defined in the Slurm configuration as a feature:
For any Intel node type use #SBATCH --constraint=&quot;intel&quot; For a specific Intel CPU model use the host group name (see Table 1) e.g. #SBATCH --constraint=&quot;skylake348G&quot; For AMD use #SBATCH --constraint=&quot;amd&quot; There are 10 nodes of node type skylake348G with SSD disk mounted on /tmp LOTUS nodes of node type epyctwo1024 are not available yet on the par-multi queue &nbsp; If you choose to compile code for specific architectures, do not expect it to run elsewhere in the system. Retired host groups no longer in use &nbsp; (For reference only)
Host group name Number of nodes/hosts Processor model CPUs per host RAM haswell256G 7 retired Intel Xeon E5-2650-v3 &ldquo;Haswell&rdquo; 20 256 GB ivybridge2000G 3 -retired Intel Xeon E7-4860-v2 &ldquo;Ivy Bridge&rdquo; 48 2048 GB`}).add({id:122,tag:"en",href:"/docs/batch-computing/lotus-overview/",title:"LOTUS overview",description:"LOTUS overview",content:`This article gives an overview of the LOTUS batch computing cluster which is part of JASMIN. It covers:
What LOTUS is and what it can be used for Where LOTUS can be accessed from What is LOTUS &nbsp; LOTUS is not, in itself, a High-Performance Computing (HPC) facility, but provides the batch and parallel processing component of the JASMIN data- intensive scientific analysis environment. LOTUS is a cluster of physical machines, running the Slurm workload manager, enabling efficient scheduling of larger data analysis tasks across nodes in the cluster as a single unit -see Figure 1.
Each node in the cluster is connected by 10Gbit/s Ethernet to JASMIN&rsquo;s high-performance 40Gbit/s core network. Although not its primary function, LOTUS also facilitates MPI-based parallel processing.
JASMIN provides both interactive and batch computing environments, recognising that scientists often need to develop and test workflows interactively before running those workflows efficiently at scale. Nodes within LOTUS run the same stack of software and can access the same high- performance storage as the JASMIN Scientific Analysis servers, ensuring a consistent working environment for all phases of users&rsquo; workflows.
See LOTUS Hardware for details of the current LOTUS environment summarised in this schematic presentation
Figure 1 shows a schematic presentation of the LOTUS cluster and its environment
LOTUS schematic When to use LOTUS &nbsp; LOTUS is ideally suited to workflows which need to process or compare entire datasets, stored either in Group Workspaces or in the CEDA archives. The latter are directly accessible read-only so can be processed in-place without the need to copy files. Intermediate working files (within batch jobs) should be stored temporarily in /work/scratch-pw* and /work/scratch-nopw* volumes which are shared across the cluster, while persistent outputs can be written efficiently to Group Workspaces and shared with collaborators for the duration of a project.
See Access to Storage for details about which file systems are appropriate to use and how to access them.
LOTUS currently has around 19,000 cores, but is heavily used and implements a fair-share scheduling system between users. It is not intended as a substitute for dedicated HPC facilities, rather as a complementary environment in which model outputs can be analyzed and compared with observational data. Users with large-scale compute-heavy requirements (in particular those requiring large- scale parallel processing) should look to access other parts of the national HPC infrastructure such as ARCHER2 or MONSooN.
In order to maintain a safe and reliable working environment for all within LOTUS and more widely within JASMIN, users are expected to follow the best practice outlined in this documentation.
How to gain access to LOTUS &nbsp; LOTUS is accessible via the batch scheduler system SLURM that is running across all JASMIN scientific analysis servers sci[1-8].jasmin.ac.uk.
From the above servers, it is possible to submit, monitor, and control batch jobs using the SLURM commands.
Please note that if you have only recently requested access to JASMIN login services and had this approved, there can sometimes be a delay (typically up to a day, but in rare cases can be longer) before the necessary configuration is created for you on LOTUS. You will not be able to submit jobs to LOTUS queues until this has been completed. Typically you would see an error message such as this, in this case after an unsuccessful attempt to submit to the short-serial queue:
sbatch: error: Batch job submission failed: Invalid account or account/partition combination specifiedIf this occurs, please try again in 24 hours before contacting the JASMIN helpdesk.`}).add({id:123,tag:"en",href:"/tags/manager/",title:"Manager",description:"",content:""}).add({id:124,tag:"en",href:"/docs/short-term-project-storage/managing-a-gws/",title:"Managing a GWS",description:"Managing a GWS",content:`This article explains the responsibilities of the Group Workspace (GWS) manager.
Role of the GWS Manager &nbsp; When a GWS is created it is important that the designated GWS Manager understands the responsibilities associated with the role. The GWS Manager has a duty to:
Ensure that GWS is being used appropriately: this may include enforcement of limits on particular users. Advertise the URL for requesting access to the GWS. Respond to e-mail authorisation requests from CEDA. Manage disk and tape effectively: specifically the use of the Elastic Tape system to back-up or migrate data. Communicate GWS etiquette to the project scientists. Manage additional services such as sharing of GWS data via HTTP server. Manage the closing down of the GWS effectively: all GWSs have a termination date and data may be lost if not managed effectively. Communicate any issues to the CEDA Helpdesk. Managing users &nbsp; Authorising access to the GWS &nbsp; When your GWS has been set up, users can submit requests for access to the GWS via the JASMIN accounts portal: the new GWS will appear in the list of JASMIN Services. An access request from a user will trigger an e-mail to you that asks you to approve (or refuse) the request. The e-mail will include details of the user and their intended use of the resource. As GWS manager, you are now responsible for approving these requests (this is a change from the previous situation where you confirmed your approval to the CEDA helpdesk who then actioned the approval). Now the approval is instant.
IMPORTANT: in order for this approval process to work, the GWS manager&rsquo;s own account needs to have been migrated to the JASMIN accounts portal if it existed prior to the JASMIN Accounts Portal in 2017. Very few accounts such now remain in that state, but you can check by going to this page:
Migrate your account&nbsp; &nbsp; &nbsp; If it says &ldquo;You are already logged in with a JASMIN account&rdquo; then you need take no further action.
File system permissions and groups &nbsp; File system access to a GWS is managed using a Unix group that begins with gws_ and normally corresponds with the name of the service in the Accounts Portal. When users are granted the USER role for the workspace, they are also made members of the corresponding gws_&lt;gwsname&gt; group. As manager, you are normally granted USER and MANAGER access at the time that the GWS is set up by the JASMIN team, so it should be in place when you first access the storage. This means that:
you have access yourself to the workspace (via the USER role giving you membership of the gws_&lt;gwsname&gt; group) you take over responsibility (via the MANAGER role) for approving other users&rsquo; applications for the USER role. you can unilaterally grant DEPUTY access to other users if you know their username and want them to help you in the task of approving requests for USER access. Once you yourself have access, a good first task is to set up the recommended directory structure.
A list of the user IDs that have access to a given GWS can be found by using the &ldquo;getent group&rdquo; command and piping it through &ldquo;grep&rdquo; to select only your GWS. For example:
getent group | grep gws_cedaproc gws_cedaproc:*:26015:fbloggs,jdoe You can lookup a specific user ID with the following:
getent passwd | grep fbloggs fbloggs:*:29775:26030:Fred Bloggs:/home/users/fbloggs:/bin/bash Maintaining group permissions throughout the GWS &nbsp; In order to maintain the group permissions throughout the GWS the highest level directory has the &ldquo;sticky bit&rdquo; set. This means that the default group for all files and directories created within the GWS will be the relevant gws_* access group. This is particularly useful to enable data within the GWS to be shared amongst collaborators. If users have a specific need to modify the group permissions they can do so using &ldquo;chgrp&rdquo; command.
Making directory contents writable by other members of the GWS &nbsp; If a user wishes to make their files/directories writable by others in the GWS they can follow the procedure here using the &ldquo;umask&rdquo; command:
Make a directory (and set it the permission so that the group can read/write to it):
mkdir --mode=u+rwx,g+rws,o-rwx testdir ls -l testdir drwxrws--- 2 jdoe gws_cedaproc 4096 Jan 26 14:36 testdir Or (as separate steps):
mkdir testdir chgrp g+rws testdir chgrp o-rwx testdir ls -l testdir drwxrws--- 2 jdoe gws_cedaproc 4096 Jan 26 14:36 testdir However, please also see security, below (and make sure your users are aware of this).
Check your umask:
umask 0022 Modify your &ldquo;umask&rdquo; so that any new file or directory that you create will be writable anyone with the group permission:
umask 002 touch testdir/newfile ls -l testdir -rw-rw-r-- 1 jdoe gws_cedaproc 0 Jan 26 14:39 newfile If you want the umask setting to persist, you should set it for yourself in your ~/.bashrc file, and advise your users to do the same.
Quota, resource allocation and GWS lifetime &nbsp; The overall usage of a GWS can be determined with the df (SOF) or pan_df (PFS) command:
pan_df -H /gws/pw/j07/workshop/ Filesystem Size Used Avail Use% Mounted on panfs://panmanager03.jc.rl.ac.uk/gws/pw/j07 2.6T 16G 2.6T 1% /gws/pw/j07/workshop/ df -H /gws/nopw/j04/ncas_generic Filesystem Size Used Avail Use% Mounted on quobyte@sds.jc.rl.ac.uk/gws_ncas_generic 83T 80T 3.4T 96% /gws/nopw/j04/ncas_generic For PFS (paths beginning /gws/pw/j07/*), the raw capacity of the GWS is 2.6TB (measured in TB, defined using powers of 10), but to obtain space available to users this should be divided by roughly 1.3, resulting in around 2TB of free space. Of this, 16GB is currently in use. The factor of 1.3 can depend on the number of small files stored in the GWS because lots of small files take up more space than expected.
For SOF (paths beginning /gws/nopw/j04/*), the value reported by df -H is the usable size.
A summary of specific sections of a GWS can be determined using pan_du -sh \\&lt;di\\r&gt; (PFS), and du -sh --si --apparent-size \\&lt;dir\\&gt; (SOF). Set the --apparent-size flag to get an accurate size.
Similarly, you can use the find command together with -atime or -mtime to locate files accessed or modified more than a certain length of time ago. For example, to find files which were accessed more than 1 year ago:
find /gws/nopw/j04/upscale/cache -type f -atime +365However, this can
consume significant system resources in running the du command, for a long time, and fail due to permission issues (as a regular user, you can&rsquo;t always &ldquo;see&rdquo; down all the directory branches) &hellip;So we provide some tools to help with this:
The GWS Scanner runs this for you, centrally, on a roughly 2-week cycle, and stores all the output in a database from which results can be visualised in the GWS Scanner User Interface.
There is also a live view of GWSs and the available space left on the JASMIN Dashboard. The “JASMIN Storage” tab shows many JASMIN storage volumes with information about current usage.
So please don&rsquo;t run large du or find jobs yourself, as this will be duplicating something already running in the background.
As a GWS Manager you will receive e-mails summarising the usage and contents of the GWS. If you wish for additional directories to be scanned and summarised please add these to the GWS scanner configuration.
The typical lifetime of a GWS is 3 years. All GWS managers are expected to actively manage the space during its lifetime and plan for the eventual reclamation of the space by deleting and migrating data to other locations. Typically, less-frequently-used data might be written to Elastic Tape (see below) and some final outputs would be curated in the CEDA Archive. In the latter case please note that you should discuss the requirements with the CEDA Archive team via the CEDA Helpdesk, ideally before the project starts.
Migrating data to tape &nbsp; Proactive data management is an important part of providing an effective GWS. We recommend that the GWS Manager discusses use of the space with the project team to ensure that the use of disk and tape are being optimised. This may involve use of the Elastic Tape system for backup or data migration (from disk to tape).
Requesting a change to the GWS size &nbsp; Although it is helpful to provide the best estimate of required allocation at the time of initially requesting the GWS, a GWS Manager may request a change in size (increase or decrease) of the GWS during its lifetime. We would positively encourage you to be honest about your requirements so that others can make use of this expensive resource if you are not using it until later in your project, or if you no longer require all the space you originally requested.
Requests for an increase in GWS size will be considered by the Consortium Manager with responsibility for managing an overall allocation to that particular scientific community. See Requesting Resources. Depending on available resources and competing demand, it may not always be possible to increase the allocation, and you may be asked to move data to Elastic Tape to free up disk space.
Security &nbsp; User account security is very important in a multi-user environment such as JASMIN. As a GWS Manager you have a responsibility to users of your GWS but also to all other GWS users in helping to maintain a safe and secure system in which productive scientific work can be done. There is a strict policy of one- user-one-key, and on no account must any user make use of the SSH key of another user to gain access to any part of the JASMIN infrastructure. Private keys MUST be protected by a strong passphrase. Please encourage adherence to these rules by users of your GWS. Any infringements may be dealt with swiftly by removal of user access. No offensive, obscene or otherwise unauthorised data may be stored in the GWS or anywhere else within JASMIN. Users should not store any data of a personal or sensitive nature in the GWS.
&nbsp; Do not set, or allow your users to set, open permissions on files or directories. By this we mean permissions where data are &ldquo;world-writable&rdquo; by anyone, for example
-rw-rw-rw- for a file, or &laquo; DON&rsquo;T USE THESE!!
drwxrwxrwx for a directory. &laquo; OR THESE!!
We provide a UNIX a group corresponding to each group workspace, which all members of that GWS belong to: this enables sharing within the group if you set permissions appropriately using that group. If you are unsure about setting permissions, please ask the helpdesk.
Keeping informed &nbsp; Please maintain contact throughout the life of the GWS via the following channels:
Using the JASMIN dashboard to check on the status of your GWS (used versus available space). Email alerts from the system when the GWS reaches &gt;83% full Email from the CEDA/JASMIN team News articles on the CEDA or JASMIN websites and by monitoring CEDA social media feeds which may be used to post messages regarding system status or security. CEDA Website CEDA News on Twitter If you are aware that a user who has access to your GWS leaves your project or, for whatever reason, no longer needs to be a member of the GWS, please let the JASMIN Helpdesk know either by email or via the beacon, lower right on this page. Arrangements may need to be made to transfer the ownership of files and/or directories to another member of the GWS to ensure continued access to the data.`}).add({id:125,tag:"en",href:"/docs/mass/",title:"MASS",description:"Read-only access to Met Office MASS archive",content:""}).add({id:126,tag:"en",href:"/tags/matlab/",title:"Matlab",description:"",content:""}).add({id:127,tag:"en",href:"/tags/met-office/",title:"Met Office",description:"",content:""}).add({id:128,tag:"en",href:"/docs/software-on-jasmin/name-dispersion-model/",title:"Met Office NAME Model",description:"Met Office NAME Model",content:`This article provides links to information about running the Met Office atmospheric dispersion model, NAME, on JASMIN.
The NAME atmospheric dispersion model &nbsp; The Met Office&rsquo;s Numerical Atmospheric-dispersion Modelling Environment (NAME) https://www.metoffice.gov.uk/research/modelling-systems/dispersion-model can be run on JASMIN using the LOTUS cluster. A NAME Group Workspace is provided to store both the Numerical Weather Prediction (NWP) met data needed to drive NAME as well as the user outputs derived from NAME itself.
This service has been developed through a collaboration between STFC CEDA, the Met Office Atmospheric Dispersion and Air Quality team and the University of Leicester.
If you would like to know more about running NAME on JASMIN, please contact us at atmospheric.dispersion@metoffice.gov.uk.`}).add({id:129,tag:"en",href:"/docs/getting-started/migrate-jasmin-account-from-ceda/",title:"Migrate a JASMIN account from CEDA",description:"Migrate a JASMIN account from CEDA",content:`&nbsp; JASMIN accounts created before February 2017 had to be migrated to use the JASMIN accounts portal. It is now no longer possible to do this migration automatically.
If you had a JAMIN account which you haven&rsquo;t used since before February 2017, we might be able to help you reclaim it. Please contact support@jasmin.ac.uk and if your account still exists we will advise as to if you are able to reclaim it.`}).add({id:130,tag:"en",href:"/docs/uncategorized/mobaxterm/",title:"MobaXterm (windows terminal client)",description:"MobaXterm (windows terminal client)",content:`Windows users are strongly recommended to connect to JASMIN using the freely available MobaXterm This article provides information about:
Downloading and installing MobaXterm Basic usage Setting up MobAgent to store your private key Additional features Versions of MobaXterm &nbsp; The instructions given below are for version 23 of MobaXterm. For other versions please check the MobaXterm documentation.
The method of configuring MobaXterm to store your private key has changed with different versions. The recommended method, and an alternative, are shown below.
Downloading and installing MobaXterm &nbsp; Download the free Home edition of MobaXterm.
There are 2 editions available:
&ldquo;Portable&rdquo; edition (can be installed as a regular user) &ldquo;Installer&rdquo; edition (may need admin privileges on your machine) Both editions should be functionally the same once installed, but your choice may depend on what level of access you have to your Windows machine.
For the &ldquo;portable&rdquo; edition, the contents of the downloaded zip file should be extracted to a folder (eg. on your Windows desktop) where you can double-click the executable file &ldquo;MobaXterm_Personal_xx.x&rdquo; (where xx.x is the version number). Note that the &ldquo;CygUtils.plugin&rdquo; file should remain in this folder as this is used for storing settings.
Once opened, MobaXterm presents a screen like this:
initial mobaxterm screen You can use the &ldquo;Start local terminal&rdquo; button or click the &ldquo;+&rdquo; tab to open multiple tabs with a different terminal session in each tab. However, it&rsquo;s worth setting up MobaXterm so that your private key is held globally, so that it&rsquo;s available to any new terminal session that you open.
Enabling MobAgent to store your private key &nbsp; In order to log in to a remote host (e.g. a jasmin host) you need to present your private key from where it&rsquo;s stored on your local machine. MobaXterm provides MobAgent which can store your key for the time you are running MobaXterm, and can then present the key for you, for any session in any tab, so you don&rsquo;t have to enter your passphrase for each new tab that you open.
The video below demonstrates this process, or you can follow the screenshots which follow:
You need to enable MobAgent in MobaXterm&rsquo;s Settings / Configuration / SSH :
ssh configuration To do this:
Tick &ldquo;Use internal SSH agent &ldquo;MobAgent&rdquo; UN-tick &ldquo;Use external Pageant&rdquo; Click the &ldquo;+&rdquo; symbol to locate your private key file (e.g. id_rsa_jasmin) Click OK to save the settings. MobaXterm will now need to restart. When you restart MobaXterm you will be prompted for the passphrase associate with your private key. passphrase prompt Once MobaXterm has started, you can check that your SSH key has been loaded by clicking on &lsquo;Start local terminal&rsquo; and using ssh-add -l to list the keys currently loaded.
IMPORTANT: in the command examples below, the dollar symbol &lsquo;$&rsquo; at the start of the command line in these example represents the shell prompt as displayed in your terminal - it does not need to be typed!
When you type the following command in the Mobaxterm terminal, you should see output similar to below:
ssh-add -l 2048 SHA256:1WgYUGSqffxJX6bWqBZvFsutN3Psjn5mcPV37r6D7vQ Imported-Openssh-Key (RSA) Sometimes the last part of this output shows your email address, but it is just a comment field at the end of the key, which can be ignored. The fact that it&rsquo;s returned something which looks like a key &ldquo;fingerprint&rdquo;, shows that your key is loaded successfully into the agent.
If you don&rsquo;t see your key listed in output similar to the above, please try again: perhaps you entered the wrong passphrase? But you will need to succeed in loading your key before you can connect to JASMIN.
Logging in to JASMIN using key stored in MobAgent (recommended) &nbsp; As shown in the video above, once you have set up MobAgent you can connect to JASMIN by creating a new terminal window. Click the &ldquo;Start local terminal&rdquo; button.
Next, try connecting to the login server:
ssh -A &lt;user_id&gt;@login2.jasmin.ac.uk (replace &lt;user_id&gt; with your own JASMIN username)
Logging in to JASMIN without storing your key in MobAgent &nbsp; MobAgent provides the most convenient way of accessing JASMIN. However, if you want to login to JASMIN without setting up MobAgent you can do so as follows.
Click on the &lsquo;Start local terminal&rsquo; button then enter the following command. The final 2 lines show the output you should see: you are prompted for your key&rsquo;s passphrase, then if successful, you see confirmation that the key is loaded.
eval $(ssh-agent -s) ssh-add ~/.ssh/id_rsa_jasmin Enter passphrase for ~/.ssh/id_rsa_jasmin: Identity added: ~/.ssh/id_rsa_jasmin If your key is named something different, or stored at a different location than shown above, you will need to specify its location in the ssh-add command. Note that MobaXterm refers to windows drives as e.g. /drives/c/ (with forward slashes). So if you&rsquo;ve put your key on your desktop, then the path to that might be /drives/c/Users/fred/Desttop/id_rsa_jasmin (if &quot; fred &quot; is your local username on Windows).
You will need to do this each time you open a new terminal session. To connect to JASMIN:
ssh -A &lt;user_id&gt;@login2.jasmin.ac.uk Again, you must replace &lt;user_id&gt; with your JASMIN username.
As you can see, the MobAgent method mentioned previously makes this a bit easier, because it persists between sessions and you navigate to the location of your private key using graphical tools instead of having to type the path.
Additional MobaXterm features &nbsp; MobaXterm is a comprehensive application that enables many useful features such as:
Saved session configurations X-forwarding / X11 / X server ( Not recommended on JASMIN : see NoMachine NX for graphical linux desktop instead) SSH agent forwarding SFTP access (with graphical drag-n-drop) Split-tab mode SSH tunnelling Basic Linux commands such as: cd, ls, pwd, cat Command-line transfer utilities: scp, rsync, wget Please see the MobaXterm documentation for details on these.`}).add({id:131,tag:"en",href:"/tags/model-validation/",title:"Model Validation",description:"",content:""}).add({id:132,tag:"en",href:"/tags/moose/",title:"Moose",description:"",content:""}).add({id:133,tag:"en",href:"/docs/mass/moose-the-mass-client-user-guide/",title:"MOOSE (the MASS client) User Guide",description:"MOOSE (the MASS client) User Guide",content:"External Users&rsquo; Version hosted on JASMIN."}).add({id:134,tag:"en",href:"/docs/getting-started/multiple-account-types/",title:"Multiple account types",description:"Multiple account types",content:`Trial period extended
This article defines the types of account available on JASMIN and their purpose. It covers:
STANDARD accounts (with note about training accounts) SHARED accounts SERVICE accounts Introduction &nbsp; For some time, we have been asked by user communities to cater for legitimate use cases where accounts need to be shared by a small, known and pre-arranged set of users, or by services or functions.
To maintain a secure approach, we have brought these together into a clearly- defined set of account types for each purpose.
These are being introduced on a trial basis as of 1st June 2023 for an initial period of 7 months.
Definitions &nbsp; STANDARD accounts &nbsp; A standard account:
is for use by one human individual user only. can login to the JASMIN accounts portal to (re)set a password, store an SSH key and apply for access roles. has a unique SSH key, traceable to its owner. Training accounts are a special type of STANDARD account, issued on a short-term basis and preconfigured with certain access roles as required for training events.
A standard account holder may act as a responsible user on one more service or shared accounts.
SHARED accounts &nbsp; A shared account:
is for use by a small, defined set of responsible users , each associated by their standard account username has a set of SSH public keys, one for each responsible user. The shared account itself does not have a key, and users do not share keys. The set of keys associated with the shared account is updated automatically in the event that any individual responsible user changes their the SSH key on their own standard account. can log in to the JASMIN accounts portal using the shared account username to apply for roles and can (re)set a a password, which may be shared securely** and only between the set of responsible users. The accounts portal profile for the shared account will display, but not allow editing of, the public keys of the responsible users. can be used by individual responsible users to login via SSH, but using their own individual SSH private key which must not be shared with any other user, and should be kept locally, i.e. not uploaded to anywhere on JASMIN. by default, emails originating from the JASMIN accounts portal destined for shared accounts are instead sent to all their responsible users. An optional email address for the shared account itself may be specified in the accounts portal profile for the account. can perform any action in the system that a standard account can, including but not limited to the following (and subject to membership of relevant access roles): becoming a member of a group workspace using elastic tape / JDMA submitting a job to the LOTUS batch processing cluster obtaining an short-lived credential for use with a high-performance transfer method may be requested by a user or group of users via the JASMIN helpdesk, but the decision as to whether to grant the request is at the discretion of the JASMIN team, after scrutiny of the request, its justification and the past JASMIN behaviour of the individual users proposed to be responsible for the shared account. **An example of a secure means of sharing a password is to use Keeper (or similar password manager system) to share a securely-stored entry with a specific list of other individuals in an encrypted form. Password sharing via unencrypted means (such as a text file, email or post-it note) is not permitted.
SERVICE accounts &nbsp; A service account:
is for use by a service or function only has one or more responsible users , each associated by their standard account username can never log in to the JASMIN accounts portal or (re)set a password. may be granted roles by arrangement with the JASMIN team has no SSH key emails originating from the JASMIN accounts portal destined for service accounts are instead sent to all their responsible users. An optional email address for the service account itself may be specified in the accounts portal profile for the account. may be requested by a user or group of users via the JASMIN helpdesk, but the decision as to whether to grant the request is at the discretion of the JASMIN team, after scrutiny of the request, its justification and the past JASMIN behaviour of the individual users proposed to be responsible for the service account. NOTES:
With the implementation of these new account types, existing setups will be examined and discussed with their &ldquo;owners&rdquo; and moved over to either service or shared account types as appropriate. Users of a shared or service account are jointly responsible for actions performed by the account. This requires coordination and communication between responsible users, which should be done independently of the JASMIN system. Membership of a shared or service account , and availability of the account itself, may be withdrawn if behaviour falls outside the JASMIN Terms and Conditions. In serious cases, individual users may be barred from further use of JASMIN altogether. Users are reminded to familiarise themselves with the Terms and Conditions and have a responsibility to keep up to date with them as they change. Users must also pay attention to service announcements made by the JASMIN team by email and other means. Requests for shared or service accounts should be sent to the JASMIN helpdesk with &ldquo;shared account request&rdquo; or &ldquo;service account request&rdquo; in the subject line.`}).add({id:135,tag:"en",href:"/docs/software-on-jasmin/nag-library/",title:"NAG Library",description:"The Numerical Algorithm Group (NAG) Library",content:`This article introduces the Fortran and C library of software under the Numerical Algorithm Group (NAG) license. NAG Library is a collection of robust, documented, tested and maintained numerical algorithms.
Accessing the NAG Library &nbsp; Requesting access &nbsp; If you wish to use the NAG Library on JASMIN you will need to request access via the JASMIN Accounts Portal at:
https://accounts.jasmin.ac.uk/services/additional_services/nerctools/
This will give your JASMIN user account access to the &ldquo;nerctools&rdquo; Unix Group that is used to limit access to NAG.
Loading the NAG Library for use on JASMIN &nbsp; The NAG library is made available via module command which is only available once you are on the scientific analysis servers and LOTUS cluster on JASMIN. In addition to loading a module for the library, you will usually need to load a module for the compiler you are using. For example:
module load contrib/nag/25 module list Currently Loaded Modulefiles: 1) intel/fce/15.0.090 2) contrib/nag/25 The NAG library is loaded as well as the Intel Fortran compiler. Now you can compile your code and link to the NAG library, for example:
ifort your_code.f90 -lnag_nag -o your_code.exec How to find a NAG library routine &nbsp; Please search the NAG documentation when looking for specific routines:
https://www.nag.co.uk/numeric/fl/nagdoc_fl25/html/indexes/kwic.html
How to use the NAG library &nbsp; The following shows the directory and file organisation of the materials.
/apps/contrib/nag/fll6i25dcl/ |- in.html (Installer&#39;s Note - this document) |- doc -|- un.html (Users&#39; Note) | |- lic_agr.txt (license agreement) | | |- libnag_nag.a (static self-contained library | | including NAG BLAS/LAPACK) | |- libnag_nag.so.25 (shareable self-contained library | | including NAG BLAS/LAPACK) | |- libnag_nag.so (symbolic link pointing at |- lib -| libnag_nag.so.26) | |- libnag_mkl.a (static library requiring | | MKL BLAS/LAPACK) | |- libnag_mkl.so.25 (shareable library requiring | | MKL BLAS/LAPACK) | |- libnag_mkl.so (symbolic link pointing at | libnag_mkl.so.26) fll6i25dcl -| |- nag_interface_blocks -|- * (interface blocks for Intel compiler) | | |- source --|- ??????e.f90 | | |- examples -|- data ----|- ??????e.d | | |- ??????e.opt | | | |- results -|- ??????e.r | | |- nag_example* (scripts to compile and run |- scripts -| NAG example programs) | | | |- nag_recompile_mods (script to recompile | interface blocks) | |- c_headers -|- * (C/C++ header file and information) | |- mkl_intel64_11.2.0 -|- * (Intel Math Kernel Library) | |- rtl -|- * (Intel compiler run-time libraries) | | |- bin -|- * (directories of license management | | binaries for supported platforms) |- license -|- README.txt | |- doc -|- * (license management documentation) Further information &nbsp; See the full NAG library manual at:
https://www.nag.co.uk/numeric/fl/nagdoc_fl26/html/frontmatter/manconts.html`}).add({id:136,tag:"en",href:"/tags/netcdf3/",title:"NetCDF3",description:"",content:""}).add({id:137,tag:"en",href:"/docs/short-term-project-storage/faqs-storage/",title:"New storage FAQs and issues",description:"New storage FAQs and issues",content:`&nbsp; This article was originally written in 2018/19 to introdice new forms of storage which were brought into produciton at that stage. Some of the information and terminology is now out of date, pending further review of JASMIN documentation. Workflows with some of the issues highlighted below will have a knock on effect for other users, so please take the time to check and change your code to make appropriate use of new storage system. If used correctly, the new storage offers us a high performance scalable file system, with the capability for object storage as tools and interfaces evolve, and we can continue to serve the growing demand for storage in the most cost effective manner.
We understand these changes may cause you some extra work, but we hope that you can understand why they were necessary and how to adapt to these changes. We will continue to add to this page when new issues or solutions are found.
1. Known cases where parallel write can occur (may be unknowingly to you!): &nbsp; Use of MPI-IO or OpenMPI &nbsp; Parallel threads can update the same file concurrently on same or from different servers.
Suggested solution: use a /work/scratch-pw* volume which is PFS (but not /work/scratch-nopw* !), then move output to SOF storage.
Writing all the logs from a LOTUS job or job array to the same output or log file &nbsp; Suggested solution: see job submission advice here showing how to use SBATCH options to use distinct output and log files for each job, or element of a job array.
Deleting a file via one host before another host has closed it &nbsp; This is a form of parallel write truncation
Suggested solution: take care to check for completion of 1 process before another process deletes or modifies a file. Be sure to check a job has completed before interactively deleting files from any server you are logged into (eg. sci1.jasmin.ac.uk)
Attempting to kill a process that was writing/modifying files, but not checking that it has been killed before starting a replacement process which attempts to do the same thing &nbsp; This can happen with rsync leading to duplicate copying processes.
Suggested solution: check for successful termination of 1 process before starting another.
Opening the same file for editing in more than one editor on the same or different servers &nbsp; Here’s an example of how this shows up using “lsof” and by listing user processes with “ps”. The same file “ISIMIPnc_to_SDGVMtxt.py” is being edited in 2 separate “vim” editors. In this case, the system team was unable to kill the processes on behalf of the user, so the only solution was to reboot sci1.
lsof /gws/nopw/j04/gwsnnn/ COMMAND PID USER FD TYPE DEVICE SIZE/OFF NODE NAME vim 20943 fbloggs cwd DIR 0,43 0 2450 /gws/nopw/j04/gwsnnn/fbloggs/sdgvm/ISIMIP vim 20943 fbloggs 4u REG 0,43 24576 2896 /gws/nopw/j04/gwsnnn/fbloggs/sdgvm/ISIMIP/.ISIMIPnc_to_SDGVMtxt.py.swp vim 31843 fbloggs cwd DIR 0,43 0 2450 /gws/nopw/j04/gwsnnn/fbloggs/sdgvm/ISIMIP vim 31843 fbloggs 3r REG 0,43 12111 2890 /gws/nopw/j04/gwsnnn/fbloggs/sdgvm/ISIMIP/ISIMIPnc_to_SDGVMtxt.py ps -ef | grep fbloggs ...... fbloggs 20943 1 0 Jan20 ? 00:00:00 vim ISIMIPnc_to_SDGVMtxt.py fbloggs 31843 1 0 Jan20 ? 00:00:00 vim ISIMIPnc_to_SDGVMtxt.py smc_1D-2D_1979-2012_Asia_NewDelhi.py Suggested solution: If you are unable to kill the processes yourself, contact the helpdesk with sufficient information to ask for it to be done for you. In some cases, the only solution at present is for the host or hosts to be rebooted.
2. Issues with small files &nbsp; The larger file systems in operation within JASMIN are suitable for storing and manipulating large datasets and not currently optimised for handling small ( &lt;64kBytes) files. These systems are not the same as those you would find on a desktop computer or even large server, and often involve many disks to store the data itself and metadata servers to store the file system metadata (such as file size, modification dates, ownership etc). If you are compiling code from source files, or running code from python virtual environments, these are examples of activities which can involve accessing large numbers of small files.
Later versions of our PFS systems handled this by using SSD storage for small files, transparent to the user. SOF however, can’t do this (until later in 2019), so in Phase 4, we introduced larger home directories based on SSD, as well as an additional and larger scratch area.
Suggested solution: Please consider using your home directory for small- file storage, or /work/scratch-nopw2 for situations involving LOTUS intermediate job storage. It should be possible to share code, scripts and other small files from your home directory by changing the file and directory permissions yourself.
We are planning to address this further in Phase 5 by deploying additional SSD storage which could be made available in small amounts to GWSs as an additional type of storage. [Now available: please ask about adding an &ldquo;SMF&rdquo; volume to your workspace]
Issues writing netCDF3 classic files to SOF storage type &nbsp; Writing netCDF3 classic files to SOF storage e.g. /gws/nopw/j04/* should be avoided. This is due to the fact that operations involving a lot of repositioning of the file pointer (as happens with netCDF3 writing) has similar issues from writing large numbers of small files to SOF storage (known as QB ).
Suggested solution: It is more efficient to write netCDF3 classic files to another filesystem type (e.g. /work/scratch/pw* or /work/scratch-nopw2) and then move them to a SOF GWS, rather than writing directly to SOF.
3. &ldquo;Everything&rsquo;s running slowly today&rdquo; &nbsp; _This can be due to overloading of the scientific analysis servers (sci*.jasmin.ac.uk) which we provide for interactive use. They’re great for testing a code and developing a workflow, but are not designed for actually doing the big processing. Please take this heavy-lifting or long-running work to the LOTUS batch processing cluster, leaving the interactive compute nodes responsive enough for everyone to use.
Suggested solution: When you log in via one of the login*.jasmin.ac.uk nodes, you are shown a &lsquo;message of the day&quot; a list of all the sci* machines, along with memory usage and the number of users on each node at that time. This can help you select a less-used machine (but don’t necessarily expect the same machine to be the right choice next time!).`}).add({id:138,tag:"en",href:"/tags/nomachine/",title:"Nomachine",description:"",content:""}).add({id:139,tag:"en",href:"/tags/notebook/",title:"Notebook",description:"",content:""}).add({id:140,tag:"en",href:"/tags/numpy/",title:"Numpy",description:"",content:""}).add({id:141,tag:"en",href:"/tags/nx/",title:"Nx",description:"",content:""}).add({id:142,tag:"en",href:"/tags/obs4mips/",title:"Obs4mips",description:"",content:""}).add({id:143,tag:"en",href:"/tags/orchid/",title:"Orchid",description:"",content:""}).add({id:144,tag:"en",href:"/docs/batch-computing/orchid-gpu-cluster/",title:"Orchid GPU cluster",description:"Orchid GPU cluster",content:`This article provides details on JASMIN&rsquo;s GPU cluster, named ORCHID.
GPU cluster spec &nbsp; The JASMIN GPU cluster is composed of 16 GPU nodes:
14 x standard GPU nodes with 4 GPU Nvidia A100 GPU cards each 2 x large GPU nodes with 8 Nvidia A100 GPU cards ORCHID GPU cluster Request access to ORCHID &nbsp; Before using ORCHID on JASMIN, you will need:
An existing JASMIN account and valid jasmin-login access role: Apply here&nbsp; &nbsp; &nbsp; Subsequently (once jasmin-login has been approved and completed), the orchid access role: Apply here&nbsp; &nbsp; &nbsp; The jasmin-login access role ensures that your account is set up with access to the LOTUS batch processing cluster, while the orchid role grants access to the special LOTUS partition used by ORCHID.
Holding the orchid role also gives access to the GPU interactive node.
Note: In the supporting info on the orchid request form, please provide details on the software and the workflow that you will use/run on ORCHID.
Test a GPU job &nbsp; Testing a job on the JASMIN ORCHID GPU cluster can be carried out in an interactive mode by launching a pseudo-shell terminal Slurm job from a JASMIN scientific server e.g. sci2:
srun --gres=gpu:1 --partition=orchid --account=orchid --pty /bin/bash srun: job 24096593 queued and waiting for resources srun: job 24096593 has been allocated resources # you are now on gpuhost16 The GPU node gpuhost016 is allocated for this interactive session on LOTUS
Note that for batch mode, a GPU job is submitted using the Slurm command &lsquo;sbatch&rsquo;:
sbatch --gres=gpu:1 --partition=orchid --account=orchid gpujobscript.sbatch or by adding the following preamble in the job script file
#SBATCH --partition=orchid #SBATCH --account=orchid #SBATCH --gres=gpu:1Note 1: gpuhost015 and gpuhost016 are the two largest nodes with 64 CPUs and 8 GPUs.
Note 2: CUDA Version: 11.6
Note 3: The Slurm batch partition/queue orchid has a maximum runtime of 24 hours and the default runtime is 1 hour. The maximum number of CPU cores per user is limited to 8 cores. If the limit is exceeded then the job is expected to be in a pending state with the reason being QOSGrpCpuLimit
GPU interactive node &nbsp; There is an interactive GPU node gpuhost001.jc.rl.ac.uk, with the same spec as other Orchid nodes, that you can access via a login server to prototype and test your GPU code prior to running as a batch job.
ssh -A gpuhost001.jc.rl.ac.uk # you are now on gpuhost001 Software Installed on the GPU cluster (to be updated) &nbsp; CUDA drivers 10.1, and CUDA libraries 10.0, 10.1 and 11.4 CUDA DNN (Deep Neural Network Library) NVIDIA container runtime (see notes below) NGC client (GPU software hub for NVIDIA) Singularity 3.7.0 - which supports NVIDIA/GPU containers SCL Python 3.6`}).add({id:145,tag:"en",href:"/tags/packages/",title:"Packages",description:"",content:""}).add({id:146,tag:"en",href:"/tags/partition/",title:"Partition",description:"",content:""}).add({id:147,tag:"en",href:"/tags/password/",title:"Password",description:"",content:""}).add({id:148,tag:"en",href:"/docs/software-on-jasmin/postgres-databases-on-request/",title:"Postgres databases on request",description:"Postgres databases on request",content:`Introduction &nbsp; This article explains that users may request access to a PostgreSQL (known as Postgres) database on JASMIN for use with scientific workflows.
Overview of the user database service &nbsp; There are a large number of different workflows on JASMIN and it is common for users to require access to persistent storage of information about the progress of a workflow. In some cases, it is appropriate for users to save information in a relational database. Examples might be to create/update/delete data records (when working with small results) or to store the success/failure of batch tasks (running on LOTUS).
To meet this need, a user database service is available on request. The service provides secured access to a Postgres database that is accessible from the interactive and batch compute nodes on JASMIN. An individual user, or group of users, can be issued with login credentials to enable read and/or write access to the database.
How to request a Postgres database for use on JASMIN &nbsp; In order to request a Postgres database from the user database service, please ensure you have a JASMIN Login account and then send a message to the JASMIN Helpdesk. You should include the following information in your message:
state that you would like a user database set up your JASMIN user ID Postgres details: database name, database user account name the expected size of the database (fully populated) machines (inside JASMIN) from which you would like to contact the database If you require backups of the database to be made. Postgres extensions &nbsp; The Postgres installation includes the following extension:
PostGIS&nbsp; Backups &nbsp; By default we make daily backups of the databases, which are kept for a week. We keep a weekly backup for a month and a monthly backup for 6 months. These intervals may be subject to change, so if you have particular concerns about backups please let us know. If your database is particularly large we may either make less frequent backups or not make backups at all. We will discuss any particular backup requirements you may have when we set up your database.
You should contact the JASMIN Helpdesk to request access to previous backups.
Restrictions and limitations &nbsp; Please note that the following restrictions and limitations apply to the user database service:
We cannot provide training in SQL or the use of relational databases: please ensure that you have the appropriate experience before requesting access. There is a size limit on the server and the disk that the user databases are housed on: if you expect to store many GBs of data then please discuss this with the JASMIN Team. The database cannot be made accessible outside the JASMIN firewall: it is intended to support applications and workflows that take place inside JASMIN. The database should not be considered as a long-term data store: you should migrate any content elsewhere if you intend to keep it for the medium or long term.`}).add({id:149,tag:"en",href:"/docs/uncategorized/processing-requests-for-resources/",title:"Processing requests for resources",description:"Processing requests for resources",content:`This article is for consortium managers and explains:
The overall process and role of consortium manager How to process a request for new resources for a service, submitted by a project How to process a request for additional resources on an existing project&rsquo;s service Introduction &nbsp; Please make sure you have read the article &ldquo;Requesting resources&rdquo; to understand how the process works from the requester&rsquo;s point of view.
This article will show you how to process requests for resources, but also show you what you need to consider when doing so.
Overall process &nbsp; The overall process for handling requests for resources from projects is summarised as follows. It all happens via the JASMIN Projects Portal.
A project owner will have created a record representing a project for you to review This will come to you for review because they have selected your consortium as the most relevant to their work. But this means that the resources they are requesting need to come out of your consortium allocation. The project record should contain: A project description Requests for 1 or more services. Each proposed service (e.g., a Group Workspace or a Cloud Tenancy) can have 1 or more requirements for resources For a Group Workspace service, these could be requirements for disk or tape storage For a Cloud Tenancy service, these could be requirements for disk, CPU and memory resources for the tenancy Once all the requirements for a service have been agreed with the project owner, you, as consortium manager can submit the request for provisioning by the JASMIN team. Different services on the same project can be provisioned separately: for example, we can provision the Group Workspace resources while you&rsquo;re still discussing what&rsquo;s needed for a cloud tenancy. But all the requirements for a particular service (for example, disk and tape, for a Group Workspace) need to be agreed before it can be submitted for provisioning. If necessary, certain requirements can simply be rejected and excluded from the submission and can be added later. Requests made by projects directly to the JASMIN team will be referred back to this process, as it&rsquo;s essential that we manage valuable resources in an organised manner, involving you as consortium manager to make decisions for your consortium&rsquo;s allocations. So this does involve active engagement on your part. Once resources have been provisioned, you should be notified so that you can track the progress of the request on behalf of the project. Role of the consortium manager &nbsp; Your task when reviewing should be to:
Check that the project has selected the appropriate consortium: does this activity sit within your domain? Scrutinise the project&rsquo;s request for use of your allocation of consortium resources for this project. Questions to consider are: Do the proposed resource requirements sound reasonable? Have they properly considered using shared services like scratch and XFC to minimise the need for their own dedicated resources? For example: Instead of 100TB SOF for their Group Workspace, could they manage with 25TB, knowing that copious scratch space is nearly always available? Could some of the 100TB go on tape first, &ldquo;streaming&rdquo; their processing so that only some fraction is needed on disk at a time? Have they asked for tape resources alongside their disk space? (this would reassure you that they&rsquo;ve considered a sensible workflow like above, but you might want to discuss with them). It&rsquo;s reasonable to ask for an equivalent amount of space on tape as on disk. Historically this has usually been provisioned by default anyway, but we do want to capture what the project actually plans to use. Is the proposed workflow free of unnecessary duplication of data already available elsewhere on JASMIN, either in the CEDA Archive or other Group Workspaces (which can be processed in place rather than needing to be copied)? Some of this information will be in the project description but feel free to contact the project owner to gather more details yourself to form your opinion. Are the start and end dates realistic? You will need to reclaim your consortium&rsquo;s resources once a project has finished (in order to support other projects from your allocation), so it&rsquo;s important that these dates are agreed and regularly reviewed. Does the project actually need all the requested resources initially, or could they manage with some fraction to start with? &ldquo;Hogging&rdquo; disk space (or other resources), but not using it, wastes expensive resources. Is there a date beyond which the data could be moved off disk onto tape, freeing up disk? The project&rsquo;s requirements can be modified during its lifetime to achieve this, but this should be considered (at the start) as a way to &ldquo;sunset&rdquo; the disk requirements while keeping some data still available after the active phase of the project. Group Workspace storage is short-term storage for the duration of a project only. Keeping data in Group Workspace disk storage in an open-ended way is bad for a number of reasons: other projects won&rsquo;t have the resources they need, plus there are a number of data-sharing services attached to the CEDA Archive (such as, enabling other projects to discover the data) which make this a much better place to share data from, with all the benefits of professional data curation. The disk requirement for Group Workspaces should only be allocated for the active phase of the project where working space is needed. Longer-term visibility of any data produced should be addressed by involving the CEDA Archive team at the project planning stage. Processing a request for new resources &nbsp; Log in to the JASMIN Projects Portal
This requires your JASMIN credentials (so you need to have a JASMIN account to proceed). Two-factor authentication is used: you can opt to send a verification code to the email address registered with your JASMIN account, then enter that code to proceed. Check your spam folder if the message doesn&rsquo;t appear.
Follow the &ldquo;Consortia&rdquo; link at the top, to show all the consortia. The one(s) you are responsible for will have a &ldquo;Go to consortium&rdquo; button.
Click &ldquo;Go to consortium&rdquo;
This screen has 3 tabs: we are looking at the &ldquo;overview&rdquo; tab first, showing your how much of each type of resource is committed (provisioned) against the allocated resources for your consortium.
Go to the &ldquo;Projects&rdquo; tab. If you have any projects with outstanding items for review, the number of projects will be indicated next to the &ldquo;Projects&rdquo; tab.
Here we can see all the projects in this consortium: scroll down to see &ldquo;cards&rdquo; for all the projects. The tab indicated that there were 2 to be reviewed and these are labelled here too.
Click &ldquo;Go to Project&rdquo; for the one you want to review, to see the project overview screen.
The &ldquo;Overview&rdquo; screen for a project gives you the timeline of what&rsquo;s happened (most recent first) so you can see the description and any comments.
Now go to the &ldquo;Services&rdquo; tab, to see what service(s) this project thinks it needs, and what resources are requested for those services:
In this case, they&rsquo;re just asking for a Group Workspace, and have documented a requirement for 10 TB of SOF disk space, between the dates shown. For now, we&rsquo;ll just consider how to approve that one request (but you could encourage them to ask for tape space as well, then approve both together).
The SOF requirement is in the &ldquo;REQUESTED&rdquo; state, meaning it&rsquo;s awaiting your review, so click the &ldquo;?&rdquo; icon, to review that requirement:
Here, you can see that this requirement for 10 TB SOF of SOF disk is OK in terms of your consortium&rsquo;s overall allocation for SOF (1.6 PB), and current commitments (770.2 TB or 48%) against that allocation. But only you know what other projects are in the pipeline in your science domain:
is there some big project on the horizon which will need lots of space in the near future? if you&rsquo;re struggling for space, are there other projects which you could ask to give up some or all of their disk space, if they&rsquo;ve finished their work? if they&rsquo;ve asked for particular types of disk space (PFS, SSD or HPOS), have they justified why? The default storage type for Group Workspaces should be SOF, but there may be reasons why others are more appropriate, e.g. HPOS (Object Storage) for visibility inside / outside of JASMIN (to be encouraged!) SSD (Solid State Disk) for small file storage (but very limited amounts available, normally 100GB at a time) PFS (Parallel File System) for workflows which absolutely must be able to write in parallel to the same file from multiple processes (&hellip;but there are 2 PB of scratch space available for this purpose, so consider carefully). If you want to suggest changes to the project (e.g. you think they&rsquo;ve picked the wrong type) you can &ldquo;Reject&rdquo; with comments, and they can re-submit the request.
If you&rsquo;re happy to approve, click &ldquo;Approve&rdquo;:
The SOF requirement now has status &ldquo;APPROVED&rdquo; so (as long as there are no other requirements in &ldquo;REQUESTED&rdquo; state), you can click &ldquo;Submit for provisioning&rdquo;.
If there are other requirements that have been requested, you either need to approve them too, or reject them so that you can agree acceptable resource request with the project owner.
If submitted, the requirement will then have the status &ldquo;AWAITING PROVISIONING&rdquo; and the JASMIN team will pick up the request to arrange provision of the resources.
Once the JASMIN team has completed provisioning the resources, the status changes to &ldquo;PROVISIONED&rdquo; and the location is confirmed: in this case giving the path to the disk space now that&rsquo;s now available.
At this point, the project owner who requested the resources would also be notified to check the status on the portal, so should be able to pick up the location, but you may wish to check with them yourself, to track the request to completion.
Processing a request for additional resources &nbsp; Where a project already exists, a project owner can submit a request for changes to resources on an existing service, or could request an additional service (e.g. adding a cloud tenancy where there&rsquo;s already a Group Workspace). Adding an additional service should work as described above, but reviewing a request to modify resources on an existing service, is shown below:
We start from the project overview screen (so check above for steps to reach that):
We can see in the comments that something has been requested: those comments are attached by the project owner to provide extra context to the request.
Go to the Service tab to review further:
Here we can see the original 10 TB which is &ldquo;PROVISIONED&rdquo; but above it is the request for the additional 1 TB, with status &ldquo;REQUESTED&rdquo;.
Click the &ldquo;?&rdquo; to review:
From the consortium manager&rsquo;s point of view, it&rsquo;s the same process as before, so go through the same steps to scrutinise the request.
Reject the request (with comments) if you want the project owner to change things, or approve it if you&rsquo;re happy:
Now the request is marked as &ldquo;APPROVED&rdquo;, and since we have no other requests in &ldquo;REQUESTED&rdquo; state for you to review, you can click &ldquo;Submit for provisioning&rdquo;.
Once you have submitted it, the request is marked &ldquo;AWAITING PROVISIONING&rdquo; for the JASMIN team to pick up.
In this case, we&rsquo;re adding space to the same service, so when it comes to recording what&rsquo;s provisioned, the 10 TB &amp; 1 TB &ldquo;chunks&rdquo; will be combined (in terms of how they&rsquo;re recorded here), reflecting the fact that the JASMIN team will have simply expanded the size of the (single) disk volume. This makes sense if the project has asked for more space, but the total space is needed until the end of the whole project. So the previous 10TB (the record, not the actual disk) has been marked &ldquo;DECOMMISSIONED&rdquo;:
An alternative, which might be applicable in some cases, is where the extra space &ldquo;boost&rdquo; is only needed for a shorter period of time, as shown by the different end dates to the 2 requirements below. They&rsquo;re both referring to the same physical storage, but the extra 1 TB space &ldquo;expires&rdquo; first.
Processing requests for resource types other than storage &nbsp; The process for reviewing requests for other resource types, such as those needed for cloud tenancies, is the same as above. Further examples may follow here as needed.`}).add({id:150,tag:"en",href:"/docs/interactive-computing/project-specific-servers/",title:"Project-specific servers",description:"Project-specific servers",content:`&nbsp; Deprecated feature documented here to provide information about how to access existing instances. Project-specific servers are no longer provided on request, as most use cases can be satisfied by a tenancy in the JASMIN cloud. This article introduces the project specific servers. It covers:
What is a project-specific server? &nbsp; Previously, projects could be provided with dedicated servers built with specific software required by the project, or where access needs to be restricted to members of a project or institution.
Get Access &nbsp; On the JASMIN accounts portal, you can apply for access to an existing Project VM.
Step 1: Select Project VMs from the Discover Services menu on the left
discover services menu Step 2: You can either browse the page listing or do a search on the Project VMs. For example here using CEDA as a keyword search and to apply for access to CEDA_scisup, click apply or look into More information
locate relevant server apply for access provide supporting information and submit request request pending`}).add({id:151,tag:"en",href:"/docs/for-cloud-tenants/provisioning-tenancy-sci-vm-managed-cloud/",title:"Provisioning a Sci VM in a Managed Cloud Tenancy",description:"Provisioning a Sci VM in a Managed Cloud Tenancy",content:`This article is for admins and managers of managed-cloud tenancies and shows how to provision a sci VM within one. It involves the following:
Becoming a member of a managed cloud tenancy Provisioning a VM A &ldquo;sci vm&rdquo; is essentially the same as the general-access scientific analysis servers, but created within a specific tenancy aimed at a certain group of users. The manager/deputy then has the responsibility to stop/start/restart or redeploy the VM, and to control who can access it.
The managed cloud tenancy has four access roles:
MANAGER role: can approve DEPUTY, ADMIN, and USER role access requests DEPUTY manager role: can approve ADMIN and USER role access requests ADMIN role: can access the cloud portal and can restart or provision the Sci VM USER role: can log in into the sci VM from a JASMIN login node Apply for access to the Sci tenancy &nbsp; A managed cloud tenancy is accessible via the JASMIN cloud portal&nbsp; . Access is controlled by a service corresponding to the name of the tenancy: these services are listed under Sci Analysis VMs&nbsp; category of &ldquo;My Services&rdquo;.
Access the tenancy &nbsp; With an ADMIN role, you can log in to the JASMIN cloud portal using the same credentials for signing into the JASMIN accounts portal.
You will be presented with the &ldquo;Dashboard&rdquo; page -below- showing the tenancies you have access to. On the dashboard, select the organization representing the tenancy to find out the VM provisioned within a given tenancy, e.g ncas-sci-M
dashboard showing tenancies available to this user Note: The &ldquo;ncas-sci-M&rdquo; tenancy shown below has 0 machines as this is a new tenancy. We will proceed next to the provisioning of a virtual machine.
Provision a virtual machine &nbsp; Step 1: Select &ldquo;Machines&rdquo; from the top menu, then click &ldquo;New machine&rdquo; to create a new VM. Choose a name for the new VM. Then select a size from the drop-down menu which shows the catalog of VM template size. For example, select &ldquo;j4.large&rdquo; which allocates 8 CPUs and 32GB of RAM resources for the new VM
IMPORTANT: A Sci machine should be deployed with a minimum of 2 GB RAM
IMPORTANT : A Sci machine name should not exceed 8 characters long. The preferred naming format is sci e.g. sci1
dialogue for creating a new VM The VM with the chosen name ncas-sci1 is created and it is running as shown below.
vm now shown in dashboard Step 2: Attach an external IP to the new VM by clicking &ldquo;Actions&rdquo; and selecting &ldquo;Attach external IP&rdquo;. Note that you can restart the VM from the &ldquo;Actions&rdquo; menu.
attach external IP (1) Step 3: From the box that pops up -see image below- click on the &ldquo;+&rdquo; (green button) to add an IP. Then click on the down arrow next to &ldquo;Select an external IP&rdquo; you will see the IP address to assign to the machine, select the IP and click attach IP
attach external IP (2) Step 4: Click &ldquo;Attach IP&rdquo;
Important note: As ADMIN and MANAGER of a Sci tenancy, you should note the &ldquo;External IP&rdquo; as this is the IP address you will need to provide to your users in order for them to connect to the machine via SSH using a JASMIN login server.
summary dashboard showing IP allocated. Step 5: An overview of the resources used by the VM is shown below
resources dashboard Note 1: Only ADMIN and MANAGER roles have access to the JASMIN cloud portal and can provision VMs. ADMIN and MANAGER roles of a Sci tenancy will not be granted root access.
Note 2: ADMIN and MANAGER roles will not allow you to SSH into the Sci VM. It is necessary to have a USER role to do so.
Connect to the VM &nbsp; From a JASMIN login server, login to the machine using the External IP address. In the same way, as you login to a JASMIN scientific server via login1. Your initial connection to JASMIN from your local machine needs to have your SSH key loaded in your SSH authentication agent, and you must have SSH Agent Forwarding enabled &ldquo;-A&rdquo;, see also how MISSING LINK.
terminal session showing connection to new VM Note that although the new provisioned Sci VM has a local hostname (in this example, sci1-202012041148.ncas-sci-m.jasmin.ac.uk ), this is NOT registered in any Domain Name Service (DNS) by default, and we are not able to arrange this for you, so you need to connect to the machine using its External IP address, not the name.
Note : Users should report issues to the ADMIN and/or MANAGER of the tenancy based SCI VM initially, rather than the JASMIN team. If the issue cannot be resolved by the ADMIN and/or MANAGER, they should contact the JASMIN helpdesk.`}).add({id:152,tag:"en",href:"/tags/python/",title:"Python",description:"",content:""}).add({id:153,tag:"en",href:"/docs/software-on-jasmin/python-virtual-environments/",title:"Python Virtual Environments",description:"Python Virtual Environments",content:`This article describes how you can use &ldquo;virtual environments&rdquo; to install Python packages that are not provided in the common software environments on JASMIN. You might wish to do this if you want to use different packages/versions from those installed on the system, or if you have requested for a package to be installed system-wide but wish to start using it before this request can be acted upon.
To decide whether you should use a Python virtual environment or a Conda environment for this purpose, see: overview of software environments.
What is a &ldquo;virtual environment&rdquo;? &nbsp; A &ldquo;virtual environment&rdquo; is a self-contained directory tree that contains a Python installation for a particular version of Python (such as 2.7, 3.7, 3.8), plus a number of additional packages. It provides a very useful method for managing multiple environments on a single platform that can be used by different applications.
Creating a virtual environment &nbsp; As a pre-requisite, when using any modern Python (i.e. Python2.7 onwards), you shouldactivate a Jaspy environment before following the instructions below.
Python allows you to create a directory containing a private virtual environment, into which you can install your packages of choice. This is done differently for python2 and python3, as follows:
# Python 3 onwards: python -m venv /path/to/my_virtual_env # Python 2.7 (deprecated) virtualenv /path/to/my_virtual_env The path can be an absolute or relative path, but it should not already exist. Note: /path/to/my_virtual_env here (and also in the commands shown below) should be replaced by the actual path where you choose to create your virtual environment.
Using the system &ldquo;site-packages&rdquo; with your virtual environment &nbsp; Note that if you create a virtual environment using the above syntax, the packages initially installed in it will only be those in the standard Python library. This means, for example, that the numpy package (not in the standard library, but installed as part of Jaspy) will be unavailable unless you install it yourself. If you would prefer as a starting point to have all the add-on packages which have already been installed in Jaspy, then use instead:
python -m venv --system-site-packages /path/to/my_virtual_env This will work for most packages in Jaspy. We have seen situations where one or two packages from Jaspy do not work in private virtual environments, and if you are affected by this then please see the &ldquo;package-specific fixes&rdquo; section below.
Activating a virtual environment &nbsp; Before the virtual environment can be used, it needs to be &quot; activated &ldquo;. This is done by running the activate script using the source command:
source /path/to/my_virtual_env/bin/activate (If you prefer, you can use . instead of source.)
After you run the activate script, some environment variables will be set so that the python (or python2.7 (deprecated), python3) command will point to the one in the virtual environment, allowing installation and use of packages in that environment.
You can see that python points to the python executable in the virtual environment, with:
which python /home/users/my_username/my_virtual_env/bin/python Note that you have to source the activate script in every shell (login session) in which you intend to use the virtual environment. If there is a particular virtual environment which you want to use consistently, you might consider putting the command to source the activate script in your $HOME/.bashrc file.
If you wish to deactivate the currently active virtual environment in a particular shell, just type deactivate. The environment variable changes will be undone, and you will again be using the system default set of packages. This is also reflected in the shell prompt.
Installing packages into a virtual environment &nbsp; Once you have activated a virtual environment, the pip utility will be available. This allows package installation into the environment using the command:
pip install your_package pip is quite flexible what you can use for your_package. It can include:
a package name in the Python Package Index (PyPI) a URL pointing to a package repository the local path of a .tar.gz or .zip file containing the package source the local path of a directory containing the extracted package source the download URL of a .tar.gz or .zip file If the package requires other packages that are not already installed into the virtual environment, then pip will use the package&rsquo;s requirements file to install them automatically from PyPI.
One thing to consider when doing this, is that some temporary space is needed by the install process. The location of this temporary space may be set by default to /tmp, which is restricted on the sci machines.
You might see this error, despite having ample free space in your own home directory:
ERROR: Could not install packages due to an OSError: \\ [Errno 122] Disk quota exceededIn order to avoid encountering this, you are advised to follow this advice to over-ride the TMPDIR environment variable, setting it to the location of somewhere you know have free space. Don&rsquo;t forget to clean up afterwards!
To upgrade an existing package, use:
pip install --upgrade your_package If your Python package cannot be installed with pip for any reason, it can also be installed directly from the setup.py file after activating the virtual environment.
python setup.py install To install a specific version of a package, this can be specified with:
pip install your_package==1.2.3 Inspecting the virtual environment &nbsp; To list the packages installed into the virtual environment, with their version numbers, type:
pip freeze Using the virtual environment &nbsp; Interactive use &nbsp; After you have activated the virtual environment in your shell, any packages that you have installed into it can be imported into an interactive python session.
python automatically uses python in your virtualenv The prompt changes to &gt;&gt;&gt;:
import my_package Scripts &nbsp; If a script is run using the python command on the command-line in a similar way to when starting an interactive Python session, this will use any virtual environment that has been activated in the calling shell.
python my_script.py If an executable script is run using the #! mechanism, and the first line of the script has the hard-coded path to the executable in the virtual environment, then it is not necessary to activate the virtual environment in the calling shell.
head -n 1 myscript.py show the first line #!/path/to/my_virtual_env/bin/python3.7 chmod u+x myscript.py ensure that it is executable ./myscript.py run it As an alternative to hard-coding the path of the virtual environment, it is possible to use the /usr/bin/env approach to ensure that the script is run using whichever python executable is found via $PATH. The script will then run using any virtual environment that has been activated in the calling shell. This makes the script more portable, although at the expense of having to source the activate script.
head -n 1 myscript.py #!/usr/bin/env python3.7 chmod u+x myscript.py ./myscript.py Package-specific fixes &nbsp; When using the --system-site-packages option in combination with Jaspy, it has been found that some packages provided by Jaspy (and which work correctly in the Jaspy environment itself) require fixes in order to use them in virtual environments that are created on top of Jaspy. In particular:
if you use shapely, we suggest to reinstall this into your virtual environment using pip install --ignore-installed shapely after activating the environment if you use geopandas, you will need to reinstall shapely as above, and also when running python you will need to set an environment variable to enable it to find the spatialindex library. After loading Jaspy and activating the virtual environment, you could use either one of the following: export LD_LIBRARY_PATH=$CONDA_PREFIX/lib:$LD_LIBRARY_PATH export LD_PRELOAD=$CONDA_PREFIX/lib/libspatialindex.so:$CONDA_PREFIX/lib/libspatialindex_c.so Note that these environment variables could potentially also affect the behaviour of other Linux commands, although unlikely, so you might prefer to set them only for the python session (using a command of the form env variable_name=value python) rather than using export.
if you use cartopy (also used by iris), you may need to create a symbolic link into your virtual environment to allow the correct loading of libgeos_c.so during import cartopy or import iris. To do this: ln -s $CONDA_PREFIX/lib/libgeos_c.so /path/to/my_virtual_env/lib/`}).add({id:154,tag:"en",href:"/tags/queue/",title:"Queue",description:"",content:""}).add({id:155,tag:"en",href:"/tags/quickstart/",title:"Quickstart",description:"",content:""}).add({id:156,tag:"en",href:"/docs/software-on-jasmin/quickstart-software-envs/",title:"Quickstart for activating/deactivating software environments",description:"Quickstart for activating/deactivating software environments",content:`This article provides a minimum quick-start guide for working with software environments on JASMIN.
Activate (load) an environment &nbsp; To activate an environment containing the &ldquo;current&rdquo; common software packages (including a modern Python):
module load jaspy or for a specific version, see how to discover what versions are available
To activate additional packages (known as &ldquo;jasmin-sci&rdquo;):
module load jasmin-sci Deactivate (unload) an environment &nbsp; If you want to deactivate an environment that you have previously activated, do:
module unload &lt;env-id&gt; Where &ldquo;&rdquo; is the name used when you activated the environment.
Which environment(s) should you use? &nbsp; If you are not sure which environment(s) to use please see details on the overview of Jaspy and &ldquo;jasmin-sci&rdquo; environments page.`}).add({id:157,tag:"en",href:"/tags/quota/",title:"Quota",description:"",content:""}).add({id:158,tag:"en",href:"/tags/r/",title:"R",description:"",content:""}).add({id:159,tag:"en",href:"/docs/data-transfer/rclone/",title:"rclone",description:'A "Swiss army knife" tool for data transfers',content:`This article provides information about the rclone data transfer tool. In particular:
what is rclone? installing rclone for yourself on JASMIN. configuring rclone Dos and Don&rsquo;ts What is rclone? &nbsp; rclone is a command-line utility which enables access to lots of different storage systems including object stores and cloud-based storage. It can also move data between directories act as an SFTP client so could be used to access files on JASMIN.
It is very well documented already, so rather than repeat that information here, this article highlights aspects relevant to its use on JASMIN.
Further information will follow in due course as our experience with this tool develops.
Installing rclone for yourself on JASMIN &nbsp; First off, do not attempt to follow the documented instructions for installing on Linux. As a regular user, you do not have root/administrator permission and are not permitted to run scripts using sudo. Normally most utilities are already installed for you on JASMIN, but in this case you need to adapt the documented instructions so that you can safely install this in your OWN home directory. [That may change in the future if this tool proves useful].
The recommended procedure for installation on JASMIN is as follows:
Fetch and unpack the Linux binary distribution: (in your home directory on an xfer server)
curl -O https://downloads.rclone.org/rclone-current-linux-amd64.zip unzip rclone-current-linux-amd64.zip cd rclone-*-linux-amd64 Next, move the rclone executable to your own bin directory. You may need to create that directory if it does not exist already, and add it to your PATH environment variable in your ~/.bash_profile file.
# only need these if these aren&#39;t in place already in your own setup: mkdir ~/bin comment here # add this to your PATH (add to your ~/.bash_profile to make this permanent) export PATH=&#34;~/bin:$PATH&#34; # move the rclone executable mv rclone ~/bin/ # make the permissions on the file executable by you chmod 700 ~/bin/rclone Note that you will not have installed the man pages, so these will not be available: please consult the online documentation instead.
Configuring rclone &nbsp; Configuring rclone is covered in the rclone documentation. Essentially you need to configure a &ldquo;remote&rdquo; representing each storage system you want to interact with. You can then use rclone to manage data between those &ldquo;remotes&rdquo;.
Dos and Don&rsquo;ts &nbsp; Please DO NOT use the following features on JASMIN (at least until further notice). Some of these features look useful, but more work is needed to understand if/how they can be used safely on JASMIN without causing problems. rclone mount (mounting a remote as a filesystem) - DO NOT USE rclone rcd (remote control daemon) - DO NOT USE rclone serve(serve remote over a protocol) - DO NOT USE You should safely be able to use the following, between remotes that you have configured: rclone copy rclone sync rclone lsd rclone ls ..(other basic commands) Help on a particular command is found using
rclone &lt;command&gt; --help Further examples of useful ways of using rclone on JASMIN will follow&hellip;`}).add({id:160,tag:"en",href:"/docs/getting-started/reconfirm-email-address/",title:"Reconfirm JASMIN account email address",description:"Reconfirm JASMIN account email address",content:`This article describes how to reconfirm the email address associated with your JASMIN account.
For security reasons, this is a process which you will be asked to repeat annually.
Once a year, you will receive an email asking you to reconfirm your email address. You will receive reminders to do this 2 months, 2 weeks and finally 2 days before the required date. Once you are within 2 months of the required date, you can carry out the steps below at any time within before the required date: the sooner the better.
Visit your profile at the JASMIN Accounts Portal https://accounts.jasmin.ac.uk If you are already signed in you can get to your profile by following the link to &ldquo;My JASMIN Account&rdquo;, otherwise you will be automatically taken to your profile when you sign in. Click the “Confirm now” button in your JASMIN profile to request that an email containing a confirmation link is sent to your email address. If this button is not visible and instead you see the message &ldquo;confirmed&rdquo; next to your email address: already confirmed this indicates that your email address has already been confirmed and no further action is necessary.
Wait for the email to arrive, then click on the special one-time link within it. You need to complete this step within the time limit specified in the email (2 days). If the link has expired, you can repeat step 2 to generate a new link. Once you have successfully completed the process, your account profile page will be updated with a message confirming this. Look out for the reminder email in 10 months&rsquo; time inviting you to re-confirm again. If you don’t complete the process before the required date, you may find that your account is suspended along with privileges attached to the account (e.g. access to group workspaces etc). However, neither your account nor any of your data be deleted , so please get in touch with the helpdesk to restore your access if this should happen.
Please also contact the helpdesk if:
You know that you will be away from access to your institutional email for a significant period (e.g. 1 year) You no longer need your JASMIN account You need to change your email address You cannot update the email address yourself, since a change of institution may affect your eligibility to some JASMIN services. See here for details of how to update other aspects of your JASMIN account.`}).add({id:161,tag:"en",href:"/tags/reject/",title:"Reject",description:"",content:""}).add({id:162,tag:"en",href:"/docs/uncategorized/requesting-resources/",title:"Requesting resources",description:"Requesting resources",content:`How projects and resources are managed &nbsp; Resouces on JASMIN, such as storage and compute, are allocated to science communities separated into &ldquo;consortia&rdquo;. Each consortium has a manager: a representative of that science community who is in touch with its major activities and understands the resource requirements for projects in that domain. Representatives of individual projects should discuss requirements with their Consortium Manager, who is best placed to make decisions about the allocation of JASMIN resources within that consortium. Requirements can be documented using the “JASMIN Resource Management” tool, but need to be approved by a Consortium Manager before being passed to the JASMIN Team for provisioning.
See here for further details, including a list of current consortia and their managers.
Accessing the JASMIN projects portal &nbsp; The JASMIN projects portal provides a place to:
document the resources required for a project (new projects, or changes to existing projects) submit those requirements for review track the provision of those resources Usually, you would only need to access the projects portal if you are:
the Principal Investigator (or their delegated project manager) for a project to document requirements for a project to invite other individuals (with a JASMIN account) who may wish to view and/or discuss the requirements a consortium manager to review/approve resource requirements Note: Please do not make requests yourself unless you are involved in the management of the project: speak to the project or group workspace (GWS) manager and ask them to make the request.
These users need to log in with their JASMIN account credentials, the same as those used for the JASMIN accounts portal. 2-factor authentication is in use, with verification codes sent to the email address associated with your JASMIN account (this is the same process used to access the JASMIN notebook service).
Once you have logged in, you are presented with a view of the projects where you are named as owner or collaborator (or, for consortium managers, where you are the relevant consortium manager. [A further guide for consortium managers about how to process requests for resources is available here).
Create a project to record resource requirements &nbsp; To create a new project:
Go to &ldquo;My Projects&rdquo; Click &ldquo;Start new project&rdquo; Enter details for the project, as described below.
A project can have several Services, such as:
a group workspace a managed cloud tenancy an external cloud tenancy [particular compute requirements*] some services are not yet able to be described/requested via this tool, but will be soon. please contact the helpdesk if you&rsquo;re not able to describe what you need. To add the services needed for the project:
in the panel on the right, click &ldquo;Add Service&rdquo; Select the category of service required: in this case, we&rsquo;re making requirements for a group workspace, but the available options are: Group Workspace (for shared disk storage for a project) External Tenancy VIO (for an external cloud tenancy on the VIO cloud platform) Managed Tenancy VIO (for a managed cloud tenancy on the VIO cloud platform) (please do not use the &ldquo;&hellip; Tenancy MCP &quot; options as these will soon be removed) Provide a short name for the service Click &ldquo;create&rdquo;. A Service may have several requirements, but, for example, we could request 10 TB of SOF storage for our GWS:
SOF (scale-out filesystem) is the usual type of storage used for GWS volumes, but you could also request:
HPOS (high-performance object store available via an S3-like interface) PFS (parallel file system, by special request if certain workflows specifically need this) SSD (Solid State Disk, used for &ldquo;small files&rdquo; or &ldquo;SMF&rdquo; volumes for storing code or virtual environments to share within a GWS. It is assumed that you&rsquo;ve considered carefully how you will do your work on JASMIN, with some knowledge of its services and components. You may find the following helpful:
Article: Understanding new JASMIN storage JASMIN workshop overview talk, explaining the main services offered by JASMIN how your request will be scrutinised by the relevant consortium manager. Once created, the requirements appear in the list, along with their start and end dates and status. This one is &ldquo;REQUESTED&rdquo;.
Click &ldquo;Submit for review&rdquo; and the manager of the relevant consortium will be notified that they need to review the request, with status updated to &ldquo;REQUESTED&rdquo;.
Only a user with &ldquo;OWNER&rdquo; status on a project can submit the project for review. It&rsquo;s best if one person coordinates with the consortium manager once the outline plan has been agreed with other project contacts (see inviting another user and joining a project, below)
If there are multiple requirements, make sure these are all documented so that the consortium manager can consider them all together, in context. Just repeat the process above for each additional requirement.
The project is marked as &ldquo;UNDER REVIEW&rdquo; while the requirements are being agreed.
The consortium manager may approve, reject or request changes to the requirements before they are agreed.
Once the consortium manager has agreed, the requirements are ready for provisioning: the JASMIN team will then manage the provisioning of the requested resources and the project contact will be notified when this is complete and the new resources available.
Invite another user &nbsp; By default, information in the projects portal is only visible by those nominated &ldquo;collaborators&rdquo; on the project, the relevant consortium manager, and the JASMIN Team (or others involved in the provision of JASMIN services). To share your plans for what&rsquo;s needed on a project with other individuals, you can invite another user to the project:
Go to &ldquo;My Projects&rdquo; In the panel on the right, click the link with the number of current collaborators Enter the email address of the other user you wish to invite, and press &ldquo;Invite&rdquo; Although you are inviting them by email address, they must have a JASMIN account in order to access the projects portal. Join an existing project by invitation from another user &nbsp; If you have received an invitation code from an existing collaborator on a project, you can use it to join a project as follows:
Go to &ldquo;My Projects&rdquo; Click &ldquo;Join existing project&rdquo; Enter the invitation code which the other user has sent you. Request additional resources for an existing project &nbsp; You can add new requirements to a project once it has been PROVISIONED (but not while it&rsquo;s already UNDER_REVIEW).
To add new requirements, go to &ldquo;My Projects&rdquo; and create the new requirement.
For example, if a GWS currently has 10 TB of SOF space provisioned, and the new and an additional 5 TB of space is needed, then:
If the GWS as a whole has the same end date, then create a new requirement for 15TB, with that end date, and submit this so that it can be reviewed. If it&rsquo;s just a temporary / short-term boost of storage that&rsquo;s needed consider whether scratch or XFC storage would suffice create a requirement for the additional storage only, confirming the start and end dates of the new storage in some cases, the end dates of the original storage will be out-of-date, so please agree new dates with your consortium manager as part of this process. Although these examples have concentrated on storage requirements, the same methods apply to requesting cloud tenancies. More detail on how to request these, and additional methods for documenting requirements for compute resources, will follow in due course.
Alternatives &nbsp; In some cases, it may not be appropriate to provide dedicated resources to certain projects. Your consortium manager should be able to help you look at other options. In some cases, a relevant project may already exist, and by discussion with the appropriate manager of that project, it may be possible for you to make use of those existing resources without the need to create a new one. There is a certain management overhead associated with setting up and operating each project&rsquo;s dedicated services, which use expensive resources, so requests do have to be considered carefully.
The following &ldquo;generic&rdquo; Group Workspaces exist for general use by members of these communities and often solve the problem of a small GWS needed by an individual:
ncas_generic : (National Centre for Atmospheric Science) nceo_generic : (National Centre for Earth Observation) ceh_generic : (UK Centre for Ecology and Hydrology) In these cases, the relevant consortium manager is usually the manager of the &ldquo;generic&rdquo; workspace so can approve applications for access to these workspaces themselves.
Please consult the list of available group workspaces for other options.
Another alternative, for easily accessible short-term storage for an individual user is the JASMIN Transfer Cache (XFC) service.`}).add({id:163,tag:"en",href:"/tags/requests/",title:"Requests",description:"",content:""}).add({id:164,tag:"en",href:"/tags/requirement/",title:"Requirement",description:"",content:""}).add({id:165,tag:"en",href:"/tags/requirements/",title:"Requirements",description:"",content:""}).add({id:166,tag:"en",href:"/docs/getting-started/reset-jasmin-account-password/",title:"Reset JASMIN account password",description:"Reset JASMIN account password",content:`This article illustrates how to reset the password of your JASMIN account to access the JASMIN Accounts Portal. On the JASMIN Accounts Portal sign-in page, select &ldquo;Forgotten password&rdquo; on the &ldquo;useful links&rdquo; menu:
Follow Forgotten password Step 1 : You will be directed to the following page. Enter your email address that is registered with your JASMIN account
Enter email address Step 2: You will receive an email from the JASMIN accounts portal containing a link which can only be used once and it will expire in two days
Read instructions Example of email from jasmin-accounts containing a link which can only be used once and it will expire in two days
Example email Step 3: Enter the new password, confirm it and then click &ldquo;Reset password&rdquo;
Enter new password & click Reset password Finally, you have now reset the password of your JASMIN account portal.`}).add({id:167,tag:"en",href:"/tags/rose/",title:"Rose",description:"",content:""}).add({id:168,tag:"en",href:"/tags/rscript/",title:"Rscript",description:"",content:""}).add({id:169,tag:"en",href:"/docs/data-transfer/rsync-scp-sftp/",title:"rsync, scp, sftp",description:"Data Transfer Tools: rsync, scp, sftp",content:`This article tells you about some of the basic transfer tools available for use with JASMIN that work over an SSH connection:
rsync (over SSH) scp sftp rsync over SSH &nbsp; rsync is a file synchronisation and file transfer program for Unix-like systems that can minimise network data transfer by using a form of delta encoding such that only the differences between and source and destination data are actually transmitted. rsync can compress the data transferred further using zlib compression and SSH or stunnel can be used to encrypt the transfer.
rsync is typically used to synchronise files and directories between two different systems, one local and one remote. For example, the command:
rsync mydata remoteuser@remotehost:/data/ will use SSH to connect as remoteuser to remotehost. Once connected, it will invoke another copy of rsync on the remote host, and then the two programmes will talk to each other over the connection, working together to determine which parts of mydata are already on the remote host and don&rsquo;t need to be transferred over the connection.
The generic syntax is:
rsync [OPTION] ... SRC [SRC] ... [USER@]HOST:DEST rsync [OPTION] ... [USER@]HOST:SRC [DEST] &hellip;where SRC is the file or directory (or a list of multiple files and directories) to copy from, and DEST represents the file or directory to copy to. (Square brackets indicate optional parameters.)
For more information visit the official rsync website.
rsync example with JASMIN &nbsp; Here is a simple example using rsync over SSH to your home directory copy a file to a Group Workspace on JASMIN:
exec ssh-agent $SHELL ssh-add ~/.ssh/id_rsa_jasmin # local path to your private key file rsync myfile &lt;username&gt;@xfer1.jasmin.ac.uk:/gws/nopw/j04/myproject/data/ NOTE: The first two lines are the standard method for setting up the SSH agent in order to allow connections without prompting for a passphrase each time.
scp &nbsp; scp is another basic command-line tool for secure copying between two machines. It is installed as part of most SSH implementations and comes as standard on the JASMIN transfer servers. scp is the secure analogue of the rcp command. Typically, the syntax of scp is like the syntax of cp (copy):
To copy a file to a host:
scp myfile remoteuser@remotehost:directory/target To copy a file (or directory) from a host to the local system:
scp remoteuser@remotehost:directory/source target scp -r remoteuser@remotehost:directory/source_folder target_folder Note that if the remote host uses a port other than the default of 22, it can be specified in the command. For example, copying a file from host over a non- standard SSH port (2222):
scp -P 2222 remoteuser@remotehost:directory/source target For more information on scp please visit the following website.
sftp &nbsp; sftp is a similar command-line tool to scp, but the underlying SFTP protocol allows for a range of operations on remote files which make it more like a remote file system protocol. sftp includes extra capabilities such as resuming interrupted transfers, directory listings, and remote file removal.
For basic transfer of a file on JASMIN to the local machine:
sftp remoteuser@xfer1.jasmin.ac.uk:/group_workspaces/jasmin/myproject/data/notes.txt ./ For more information see the Wikipedia page on SFTP.
There are various 3rd-party tools and clients, for example, WinSCP, FileZilla, MobaXterm and others, which can do transfers using the SCP and/or SFTP protocols. Please refer to the documentation for that particular software, but the basic principles are the same, i.e that you can set up a connection to a remote host by specifying the same parameters that you would with the command- line tool, but often through a graphical user interface instead.
Note on performance &nbsp; While convenient and familiar to many users, the tools described above do not make efficient use of available bandwidth for transferring large quantities of data via high-speed networks over long distances. Please consult Data Transfer Tools to learn more about which might be the most appropriate tool to use in different contexts.`}).add({id:170,tag:"en",href:"/docs/software-on-jasmin/running-python-on-jasmin/",title:"Running python on JASMIN",description:"Running python on JASMIN",content:`On the JASMIN analysis machines and on Lotus, we currently support Python version 3.10 through Jaspy.
When you log in, the default version of Python is 2.7.5 which is the used by the operating system. You shoud now use a more modern version of Python as v2.x is now deprecated. We recomment using the Jaspy environments. In this example, we activate the current Jaspy environment before running Python.
module load jaspy Check the Python version:
python -V Python 3.10.8 Run a script:
python your_script.py If you want to use an executable script (which can be invoked just by name), then the recommended line to put at the top of the script would be:
#!/usr/bin/env pythonafter which you should set &ldquo;write&rdquo; permission, and then you can run it without the &ldquo;python &quot; prefix:
chmod 755 your_script.py ./your_script.py You should work with Python on the scientific analysis servers. Login servers do not have any software installed, or filesystems mounted other than home directories.`}).add({id:171,tag:"en",href:"/docs/software-on-jasmin/running-r-on-jasmin/",title:"Running R on JASMIN",description:"Running R on JASMIN",content:`On the JASMIN sci servers and LOTUS, we support the use of R through the &ldquo;jasr&rdquo; environment(s), as listed on the Jaspy page.
In order to activate the R environment, you will need to use:
module load jasr Note that the Jaspy page lists all available environments. You can also list the R packages that are available in the environment by typing:
ls $CONDA_PREFIX/lib/R/library/ Once you have activated the environment, you can start R, using:
R R version 4.0.5 (2021-03-31) -- &#34;Shake and Throw&#34; Copyright (C) 2021 The R Foundation for Statistical Computing Platform: x86_64-conda-linux-gnu (64-bit) R is free software and comes with ABSOLUTELY NO WARRANTY. You are welcome to redistribute it under certain conditions. Type &#39;license()&#39; or &#39;licence()&#39; for distribution details. Natural language support but running in an English locale R is a collaborative project with many contributors. Type &#39;contributors()&#39; for more information and &#39;citation()&#39; on how to cite R or R packages in publications. Type &#39;demo()&#39; for some demos, &#39;help()&#39; for on-line help, or &#39;help.start()&#39; for an HTML browser interface to help. Type &#39;q()&#39; to quit R. [Previously saved workspace restored] If you have an R script that you wish to run, you can use the &ldquo;Rscript&rdquo; command, such as:
Rscript &lt;myscript&gt; The following shows the options available when using &ldquo;Rscript&rdquo;:
Rscript --help Usage: /path/to/Rscript [--options] [-e expr [-e expr2 ...] | file] [args] --options accepted are --help Print usage and exit --version Print version and exit --verbose Print information on progress --default-packages=list Where &#39;list&#39; is a comma-separated set of package names, or &#39;NULL&#39; or options to R, in addition to --no-echo --no-restore, such as --save Do save workspace at the end of the session --no-environ Don&#39;t read the site and user environment files --no-site-file Don&#39;t read the site-wide Rprofile --no-init-file Don&#39;t read the user R profile --restore Do restore previously saved objects at startup --vanilla Combine --no-save, --no-restore, --no-site-file --no-init-file and --no-environ &#39;file&#39; may contain spaces but not shell metacharacters Expressions (one or more &#39;-e &lt;expr&gt;&#39;) may be used *instead* of &#39;file&#39; See also ?Rscript from within R The version number (currently 4.0.5) is reported when you start R, or if you type: R --version R version 4.0.5 (2021-03-31) -- &#34;Shake and Throw&#34; Copyright (C) 2021 The R Foundation for Statistical Computing Platform: x86_64-conda-linux-gnu (64-bit) R is free software and comes with ABSOLUTELY NO WARRANTY. You are welcome to redistribute it under the terms of the GNU General Public License versions 2 or 3. For more information about these matters see https://www.gnu.org/licenses/. Here are commands to do a simple plot to a file, which you can use to test running R either interactively or with &ldquo;Rscript&rdquo; as described above.
png(&#34;myplot.png&#34;) x &lt;- c(1,2,3,4) y &lt;- x*x plot(x,y) dev.off()(You could use the &ldquo;display&rdquo; command on JASMIN to view the output file.)
Here is a minimal example of using the &ldquo;library&rdquo; command to load one of the many add-on libraries that have been installed to supplement the core R distribution. It uses the &ldquo;prettyunits&rdquo; package to convert a number of bytes to human-readable format.
module load jasr R --quiet library(prettyunits) pretty_bytes(12345678) [1] &#34;12.35 MB&#34; Finally, to quit R, type the following:
q() Save workspace image? [y/n/c]: n`}).add({id:172,tag:"en",href:"/tags/s3/",title:"S3",description:"",content:""}).add({id:173,tag:"en",href:"/docs/data-transfer/scheduling-automating-transfers/",title:"Scheduling/Automating Transfers",description:"Scheduling/Automating Transfers",content:`This article explains how to schedule or automate data transfers. It covers:
Using Globus for transfer automation Scheduling download tasks using cron and LOTUS Overview &nbsp; In many cases it can be useful to fetch data from an external source for processing/analysis on JASMIN on a regular basis, for example &ldquo;every Monday at 11:00 fetch all last week&rsquo;s data&rdquo;. It can also be helpful to distribute the task downloading of some large datasets, or simply to be able rely on data being pulled in from some external source to an accumulating dataset used for periodic analysis.
Using Globus for transfer automation &nbsp; It is easy to automate transfers using Globus. This method has the advantage that you do not need to remain connected or logged in to any JASMIN server for the automated transfers to take place on your behalf, and the transfer itself can be more efficient than other methods described below.
Some introductory information about how to do this is available in this article Using the Globus command-line interface (with more to follow) but please also refer to the comprehensive Globus documentation and their automation examples. You can choose whether to schedule/automate tasks via the Globus web interface&nbsp; , command-line interface&nbsp; , or use their Globus Python SDK&nbsp; to build Python code that uses this functionality.
Scheduling download tasks using cron and LOTUS &nbsp; While the cron server cron.jasmin.ac.uk is provided for scheduling general tasks, it should not be used for the work of executing those tasks itself, and not for transfer tasks.
xfer3 - transfer machine with cron &nbsp; The transfer server xfer3.jasmin.ac.uk is also provided with cron, and should be used where a task is primarily a transfer rather than a processing task and needs the functionality of a transfer server. For access to xfer3 you will need the xfer-sp access role&nbsp; . Please refer to the above cron guidance for best practice advice.
Invoking LOTUS from cron to carry out multiple download tasks &nbsp; Sometimes we need a task to be invoked from cron but executed where there are lots of nodes to parallelise the tasks (i.e. the LOTUS cluster). In this case, we DO need to use the cron server rather than xfer3, since we need to be able to talk to LOTUS (xfer3 can&rsquo;t do that, as a transfer server).
This will only work where the download can happen over HTTP(S), so depends on how the remote data is made available.
We need it to:
invoke a job submission script at regular intervals have that script initiate downloads using LOTUS nodes In the examples below, we use the test queue (or partition, as queues are known in SLURM). You can use this for testing, but once you know roughly how long your download(s) should take, you should choose an appropriate queue so that the jobs can be scheduled in a fair way alongside other users&rsquo; jobs.
1. Single download script &nbsp; The simple script below is used to download a single file from an external source via HTTP using wget. It initially uses the test partition (queue), but once you had tested it, you would need to use a more appropriate queue.
#!/bin/bash #SBATCH --partition=test #SBATCH -o %j.out #SBATCH -e %j.err #SBATCH --time=00:30 # executable wget -q -O 1MB_$SLURM_JOBID.zip http://speedtest.tele2.net/1MB.zipIn this example, the file is labelled with the id of the job which downloaded it, e.g. 1MB_61117380.zip
The same could be also achieved using curl, or using a Python script making use of (for example) the requests library.
A note about transfer tools: since we are delegating the actual download task to a LOTUS node, we are restricted to transfer tools already installed on those nodes or available in the user&rsquo;s path at a location cross-mounted with nodes in the LOTUS cluster (see Table 1 in Access to Storage), such as $HOME or a group workspace. It is not possible for the JASMIN team to install specialist data transfer tools across the whole cluster, so you may be limited to downloading via HTTP(S), FTP, or via tools available via libraries in the Python environment such (which you do have access to and can easily customise to install additional libraries using virtual environments).
Due to networking limitations, LOTUS nodes cannot perform downloads using SSH-based methods, i.e. scp/rsync/sftp.
Download tools installed on LOTUS nodes include:
wget curl ftp (but not lftp) In our simple example above, we can subit this script to LOTUS from the command line with
sbatch test_download.sh This could be invoked on a regular basis by adding a crontab entry like this
30 * * * * sbatch /home/users/username/test_download.shHowever it would be safer to wrap this in a crontamer command like this to ensure one instance of the task had finished before the next started: (see Using cron for details)
30 * * * * crontamer -t 2h &#39;sbatch /home/users/username/test_download.sh&#39; 2. Multi-node downloads &nbsp; We could expand this example to download multiple items, perhaps 1 directory of data for each day of a month, and have 1 element of a job array handle the downloading of each day&rsquo;s data.
A few words of warning: Distributing download tasks as shown below can cause unintended side-effects. Here, we&rsquo;re submitting an array of 10 download jobs, each initiating a request for a 1MB file which may well happen simultaneously. So we need to be confident that the systems and networks at either end can cope with that. It would be all too easy to submit a task to download several thousand large data files and cause problems for other users of JASMIN (and other users on its host institution&rsquo;s network), or indeed at the other end. Taken to the extreme, this could appear over the network as a Distributed Denial-of-Service (DDoS) attack. As with all LOTUS tasks: start small, test, and increase to sensible scales when you are confident it will not cause a problem. A limit of 10 jobs would be a sensible maximum, for one user.
We&rsquo;ll simulate this here by downloading the same external file to 10 different output files, but you could adapt this concept for your own purposes depending on the layout of the source and destination data.
#!/bin/bash #SBATCH --partition=test #SBATCH -o %A_%a.out #SBATCH -e %A_%a.err #SBATCH --time=00:30 #SBATCH --array=1-10 #SBATCH --time=00:30 # executable wget -q -O 1MB_$SLURM_ARRAY_TASK_ID.zip http://speedtest.tele2.net/1MB.zip echo &#34;script completed&#34;In this (perhaps contrived) example, we&rsquo;re setting up an array of 10 elements and using the SLURM_ARRAY_TASK_ID environment variable to name the output files (otherwise they&rsquo;d all be the same). In a real-world example you could apply your own logic to divide up files or directories matching certain patterns to become elements of a job array.
The script could then be scheduled to be invoked at regular intervals as shown in (1).
Some tools provide functionality for mirroring or synchronising directories, i.e. only downloading those files in a directory which are new have been added since the last time a task was run. These can be useful to avoid repeated downloads of the same data.`}).add({id:174,tag:"en",href:"/tags/sci/",title:"Sci",description:"",content:""}).add({id:175,tag:"en",href:"/docs/interactive-computing/sci-servers/",title:"Scientific analysis servers",description:"Scientific analysis servers",content:`Intro &nbsp; Once you have logged on to one of the login servers you can then ssh to a scientific analysis (sci) server to do your work. The sci servers are not directly accessible outside the firewall of RAL (JASMIN&rsquo;s host instution) so most users will need to access them via a login server.
Available sci servers &nbsp; The following sci servers are available:
Server name Virtual/Physical (OperatingSystem) Processor model CPU Cores RAM (GB) /tmp (GB) sci1.jasmin.ac.uk V (CentOS7) Xeon(R) Silver 4114 CPU @ 2.20GHz 8 32 N/A [Note 2.] sci2.jasmin.ac.uk V (CentOS7) Xeon(R) E5-2630 @ 2.20GHz 8 32 [Note 2.] sci3.jasmin.ac.uk P (CentOS7) [Note 1.] AMD EPYC 7402 48 1000 25 sci4.jasmin.ac.uk V (CentOS7) Xeon E5-2660 @ 2.20GHz 8 32 N/A [Note 2.] sci5.jasmin.ac.uk V (CentOS7) Intel(R) Xeon(R) CPU E5-2630 v4 @2.20GHz 8 32 N/A [Note 2.] sci6.jasmin.ac.uk P (CentOS7), [Note 1.] AMD EPYC 7402 48 1000 25 sci8.jasmin.ac.uk P (CentOS7), [Note 1.] Intel(R) Xeon(R) Gold 5118CPU @ 2.30GHz 24 383 25 Notes &nbsp; 1. Physical servers &nbsp; Hosts sci[3,6,8].jasmin.ac.uk are physical servers on a private internal network, so outbound internet access (via NAT) is only for HTTP(S), so outbound SSH will not work (to hosts outside of JASMIN) on these machines. If you try to git pull/clone from external repositories e.g. Github, the operation will timeout with error fatal: Could not read from remote repository. The solution in this case is to access git pull/clone over HTTPS instead (check the repo for alternative access details).
2. /tmp on VMs &nbsp; The local /tmp of the virtual sci servers is not available (N/A) for users as this is used by the VM itself. It also provides no performance advantage as it is not local to the server.
3. Arbiter &nbsp; A monitoring utility &ldquo;Arbiter&rdquo; is implemented across all sci machines to control CPU and memory usage. This utility records the activity on the node, automatically sets limits on the resources available to each user. Users&rsquo; processes are thus capped from using excessive resources, and can be slowed or have memory reduced in response to repeated violations.
4. Privileges &nbsp; Users are not permitted to execute commands which require administrative privileges. This applies to all hosts in the managed part of JASMIN where users have SSH login access (for example login, nx-login, sci, xfer and hpxfer machines). In other words, the use of su or sudo is not permitted. Please be careful when typing commands, particularly if you have multiple terminal windows open on your own computer, that you do not accidentally attempt sudo on a JASMIN machine: expect some follow-up from the JASMIN team if you do!
See also Software installed, below.
Purpose &nbsp; Scientific analysis servers are designed for interactive and ad-hoc analysis of data in group workspaces, the CEDA archive, and users&rsquo; home directories. For long-running and resource-intensive jobs, users are required to use the LOTUS cluster which offers better I/O performance, parallelism, and fair-share scheduling.
The following guidelines should be considered when using the scientific analysis servers:
Check available resources before your process starts and choose a sci server that is suitable (check average load in the list displayed at the login screen on the login servers, or by using the Linux monitoring commands: top, or free -h ) Execution/processing time should be less than 1 hour Serial jobs only High memory jobs should be executed on the physical servers which have more memory (labelled P in above table). Monitor your process on a sci server using top or ps Linux commands Report if there is a user&rsquo;s process affecting the performance of a scientific server Software installed &nbsp; Each sci server has the following features:
CentOS7 operating system with development tools. [NB: Rocky9 from summer 2024] Software packages that make up the JASMIN Analysis Platform are all installed - providing commonly-used open-source analysis tools. These packages include NCO, CDO, Python (with netCDF4, matplotlib, numpy etc.,) and R. Access to proprietary tools, e.g. IDL and Intel Fortran, through the module system. Ability to run graphical applications: use the NX graphical desktop service for best performance. Further information on using the software provided on JASMIN can be found here.
See [Note 4] above about privileges: you can only install software for yourself if it can be done with user-level privileges.
Access to storage &nbsp; Each sci server has:
Access to the LOTUS /work/scratch-pw* and /work/scratch-nopw2 volumes. Read access to the CEDA Archive according to permissions on your CEDA account. Read/Write access to Group Workspaces according to membership.`}).add({id:176,tag:"en",href:"/tags/scp/",title:"Scp",description:"",content:""}).add({id:177,tag:"en",href:"/tags/scratch/",title:"Scratch",description:"",content:""}).add({id:178,tag:"en",href:"/docs/short-term-project-storage/secondary-copy-using-elastic-tape/",title:"Secondary copy using Elastic Tape",description:"Secondary copy using Elastic Tape",content:`&nbsp; Information below relates to the Elastic Tape command-line tools. The JDMA system provides a better interface for putting/retrieving data into the Elastic Tape System) A new system called NLDS is coming very shortly (as of Feb 2023) and will eventually replace both of these. Introduction &nbsp; Elastic Tape is a system developed for use with JASMIN Group Workspaces (GWSs), enabling the Group Workspace Manager to:
Optimise their use of high-performance online disk by moving data to and from cheaper near-line storage Create and manage secondary copies of GWS data At present, the system is designed only to be used by GWS Managers, rather than individual members of a GWS. It is the responsibility of a GWS Manager to create and manage backups or additional copies of data in a GWS.
The servers used to access Elastic Tape changed in January 2021. Previous users should note that the server to use now is et.jasmin.ac.uk.
The maximum size for any file put into Elastic Tape is 500GB. This changed in 2023, when the underlying tape system was upgraded. Please limit your files to less than 500GB.
Who can use ET? &nbsp; ET is only for use by the named GWS manager, i.e. the individual responsible for managing the GWS disk space. The high-performance disk space used for a GWS is a valuable commodity and the role of the GWS Manager involves making best use of the online space. This may mean moving data to tape to free up space online, or taking a copy of online data to make a secondary copy. No undertaking is provided that the secondary copy will exist beyond the lifetime of the Group Workspace itself, hence it is called a secondary copy and not a backup. It is also NOT long-term archive storage: some data in GWSs may need to be earmarked for longer-term archive storage and wider availability via the CEDA Archive, but this is a separate process for which data management plans, ingest processes and metadata need to be put in place. Please contact the helpdesk if this is the case, but ideally this needs to be considered at project design phase (as it may need funding!).
Each GWS has a quota of online disk space (agreed at the time of its creation) and initially the ET quota has been set to the same value. So if you have a 10 Tb workspace, you initially have a 10Tb quota of ET storage to match.
How does it work? &nbsp; Putting data into ET storage involves creating a &ldquo;batch&rdquo; of data which is transferred to the ET system. Using either a file list or top-level directory for reference, the system calculates resources needed and creates a batch, identified by a batch ID. This must be retained by the GWS manager as a &ldquo;ticket&rdquo; for later retrieval of this batch of data. It is recommended that you assess the data that you plan to transfer so that you have an idea of the overall volume to be transferred before initiating any actual transfer jobs. It is also recommended to test operation with a small set of test data.
Transparent to the user, and asynchronously (so it is not necessary to wait with a terminal window open), the data are transferred first to online cache and then to tape storage. It is not an instant process and the task of migrating data from online cache to tape can take several hours, even days, depending on factors such as the size of the transfer, contention for the tape system and network conditions. An RSS feed and a web page provide updates on the process of data transfer for each batch. Data can later be retrieved, or removed from ET storage via similar tools.
The transfer of data via a batch involves the &ldquo;registration&rdquo; of each file in a database so that its existence is recorded.
Command line tools are provided on a dedicated machine within the JASMIN infrastructure, to which GWS managers will be given access. A GWS manager has access to the python tools et_put.py, et_get.py, et_rm.py and et_ls.py. Some initial documentation for these command line tools is attached.
What should I do next? &nbsp; It is recommended to try sending and retrieving some small data transfers (a few Gb) at first using the documentation below, but the system has been designed to cope with storing entire GWSs. You will need ssh login access to et.jasmin.ac.uk first. This should have been arranged for you as part of the GWS setup process. If not, please contact the JASMIN helpdesk. Once there, you should be able to see your group workspace and try out the commands on a small set of test data.
System overview &nbsp; Elastic Tape provides the ability to create &ldquo;batches&rdquo; of files which are then sent to the storage system, initially to an online disk cache before being written to near-line tape. Batches can later be retrieved, or removed. An alert system provides the user with the ability to monitor the progress of transfer jobs.
The system comprises:
A command-line interface on a client machine A backend system, consisting of I/O servers connected to an online disk cache and database A near-line tape system Configuration file &nbsp; As a GWS manager, you will normally be responsible for one or more GWSs. The GWS with which you wish to work using ET needs to be specified either in a configuration file in your home directory, or by specifying the workspace as an option in the command line interface.
Certain default settings are set in a system-wide config file at /etc/et_config.
If needed, you need to create a small text file in your home directory named .et_config, which contains the following, replacing &ldquo;myworkspace&rdquo; with the name of your default workspace:
[Batch] Workspace = myworkspacemyworkspace should just be the short name of the workspace, not the full path to it.
The workspace specified in any command-line option overrides that specified in the user&rsquo;s (~/.et_config) config file, which in turn overrides that specified in the system (/etc/et_config) config file.
Please REMOVE any previous reference to host and port from your individual ~/.et_config file. This setting is now set from the system /etc/et_config file.
Further configuration options are available in the [DIRECTORY] section of the file, see the system-wide file /etc/et_config for examples. The main parameter for which you may wish to override the default is:
outputLevel = workspace|batch|filealthough these can be over-ridden at the command line anyway. See et_ls.py command documentation below for the meaning of these options.
User interface &nbsp; Please note that NOT ALL features of the currently-implemented user interface are described here, however we would recommend that users limit their usage to those features described below.
The user interface consists of the following components:
et_put.py Put data onto tape et_get.py Retrieve data from tape et_rm.py Remove data from tape et_ls.py List data holdings on tape Alerts Get information about processes and holdings via web interface The commands are available on host et.jasmin.ac.uk. As a GWS manager you should have been granted login access to this machine using your JASMIN account, however if accessing the host from outside the RAL network you will need to use the login gateways login1.jasmin.ac.uk, login2.jasmin.ac.uk, login3.jasmin.ac.uk or login4.jasmin.ac.uk. Use the -A option or equivalent for agent forwarding in ssh. STFC users may use the STFC VPN to connect to et.jasmin.ac.uk as if it were a local connection.
&nbsp; When writing data to the ET system, it is very important that data remains in place on disk, in the location where ET expects to find them, until the status of the batch in question has reached CACHED_SYNCED or SYNCED. This means that the data have actually been written to tape, but is not the case until that status is shown.
The location where ET expects to find the files will be specified in the LISTFILE that the user supplied to the et_put.py command, or all files and directories under the DIR. The status of user&rsquo;s batches can be checked by going to the webpage: http://et-monitor.fds.rl.ac.uk/et_user/ET_AlertWatch.php. You need to be logged into JASMIN to see this webpage, via the nx-login servers, and use Firefox as the web browser.
Deleting the data from disk prematurely can cause problems for the ET system as a whole (impacting other users) so please be careful with this aspect.
et_put.py &nbsp; Put data onto tape.
Synopsis &nbsp; et_put.py [-v] [-l LOGFILE] [-w WORKSPACE] [-c] [-t one-word-tag] [ -f LISTFILE | DIR ] Description &nbsp; Data files to be stored can be specified either in an input list file (-f) or by specifying the path to the top of a directory tree containing files to be stored. All symbolic links are ignored (see note below). In both cases, the system will analyse the request and create a batch , identified by a BATCH ID, which can later be used to retrieve that set of files from storage. Although the main &ldquo;put&rdquo; operation is asynchronous (and does not require you to maintain a terminal connection for its duration), the initial registration step, which creates the BATCH ID is synchronous, so you should wait for this step to complete before disconnecting.
Given current resources, all users of Elastic Tape share the current throughput capacity of about 25 TB/day, which may increase over time. Please consider this when organising your input batches and expectations of completion time. Large numbers of small files will degrade performance.
Options &nbsp; option details -v Verbose output -l LOGFILE Log file in which to record process output -f LISTFILE Text file containing ABSOLUTE paths of files to be stored, 1 file per line. NB Files and directory names are case-sensitive. The list should not contain any blank lines or extraneous white space. -w WORKSPACE Name of the group workspace to use. Overrides default set in config file. Case sensitive. DIR ABSOLUTE path to top of directory tree containing files to be stored -c Continue if errors encountered. -t tag Tag batch with descriptive label meaningful to user. Should be single one-word string. Appears as &ldquo;Batch name&rdquo; in ET alert output and &ldquo;Tag&rdquo; in et_ls output. Example usage &nbsp; Simple case, using a file input.list which contains paths of all the files to be included in the batch:
et_put.py -v -l et_put.log -f input.list -w myworkspace In the following example, the -coption is used to continue on errors. One error that may be encountered is that a file already exists in the system (e.g. has already been &ldquo;put&rdquo;). This option causes the system to ignore any errors and continue with the transfer. Note that this should not be used by default (we would rather know about errors and fix them!)
et_put.py -v -l et_put.log -f input.list -w myworkspace -c Alternative usage specifying a directory beneath which all files / directories will be included. In this case the directory must be the last parameter in the command:
et_put.py -v -l et_put.log -w myworkspace /group_workspaces/jasmin/myworkspace/mydir Symbolic links: Attempting to include symbolic links in an et_put operation should cause an error. You can override this with the -c option (although this will ignore ALL errors), but a better solution is to generate a list file as in the first two examples above. If this list file is generated with a command like find &lt;path&gt; -type f &gt; listfile.txt, then referring to it in the et_put command will ensure that only those files are included in the batch. You can then keep the list file (perhaps named as per the resulting batch ID for your own records.
et_get.py &nbsp; Retrieve data from tape
Synopsis &nbsp; et_get.py [-v] [-l LOGFILE] [-b BATCHID | -f FILELIST] [-w WORKSPACE] [-r DIR] [-t MAXPROC] Description &nbsp; Data files to be retrieved should be specified by referring to the batch ID of the batch in which they were stored. If files have been stored by specifying an absolute path e.g. /group_workspaces/jasmin/myworkspace/mydir, the retrieval process will not write the retrieved files to the same location but a new location specified by DIR. The final part of the relative path needs to correspond with the first part of the absolute path of the stored files, e.g. group_workspaces
Proposed best-practice is to create a temporary directory for retrieved data within your workspace, e.g. /group_workspaces/jasmin/myworkspace/ettmp and to do the initial retrieval into that directory. Once you are satisfied that the retrieval has completed correctly, data can be moved back to their original location in the workspace. NB if you need additional storage space for this, please contact the CEDA help desk.
Options &nbsp; option details -v Verbose output -l LOGFILE Log file in which to record process output. Note that the log file location must be capable of accepting multi-threaded input, or this parameter should be omitted and instead the output from the et_get command be piped to the log file from stdout -b BATCHID ID of batch to be retrieved -f FILELIST A list of individual files to be retrieved, with one file per line. Note that:
- entries in the list must contain the full name of the file, including path, just as it was archived
- the list should not contain blank lines or any extraneous white space. -w WORKSPACE name of the group workspace to use. Overrides default set in config file. Case sensitive. -r DIR ABSOLUTE path of retrieval location -t MAXPROC Maximum number of worker processes to use in retrieval. MAXPROC recommended to be between 5 and 10. Please feed back your experience of performance improvement with this feature. Example usage &nbsp; cd /group_workspaces/jasmin/myworkspace mkdir ettmp et_get.py -v -l et_get.log -w myworkspace -b 507 -r /group_workspaces/jasmin/myworkspace/ettmp At this point, data will be transferred into the specified retrieval directory. Files and directories will be restored with their ABSOLUTE path below the retrieval directory. NB this is a synchronous process and you will need to keep your terminal window open to ensure it completes (or run within the screen command if you are familiar with this).
When the retrieval process has finished, you should satisfy yourself that it is correct (using your preferred method). When this is the case, you can move the data to the required location as shown below:
mv /group_workspaces/jasmin/myworkspace/ettmp/group_workspaces/jasmin/myworkspace/* /group_workspaces/jasmin/myworkspace et_rm.py &nbsp; Remove data from tape
Synopsis &nbsp; et_rm.py [-v] -b BATCHID [-w WORKSPACE] Description &nbsp; Deletes the files in the specified batch from the Elastic Tape system.
Options &nbsp; option details -v Verbose output -b BATCHID ID of batch to be removed -w WORKSPACE name of the group workspace to use. Overrides default set in config file. Case sensitive. Example usage:
et_rm.py -v -b 507 et_ls.py &nbsp; List holdings on tape
Synopsis &nbsp; et_ls.py [-h] [-X XMLSOURCE] [-H] [-b BATCHID] [-w WORKSPACE] [-L file,batch,workspace] [-F text] Description &nbsp; Lists the holdings of a workspace within Elastic Tape at the file, batch or workspace level.
Options &nbsp; option details -h, &ndash;help show this help message and exit -x XMLSOURCE &ndash;xmlsource XMLSOURCE Base XML source, if not default. Note that this has to be compatible with the current base source currently, so can’t be pointed at files, for example -H &ndash;headerWanted Print headers showing column names for text output -b BATCHID &ndash;batchid BATCHID ID of batch by which to filter results -w WORKSPACE Name of the group workspace to use. Overrides default set in config file. Case sensitive. -L file, batch, workspace &ndash;outputLevel file, batch, workspace Level of detail to display for results (default is &ldquo;workspace&rdquo;) -F text &ndash;outputFormat text Format to use for the display of results Example usage:
et_ls.py -w myworkspace -H -L file -b 504 Works with the workspace &ldquo;myworkspace&rdquo;, selects display of headers in output, results at file level, filter by batchid 504 (i.e. shows the files present in ET in the given batch.)
et_ls.py -w myworkspace -H -L batch Works with the workspace &ldquo;myworkspace&rdquo;, selects display of headers in output, results at batch level (i.e. shows the batches present in ET holdings for this workspace.)
Alerts &nbsp; The system provides real-time status messages on the progress of operations requested. These services are now available only inside the RAL firewall , so JASMIN users outside of RAL should use the NX graphical desktop service to open a firefox browser on one of the nx-login servers, to access these URLs
Alerts Dashboard http://et-monitor.fds.rl.ac.uk/et_user/ET_AlertWatch.php
RSS Feed http://et-monitor.fds.rl.ac.uk/et_rss/ET_RSS_AlertWatch_atom.php
In both cases these can be customised to display only alerts from the workspace of interest to the GWS manager.
Alerts Dashboard http://et-monitor.fds.rl.ac.uk/et_user/ET_AlertWatch.php?workspace=WORKSPACE
RSS Feed http://et-monitor.fds.rl.ac.uk/et_rss/ET_RSS_AlertWatch_atom.php?workspace=WORKSPACE
(replace WORKSPACE with your workspace name in the above URLs)
Further views
ET Home http://et-monitor.fds.rl.ac.uk/et_user/ET_Home.php?caller=USERNAME
Holdings summaryhttp://et-monitor.fds.rl.ac.uk/et_user/ET_Holdings_Summary.php?caller=USERNAME&amp;workspace=WORKSPACE
(replace USERNAME with your username, WORKSPACE with your workspace name in the above URLs)`}).add({id:179,tag:"en",href:"/tags/service/",title:"Service",description:"",content:""}).add({id:180,tag:"en",href:"/docs/mass/setting-up-your-jasmin-account-for-access-to-mass/",title:"Setting up your JASMIN account for access to MASS",description:"Setting up your JASMIN account for access to MASS",content:`The following notes are written assuming you are using a Linux machine in your home institution, that you have applied for a new MASS account, and that you have received an email from the Met Office Storage Team with your new MASS credentials file attached.
Load your SSH key &nbsp; Start an ssh-agent on your home institution machine, load your private key, and enter your passphrase when requested.
eval $(ssh-agent -s) ssh-add ~/.ssh/id_rsa_jasmin Enter passphrase for ~/.ssh/id_rsa_jasmin: Note: it&rsquo;s a good idea to keep your private keys for different systems separated, so you may want to keep your private key for JASMIN in a separate file, just move the one created during the process described above to a new sensible location such as ~/.ssh/jasmin_id_rsa.
Test login to the JASMIN login node &nbsp; Note: that the -A in the first ssh command is mandatory to enable access to the client VM, the -X enables X11 forwarding and is optional.
ssh -A -X &lt;userid&gt;@login1.jasmin.ac.uk 3. Test login to the MASS client host &nbsp; From the login machine, you can then login to the MASS client host.
Note: If you are prompted for a password at this stage, then you have either not requested additional access to the dedicated client machine, or access hasn&rsquo;t been approved yet, email the Met Office Service Manager monsoon@metoffice.gov.uk, to verify that approval has been granted. Allow a couple of days for this process to happen after submitting your request for access to the VM.
ssh -X &lt;userid&gt;@mass-cli.jasmin.ac.uk echo &#34;Hello World&#34; Hello World exit exit # back on your local machine Install your MOOSE credentials file &nbsp; You can scp the file via a JASMIN transfer server, make sure the credentials file is called moose, and you must run the moo install command on mass- cli.jasmin.ac.uk to set it up for you.
&nbsp; The external moose client has improved security settings, so you must use the moo install command to put your moose credentials file in the correct place in order to get remote access to work. This can only be done on the client machine mass-cli.jasmin.ac.uk. The credentials file is also changed by the running of moo install, so this process can be run only once. scp moose &lt;userid&gt;@xfer1.jasmin.ac.uk:~/moose ssh -A -X &lt;userid&gt;@login1.jasmin.ac.uk ssh -X &lt;userid&gt;@mass-cli.jasmin.ac.uk ls -l ~/moose -rwx------ 1 &lt;userid&gt; users 511 Jul 3 13:45 /home/users/&lt;userid&gt;/moose moo install ### passwd, command-id=148593088 Your password is due to expire in -1 day(s). A new password can be generated using &#39;moo passwd -r&#39;. ls -l ~/.moosedir/moose -rw------- 1 &lt;userid&gt; users 511 Jul 3 13:45 /home/users/&lt;userid&gt;/.moosedir/moose Having run these commands on the client machine, the moose file will have disappeared from your home directory, but a .moosedir directory will have been created, this will contain a new moose file, an install.log file, and once you start making MOOSE queries, a moose-external-client.log will be created.
Test use of the locally installed MOOSE client &nbsp; which moo /opt/moose/external-client-version-wrapper/bin/moo moo si &lt;system information appears here&gt; moo help &lt;help details appear here&gt; moo projlist &lt;list of projects appears here&gt; You have now successfully accessed MASS from JASMIN!
If you are new to MOOSE, you might like to read the User Guide next.`}).add({id:181,tag:"en",href:"/tags/shared/",title:"Shared",description:"",content:""}).add({id:182,tag:"en",href:"/docs/short-term-project-storage/share-gws-data-on-jasmin/",title:"Sharing GWS data on JASMIN",description:"Sharing GWS data with other users elsewhere on JASMIN",content:`Introduction &nbsp; This article explains how a GWS Manager can organise for some directories within a GWS to be shared with other users on JASMIN.
Note: this only applies to sharing data within the managed environment of the JASMIN platform. If you need to share data with users outside JASMIN, or to users of external cloud tenancies, please consider the HTTP option.
How to share specific directories &nbsp; Sometimes it is useful to share the contents of specific directories within your GWS with other users on JASMIN (that do not have access to your GWS). This can be achieved with the following approach:
Suppose you manage the GWS /group_workspaces/jasmin/superproj and you want to share the directory /group_workspaces/jasmin/superproj/mydata with other JASMIN users.
1. Add read and execute permission for all to the top-level GWS directory. This requires root access so you might need to request that CEDA make this change for you:
chmod 775 /group_workspaces/jasmin/superproj 2. Alter the permissions of all sub-directories to remove the execute permission for all users that don&rsquo;t have access to the GWS:
find /group_workspaces/jasmin/superproj -type d -exec chmod o-x  \\; 3. Add execute permission on the sub-directory you want to share:
chmod o+x /group_workspaces/jasmin/superproj/mydata NOTE: You may need to change permissions on directories and files within the sub-directory as well. Please consult the chmod man pages (by typing man chmod) for details.
NOTE: if you have a public directory then it needs 755 access if you want it to be visible via the webserver on the gws-access.jasmin.ac.uk server. So you may wish to re-add execute permission on that directory, e.g.:
chmod o+x /group_workspaces/jasmin/superproj/public &nbsp; Do not set open permissions on files or directories. By this we mean permissions where data are &ldquo;world-writable&rdquo; by anyone, for example
-rw-rw-rw- for a file, or &laquo; DON&rsquo;T USE THESE!!
drwxrwxrwx for a directory. &laquo; DON&rsquo;T USE THESE!!
We provide a UNIX a group corresponding to each group workspace, usually named gws_&lt;name&gt; which all members of that GWS belong to: this enables sharing within the group if you set permissions appropriately using that group. If you are unsure about setting permissions, please ask the helpdesk.`}).add({id:183,tag:"en",href:"/docs/short-term-project-storage/share-gws-data-via-http/",title:"Sharing GWS data via HTTP",description:"Sharing GWS data via HTTP",content:`What is HTTP data sharing? &nbsp; Specific parts of JASMIN Group Workspaces (GWSs) can be made available via HTTP, so that:
data can be shared with users who do not have JASMIN accounts common clients such as wget, curl, client libraries and web browsers can be used to access the data via a commonly-supported protocol. In this respect, the service should be regarded as another data transfer tool. However it must be arranged in advance between the Group Workspace manager and the JASMIN Helpdesk. It involves:
A member of the workspace creating a public directory and placing data inside it The GWS manager making a request to the JASMIN Helpdesk to request that this specific GWS is configured to be shared via HTTP. Both these steps need to be completed in order for the GWS to be visible via HTTP. By default, GWSs are not visible by HTTP.
Once a GWS has been made available, it is publicly visible by the entire internet: please bear that in mind.
The following sections below describe how to set up restricted and unrestricted access to your &ldquo;public&rdquo; directory. If you require access control then see the section on password-protected access below. [Note: this is currently possible, though not recommended, only because the current webserver configuration permits this (now deprecated) means of restricting access. Future revisions of the service may remove or change the way access restrictions can be imposed].
&nbsp; This facility is not to be used for hosting project websites. It is provided as a simple means for specific data files to be made available to a wider audience than members of a Group Workspace, using a convenient data transfer protocol (HTTP). Likewise, it is not recommended to build tools or front-end applications relying on this service as a dependency if they are to be operated as a production or (near-)real-time service. The JASMIN team reserves the right to apply rate-limiting (by project and/or IP address) or to remove GWSs from the service if they are considered to be causing problems for the network or other parts of the service infrastructure.
Projects considering web-based solutions for showcasing or disseminating their data via more complex tools or with specific availability requirements should consider requesting an external tenancy in the JASMIN Community Cloud, or indeed external service providers if more appropriate, but should be prepared to do the necessary design, development, operation and maintenance of those services themselves.
Public access set up &nbsp; In some cases the GWS manager may want to make some files and directories available over HTTP so that users (perhaps a wider audience than just the membership of the GWS) can access the data via a web browser or other HTTP- based tools. This can be done by creating a public directory in the top- level directory of the GWS, for example:
cd /group_workspace/jasmin/foobaa/ mkdir public chmod -Rf 755 public You should then contact JASMIN Support and ask for this directory to be made visible via the gws-access server. The JASMIN team will configure this change and your public directory will then be visible from:
https://gws-access.jasmin.ac.uk/public/foobaa/
&nbsp; The URL of this service changed in June 2020. A redirect is in place from the old URL of https://gws-access.ceda.ac.uk/, so the change should be transparent to existing users, but please use the new URLs beginning with https://gws-access.jasmin.ac.uk/ to avoid any problems for example with HTTP clients that are unable to handle redirects. Please see the section below if you wish to control who can access the content of one or more of the sub-directories within your public directory.
Restricted access set up &nbsp; In order to restrict access to your &ldquo;public&rdquo; directory, and/or any sub- directories, you will need to create an &ldquo;.htaccess&rdquo; file within it. In turn, the &ldquo;.htaccess&rdquo; file must point to a &ldquo;.htpasswd&rdquo; file which lists the usernames and encrypted passwords that have read-access to that directory.
&nbsp; This method of access control is entirely independent of the SSH login accounts used on JASMIN and would be the responsibility of the GWS Manager to maintain. It is not secure by modern standards and not particularly recommended as it adds complication for GWS managers and users, but is an option for some basic access control if no other options are available.
Future revisions of the service may revise or remove this feature.
In order to create the &ldquo;.htpasswd&rdquo; file, you will need access to the &ldquo;htpasswd&rdquo; command. This is available on the transfer servers xfer[12].jasmin.ac.uk
You can then create the &ldquo;.htpasswd&rdquo; file as follows (using the example of a Group Workspace called &ldquo;foobaa&rdquo;):
export GWS=/group_workspaces/jasmin/foobaa/ cd $GWS mkdir -p public cd public htpasswd -b -m -c $GWS/public/.htpasswd i_am_a_user i_am_a_password Before this will work, you also need to create a &ldquo;.htaccess&rdquo; file which you could do as follows
cat &gt;.htaccess &lt;&lt;EOL AuthType Basic AuthName &#34;Password Required&#34; AuthUserFile /group_workspaces/jasmin/foobaa/public/.htpasswd Require valid-user EOL Finally, change the permissions on these files:
chmod 644 .htaccess .htpasswd Now, you can test that you get prompted for the username and password by visiting
https://gws-access.jasmin.ac.uk/public/foobaa/`}).add({id:184,tag:"en",href:"/docs/software-on-jasmin/share-software-envs/",title:"Sharing software environments",description:"Sharing software environments",content:`This article explains how you can share software environments with other users on JASMIN.
What is a software environment? &nbsp; A software environment is typically a collection of files and directories associated with a set of environment variables that allows a given session to access them. In the context of JASMIN, there are a number of Python/other environments already available on the system. See the Jaspy page for examples of these.
Creating software environments on JASMIN &nbsp; In some cases, JASMIN users will need to create their own software environments because the existing environments do not include all the packages that they require. See the virtual environments page for details on creating your own Python environments.
Tips on sharing software environments on JASMIN &nbsp; If you need to create your own environment it is important to be aware of which file system you are working on:
SOF (e.g. /gws/nopw/j04/*): does not perform well with small files. SSD (e.g. $HOME and /gws/smf/j04/*): performs much better with small files, but is expensive so only limited quotas are available. If you are building an environment for your use only then it makes sense to create it under your $HOME directory.
If you need to share an environment with other JASMIN users you can:
Request a &ldquo;small files&rdquo; (smf) Group Workspace volume. Install the software environment within the &ldquo;small files&rdquo; volume. Then all users with access to that GWS will be able to access the environment.`}).add({id:185,tag:"en",href:"/docs/short-term-project-storage/",title:"Short term project storage",description:"How to use short-term storage resources provided for your project",content:""}).add({id:186,tag:"en",href:"/tags/sinfo/",title:"Sinfo",description:"",content:""}).add({id:187,tag:"en",href:"/tags/slurm/",title:"Slurm",description:"",content:""}).add({id:188,tag:"en",href:"/docs/batch-computing/slurm-queues/",title:"Slurm queues",description:"Slurm queues",content:`This article introduces the Slurm scheduler queues/partitions for batch job submissions to the LOTUS and ORCHID clusters.
Queue names &nbsp; The Slurm queues in the LOTUS cluster are:
test short-serial long-serial par-single par-multi high-mem short-serial-4hr Each queue is has attributes of run-length limits (e.g. short, long) and resources. A full breakdown of each queue and its associated resources is shown below in Table 1.
Queue details &nbsp; Queues represent a set of pending jobs, lined up in a defined order, and waiting for their opportunity to use resources. The queue is specified in the job script file using Slurm scheduler directive like this:
#SBATCH -p &lt;partition=queue_name&gt;\`where &lt;queue_name&gt; is the name of the queue/partition (Table 1. column 1)
Table 1 summarises important specifications for each queue such as run time limits and the number of CPU core limits. If the queue is not specified, Slurm will schedule the job to the queue short-serial by default.
Table 1. LOTUS/Slurm queues and their specifications
Queue name Max run time Default run time Max CPU cores per job MaxCpuPerUserLimit Priority test 4 hrs 1hr 8 8 30 short-serial 24 hrs 1hr 1 2000 30 par-single 48 hrs 1hr 16 300 25 par-multi 48 hrs 1hr 256 300 20 long-serial 168 hrs 1hr 1 300 10 high-mem 48 hrs 1hr 1 75 30 short-serial-4hr
(Note 3) 4 hrs 1hr 1 1000 30 Note 1 : Resources requested by a job must be within the resource allocation limits of the selected queue.
Note 2: The default value for --time=[hh:mm:ss] (predicted maximum wall time) is 1 hour for the all queues. If you do not specify this option and/or your job exceeds the default maximum run time limit then it will be terminated by the Slurm scheduler.
Note 3 : A user must specify the Slurm job account --account=short4hr when submitting a batch job to the short-serial-4hr queue.
State of queues &nbsp; The Slurm command sinfo reports the state of queues and nodes managed by Slurm. It has a wide variety of filtering, sorting, and formatting options.
sinfo PARTITION AVAIL TIMELIMIT NODES STATE NODELIST test up 4:00:00 48 idle host[146-193] short-serial* up 1-00:00:00 48 idle host[146-193] long-serial up 7-00:00:00 48 idle host[146-193] par-single up 2-00:00:00 48 idle host[146-193] par-multi up 2-00:00:00 48 idle host[146-193] high-mem up 2-00:00:00 48 idle host[146-193] lotus_gpu up 7-00:00:00 48 idle host[146-193] copy up 7-00:00:00 48 idle host[146-193] cpom-comet up 7-00:00:00 48 idle host[146-193] ... &nbsp; Queues other than the standard queues test , short-serial , long-serial, par-single, par-multi and high-mem should be ignored as they implement different job scheduling and control policies. &lsquo;sinfo&rsquo; Output field description: &nbsp; By default, the Slurm command &lsquo;sinfo&rsquo; displays the following information:
PARTITION : Partition name followed by * for the default queue/partition AVAIL : State/availability of a queue/partition. Partition state: up or down. TIMELIMIT : The maximum run time limit per job in each queue/partition is shown in TIMELIMIT in days- hours:minutes :seconds . e.g. 2-00:00:00 is two days maximum runtime limit NODES : Count of nodes with this particular configuration e.g. 48 nodes STATE : State of the nodes. Possible states include: allocated, down, drained, and idle. For example, the state &ldquo;idle&rdquo; means that the node is not allocated to any jobs and is available for use. NODELIST List of node names associated with this queue/partition The sinfo example below, reports more complete information about the partition/queue short-serial
sinfo --long --partition=short-serial Tue May 12 18:04:54 2020 PARTITION AVAIL TIMELIMIT JOB_SIZE ROOT OVERSUBS GROUPS NODES STATE NODELIST short-serial* up 1-00:00:00 1-infinite no NO all 48 idle host[146-193] How to choose a Slurm queue/partition &nbsp; Test queue &nbsp; The test queue can be used to test new workflows and also to help new users to familiarise themselves with the Slurm batch system. Both serial and parallel code can be tested on the testqueue. The maximum runtime is 4 hrs and the maximum number of jobs per user is 8 job slots. The maximum number of cores for a parallel job e.g. MPI, OpenMP, or multi-threads is limited to 8 cores. The testqueue should be used when unsure of the job resource requirements and behavior at runtime because it has a confined set of LOTUS nodes (Intel node type) not shared with the other standard LOTUS queues.
Serial queues &nbsp; Serial and array jobs with a single CPU core should be submitted to one of the following serial queues depending on the job duration and the memory requirement. The default queue is short-serial
short-serial &nbsp; Serial and/or array jobs with a single CPU core each and run time less than 24 hrs should be submitted to the short-serial queue . This queue has the highest priority of 30. The maximum number of jobs that can be scheduled to start running from the short-serial is 2000 jobs whilst both job&rsquo;s resources are available and user&rsquo; priority is high
long-serial &nbsp; Serial or array jobs with a single CPU core and run time greater than 24 hrs and less than 168 hrs (7 days) should be submitted to the queue long-serial . This queue has the lowest priority of 10 and hence jobs might take longer to be scheduled to run relatively to other jobs in higher priority queues.
high-mem &nbsp; Serial or array jobs with a single CPU core and high memory requirement (&gt; 64 GB) should be submitted to the high-mem queue and the required memory must be specified --mem=XXX (XXX is in MB units). The job should not exceed the maximum run time limit of 48hrs. This queue is not configured to accept exclusive jobs.
Parallel queues &nbsp; Jobs requiring more than one CPU core should be submitted to one of the following parallel queues depending on the type of parallelisms such as shared memory or distributed memory jobs.
par-single &nbsp; Shared memory multi-threaded jobs with a maximum of 16 threads should be submitted to the par-single queue . Each thread should be allocated one CPU core. Oversubscribing the number of threads to the CPU cores will cause the job to run very slow. The number of CPU cores should be specified via the submission command line sbatch -n &lt;number of CPU cores&gt; or by adding the Slurm directive #SBATCH -n &lt;number of CPU cores&gt;in the job script file. An example is shown below:
sbatch --ntasks=4 --partition=par-single &lt; myjobscript Note: Jobs submitted with a number of CPU cores greater than 16 will be terminated (killed) by the Slurm scheduler with the following statement in the job output file:
par-multi &nbsp; Distributed memory jobs with inter-node communication using the MPI library should be submitted to the par-multi queue . A single MPI process (rank) should be allocated a single CPU core. The number of CPU cores should be specified via the Slurm submission command flag sbatch -n &lt;number of CPU cores&gt; or by adding the Slurm directive #SBATCH -n &lt;number of CPU cores&gt; to the job script file. An example is shown below:
sbatch --ntasks=4 --partition=par-multi &lt; myjobscript Note 1: The number of CPU cores gets passed from Slurm submission flag -n . Do not add the -np flag to mpirun command .
Note 2: Slurm will reject a job that requires a number of CPU cores greater than the limit of 256.`}).add({id:189,tag:"en",href:"/docs/batch-computing/lsf-to-slurm-quick-reference/",title:"Slurm quick reference",description:"Slurm quick reference",content:`This article shows the Slurm commands and their equivalent to the LSF scheduler (LSF was replaced by Slurm in September 2020): this webinar gave details of the transition.
The Slurm Scheduler &nbsp; Slurm is the job scheduler deployed on JASMIN. It allows users to submit, monitor, and control jobs on the LOTUS (cpu) and ORCHID (gpu) clusters.
Essential LSF/Slurm commands &nbsp; LSF Slurm Description bsub &lt; script_file sbatch script_file Submit a job script to the scheduler bqueues sinfo Show available scheduling queues bjobs squeue -u &lt;username&gt; List user&rsquo;s pending and running jobs bsub -n 1 -q test -Is /bin/bash srun -n 1 -p test &ndash;pty /bin/bash Request an interactive session on LOTUS Job specification &nbsp; LSF Slurm Description #BSUB #SBATCH Scheduler directive -q queue_name --partition=queue_name or -p queue_name Specify the scheduling queue -W hh:mm:ss --time=hh:mm:ss or -t hh:mm:ss Set the maximum runtime limit -We hh:mm:ss --time-min=hh:mm:ss Set an estimated runtime -J job_name --job-name=jobname Specify a name for the job -o filename, -e filename --output=filename or -o filename, --error=filename or -e filename. The default file name is &ldquo;slurm-%j.out&rdquo;, where &ldquo;%j&quot;is replaced by the job ID Standard job output and error output. Default append. -oo/-eo filename For job arrays , the default file name is &ldquo;slurm-%A_%a.out&rdquo;, &ldquo;%A&rdquo; is replaced by the job ID and &ldquo;%a&rdquo; with the array index. ﻿ --open-mode=append|truncate Write mode for error/output files . %J %j Job ID for -oo/eo filename %I %a Job array index -R &ldquo;rusage[mem= XXX ]&rdquo; --mem=XXX Memory XXX is required for the job. Default units are megabytes -J job_name [index_list] --array= index (e.g. &ndash;array=1-10) specify a job array -J job_name [index_list]% number-of-simultaneous-jobs --array=index% ArrayTaskThrottle e.g. --array =1-15%4 will limit the number of simultaneously running tasks from this job array to 4 A maximum number of simultaneously running tasks from the job array may be specified using a &ldquo;%&rdquo; separator. -cwd directory -D, &ndash;chdir= Set the working directory of the batch script to &lt; directory &gt; before it is executed. -x --exclusive Exclusive execution mode -w &lsquo;dependency_expression&rsquo; --dependency= &lt;dependency_list&gt; Defer the start of this job until the specified dependencies have been satisfied completed -n number-of-cores --ntasks=number-of-cores or -n number-of-cores Number of CPU cores -m --constraint=&rdquo;&lt; host-group-name&gt;&quot; To select a node with a specific processor model Job control commands &nbsp; LSF Slurm Description bkill &lt;jobid&gt; scancel &lt;jobid&gt; Kill a job bjobs -l &lt;jobid&gt; scontrol show job &lt;jobid&gt; Show details job information bmod &lt;jobid&gt; scontrol update job &lt;jobid&gt; Modify a pending job bkill 0 scancel &ndash;user=&lt;username&gt; Kill all jobs owned by a user Job environment variables &nbsp; LSF Slurm Description $LSB_JOBID $SLURM_JOBID Job identifier number $LSB_JOBID $SLURM_ARRAY_JOB_ID Job Array $LSB_JOBINDEX $SLURM_ARRAY_TASK_ID Job array index $LSB_JOBINDEX_END $SLURM_ARRAY_TASK_MAX Last index number within a job array $LSB_MAX_NUM_PROCESSORS $SLURM_NTASKS Number of processors allocated`}).add({id:190,tag:"en",href:"/docs/batch-computing/slurm-scheduler-overview/",title:"Slurm scheduler overview",description:"Overview of the LOTUS batch scheduler, Slurm",content:`What is a Job Scheduler? &nbsp; A job or batch scheduler, is a tool that manages how user jobs are queued and run on a set of compute resources. In the case of LOTUS the compute resources are the set of compute nodes that make up the LOTUS hardware. Each user can submit jobs to the scheduler which then decides which jobs to run and where to execute them. The scheduler manages the jobs to ensure that the compute resources are being used efficiently and that users get appropriate access to those resources.
The Slurm Scheduler &nbsp; Slurm is the job scheduler deployed on JASMIN. It allows users to submit, monitor, and control jobs on the LOTUS cluster.
General principles for working with Slurm &nbsp; Before learning how to use Slurm, it is worthwhile becoming familiar with the basic principles of scheduler operation in order to get the best use out of the LOTUS cluster. Scheduler software exists simply because the amount of jobs that users wish to run on a cluster at any given time is usually greatly in excess of the amount of resources available. This means that the scheduler must queue jobs and work out how to run them efficiently.
Several factors are taken into account during scheduling, such as job duration and size, but the basic principles remain the same throughout - every user gets a fair share of the cluster based on the jobs that they have submitted. This leads to a small number of important principles:
Do not try to second guess the scheduler! Submit all of your jobs when you want to run them and let the scheduler figure it out for you. You will get a fair share, and if you don&rsquo;t then we need to adjust the scheduler (so get in touch and let us know). Give the scheduler as much information as possible. There are a number of optional parameters (see &ldquo;How to submit jobs&rdquo;) such as job duration, and if you put these in then you have an even better chance of getting your jobs to run. It is very difficult for one user to monopolise the cluster, even if they submit thousands of jobs. The scheduler will still aim to give everyone else a fair share, so long as there are other jobs waiting to be run. Fair share for all users &nbsp; Example of scheduling In the example above, three users (left column) have jobs in the queue (middle column) which are waiting to run on the cluster (right column). As the blue user&rsquo;s job finishes (middle row), all three users could potentially use the two job slots that become available. However, the orange and purple users already have jobs running, whereas the blue user does not, and as such it is the blue user&rsquo;s jobs that are run (bottom row).
LOTUS queues &nbsp; There are five standard Slurm queues (also known as &ldquo;partitions&rdquo; in Slurm terminology) for batch job submissions to the LOTUS cluster: short-serial, long-serial, par-single, par-multi and high-mem. The default queue is short-serial. For testing new workflows, the additional queue testis recommended. The specification of each queue is described in detail in this article: Slurm queues on LOTUS
Queues other than the five standard queues with the test queue should be ignored unless you have been specifically instructed to use them.
The typical workflow for LOTUS jobs &nbsp; One of the great advantages of using JASMIN is the ability to create batch jobs that run simultaneously on multiple LOTUS nodes. However, users familiar with running interactively on a single machine often take time to adapt to this new way of working. The change involves moving from a &ldquo;watching your job run&rdquo; approach to &ldquo;submitting your job and coming back later&rdquo;.
The typical workflow for setting up and running LOTUS jobs is as follows:
Login to one of the scientific analysis servers. Install/write/configure your processing code. Test your code interactively: run it locally in a single-process test case. Create a wrapper script for your code that allows multiple versions to run independently: e.g. running for different dates or processing different spatial regions/variables. Submit your jobs via the batch script. Monitor your jobs. Gather/analyse/review the outputs as required. Project-specific LOTUS queues &nbsp; Occasionally a project has a specific requirement for a collection of compute nodes that involve the provision of a project-specific queue. If you are working on such a project your project lead will provide guidance on which queue to use. Please contact the helpdesk if you are interested in setting up a project-specific queue.`}).add({id:191,tag:"en",href:"/docs/batch-computing/slurm-status/",title:"Slurm status",description:"LOTUS/ORCHID Slurm scheduler status",content:`The JASMIN dashboard includes an overview of: LOTUS queues/partitions status, including the number of running/completed/pending jobs and further information about the usage of the LOTUS and ORCHID clusters.
lotus status Figure 1. LOTUS dashboard`}).add({id:192,tag:"en",href:"/tags/small-files/",title:"Small Files",description:"",content:""}).add({id:193,tag:"en",href:"/tags/software/",title:"Software",description:"",content:""}).add({id:194,tag:"en",href:"/docs/software-on-jasmin/",title:"Software on JASMIN",description:"Information about what software is available and how to use it",content:""}).add({id:195,tag:"en",href:"/docs/software-on-jasmin/software-overview/",title:"Software Overview",description:"Overview of software on JASMIN",content:`JASMIN is a large platform where a range of software tools, packages and environments are available. Many users employ software already installed on JASMIN whilst some need to install their own tools for a particular purpose.
This page provides an overview of the software on JASMIN. It links to further information about a range of tools and environments.
To help get you started, these have been split into categories:
Software available to all on JASMIN analysis/batch servers Additional tools for compiling and building software Restricted software Server-specific software Data movement software Which software should I use? &nbsp; There are a lot of different options when you are trying to work out which tools and/or environments to use on JASMIN. Here are some quick questions to help you get started:
1. Do you want to use NAME, JULES, MOOSE or the NAG libraries?
If yes, see: Restricted software 2. Do you want a workflow management tool or a graphical Linux desktop?
If yes, see: Server-specific software 3. Do you want tools for transferring data or migrating it to/from tape?
If yes, see: Data movement software 4. If you need anything else:
See: Software available to all on JASMIN analysis/batch servers Software available on all sci/batch nodes &nbsp; Data analysis and visualisation tools &nbsp; If you are looking for software packages and environments that allow you to analyse, process and visualise data then take a look at these options:
Jaspy software environments (Python, R and other tools) The &ldquo;jasmin-sci&rdquo; software environment (packages not provided by Jaspy) Additional packages (provided under: &ldquo;/apps/jasmin&rdquo;) IDL (and MIDL) Creating your own software environments NOTE : If you are using Matplotlib to visualise data please refer to the advice on our Matplotlib help page.
Jaspy Software Environments (Python, R and other tools) &nbsp; Jaspy is a toolkit for managing and deploying Conda environments that include both Python and non-Python packages. Jaspy environments, along with the &ldquo;jasmin-sci&rdquo; environment (see below), provide the main software on the scientific analysis servers and LOTUS cluster on JASMIN. Details of the Jaspy environments and packages are available on the Jaspy page.
The &ldquo;jasmin-sci&rdquo; Software Environment &nbsp; The &ldquo;jasmin-sci&rdquo; software environment is intended as a supplement to Jaspy (see above). It contains extra software packages for use with scientific data analysis which, for various reasons, are not provided as part of Jaspy itself. Details of this environment are provided on the &ldquo;jasmin-sci&rdquo; software page.
Additional packages &nbsp; A number of additional packages are available under the &ldquo;/apps/jasmin/&rdquo; directory scientific analysis servers and LOTUS cluster. Details of these packages are provided on the additional sofware packages page.
IDL &nbsp; IDL stands for Interactive Data Language. It is a licensed data manipulation toolkit made available on JASMIN. IDL is available on the JASMIN scientific analysis servers and LOTUS cluster. See IDL .
Creating your own software environments &nbsp; If you intend to create your own software environments then please take a look at the following pages:
Building virtual environments on top of Jaspy environments Sharing your JASMIN software environments with other users Compilers on JASMIN Restricted software available on specific servers &nbsp; Workflow Management with Rose and Cylc &nbsp; Rose and Cylc provide a suite of tools available for managing sophisticated multi-step workflows. See full details on the Rose and Cylc page.
Graphical Linux desktop access using NoMachine NX &nbsp; NoMachine NX is a tool that allows users to run a virtual graphical Linux desktop on JASMIN. See details on the NX page.
Data movement software &nbsp; Data transfer &nbsp; There are numerous tools for transferring data to/from JASMIN. Please consult the Data Transfer Tools page for details.
Data migration disk/tape &nbsp; The Joint Data Migration App, or JDMA, is a flexible tool for managing large migrations of data between a range of storage media. On JASMIN, it can be used for migrating data to/from tape, disk and object-store. See more details on the JDMA page.
Still have a question? &nbsp; Please consult the JASMIN software FAQs.`}).add({id:196,tag:"en",href:"/tags/ssh/",title:"Ssh",description:"",content:""}).add({id:197,tag:"en",href:"/docs/getting-started/ssh-auth/",title:"SSH public key authentication",description:"SSH public key authentication",content:`JASMIN employs SSH public key authentication for login instead of username and password. This article provides a basic overview of public key authentication.
Public key authentication (for SSH) &nbsp; SSH stands for &ldquo;Secure Shell&rdquo;, a protocol that allows login to another computer over the network. This allows the user to execute commands on a remote machine. SSH uses encryption to keep the connection secure so that it is more difficult for hackers to passwords or other sensitive information that may pass through the connection.
Public key authentication is an alternative means of identifying yourself to a login server, instead of typing a password. It is more secure and flexible, but can appear more difficult for new users.
Why is public key authentication more secure than a password? &nbsp; When using conventional username/password authentication you will type your password when you log on to a server. If the server you are working on has been compromised then an attacker could learn your password and then use it to gain access to the remote server you are connecting to.
With public key authentication, the private key is kept only on your own machine and the passphrase to unlock it is entered there too. An attacker would require both knowledge of the passphrase used to protect your private key as well as the private key file itself.
&nbsp; It is imperative that your private key is protected by a strong passphrase so that only you can use it. Public key authentication setup &nbsp; Setting up SSH keys involves the following steps:
Create a pair of SSH keys (public and private with associated passphrase ). Provide the public key to remote machines/services that you wish to login to. See instructions for setting this up on JASMIN.
Login with your SSH key pair &nbsp; Once you have set up your key pair and provided your public key to the remote machine the process is as follows:
Load the private key into an &ldquo;authentication agent&rdquo; (such as ssh-agent) on your local machine. Use an SSH client (such as the ssh command) to login to the remote server. See instructions for setting this up on JASMIN.
Logging in from multiple machines &nbsp; If you have a requirement to login to your JASMIN account from multiple servers/locations then please copy your private key file securely to the ~/.ssh directory on the new machine. Note that you should restrict access the private key so it is only readable by you.
Using public key authentication with other applications &nbsp; Many other tools use the SSH protocol for their communication with remote servers or services, for example rsync, scp, git and subversion.`}).add({id:198,tag:"en",href:"/tags/sync/",title:"Sync",description:"",content:""}).add({id:199,tag:"en",href:"/tags/system/",title:"System",description:"",content:""}).add({id:200,tag:"en",href:"/docs/for-cloud-tenants/sysadmin-guidance-external-cloud/",title:"System administration guidance (external cloud)",description:"System administration guidance (external cloud)",content:`Managing storage &nbsp; When provisioned, a virtual machine gets allocated a small hard disk (the exact size of the disk depends on the selected machine size). This disk is intended to run the operating system only. If you require additional storage for data, it is possible to add extra volumes to a virtual machine.
First, create a new volume by navigating to the volumes tab and clicking on &ldquo;New Volume&rdquo;:
create volume dialogue This will launch a dialog that allows you to specify a name and size for the volume:
specify name and size for volume Once the volume becomes available, you can attach it to a VM. First, click on the &ldquo;Actions&rdquo; button and select &ldquo;Attach volume to machine&rdquo;:
menu options This will open a dialog allowing you to select the VM that you want to attach the volume to:
attach volume to VM Once the volume has attached to the VM, the new disk will be visible to the machine but will not be usable. This can be verified using the lsblk command:
lsblk NAME MAJ:MIN RM SIZE RO TYPE MOUNTPOINT sda 8:0 0 4G 0 disk └─sda1 8:1 0 4G 0 part / sdb 8:16 0 50G 0 disk Here, we can see that the operating system is recognising the new disk - sdb - but there are no partitions or file systems associated with it. To make the disk usable, it must be formatted with a filesystem and mounted somewhere, e.g. /data:
# Create a single partition spanning the whole disk fdisk /dev/sdb Device contains neither a valid DOS partition table, nor Sun, SGI or OSF disklabel Building a new DOS disklabel with disk identifier 0x598d636f. Changes will remain in memory only, until you decide to write them. After that, of course, the previous content won&#39;t be recoverable. Warning: invalid flag 0x0000 of partition table 4 will be corrected by w(rite) Command (m for help): n Partition type: p primary (0 primary, 0 extended, 4 free) e extended Select (default p): Using default response p Partition number (1-4, default 1): Using default value 1 First sector (2048-33554431, default 2048): Using default value 2048 Last sector, +sectors or +sizeK,M,G (2048-33554431, default 33554431): Using default value 33554431 Command (m for help): w The partition table has been altered! Calling ioctl() to re-read partition table. Syncing disks. # Verify that the partition was created lsblk /dev/sdb NAME MAJ:MIN RM SIZE RO TYPE MOUNTPOINT sdb 8:16 0 16G 0 disk └─sdb1 8:17 0 16G 0 part # Create a filesystem on the partition mkfs.ext4 /dev/sdb1 mke2fs 1.42.9 (4-Feb-2014) Filesystem label= OS type: Linux Block size=4096 (log=2) Fragment size=4096 (log=2) Stride=0 blocks, Stripe width=0 blocks 1048576 inodes, 4194048 blocks 209702 blocks (5.00%) reserved for the super user First data block=0 Maximum filesystem blocks=4294967296 128 block groups 32768 blocks per group, 32768 fragments per group 8192 inodes per group Superblock backups stored on blocks: 32768, 98304, 163840, 229376, 294912, 819200, 884736, 1605632, 2654208, 4096000 Allocating group tables: done Writing inode tables: done Creating journal (32768 blocks): done Writing superblocks and filesystem accounting information: done # Mount the filesystem mkdir /data mount /dev/sdb1 /data # Verify that the filesystem is now available lsblk NAME MAJ:MIN RM SIZE RO TYPE MOUNTPOINT sda 8:0 0 4G 0 disk └─sda1 8:1 0 4G 0 part / sdb 8:16 0 50G 0 disk └─sdb1 8:17 0 50G 0 part /data df -h Filesystem Size Used Avail Use% Mounted on /dev/sda1 4.0G 1.4G 2.7G 34% / devtmpfs 222M 0 222M 0% /dev tmpfs 245M 0 245M 0% /dev/shm tmpfs 245M 8.8M 236M 4% /run tmpfs 245M 0 245M 0% /sys/fs/cgroup tmpfs 49M 0 49M 0% /run/user/0 /dev/sdb1 50G 53M 47G 1% /data # Add a line to /etc/fstab to make the mount persistent (i.e. automatic mount on boot) echo &#34;/dev/sdb1 /data ext4 defaults 0 0&#34; &gt;&gt; /etc/fstab`}).add({id:201,tag:"en",href:"/tags/",title:"Tags",description:"",content:""}).add({id:202,tag:"en",href:"/tags/tape/",title:"Tape",description:"",content:""}).add({id:203,tag:"en",href:"/tags/tenancy/",title:"Tenancy",description:"",content:""}).add({id:204,tag:"en",href:"/docs/interactive-computing/tenancy-sci-analysis-vms/",title:"Tenancy Sci Analysis VMs",description:"Tenancy-Sci Analysis VMs",content:`This document explains how to access a tenancy-based sci machine. These are normally provisioned by an admin/manager representing a particular community/institution.
Check which institutions/group you belong to:
NCAS, NCEO, UKMO, RSG, &hellip;
The admin/manager will provide you the name of the tenancy. You can then search for it on your JASMIN accounts portal under the JASMIN service named Sci Analysis VMs.
How to request access &nbsp; Step 1: Find the Sci Analysis VMs under the Menu &lsquo;Discover services&rsquo; at https://accounts.jasmin.ac.uk/services/
Step 2: Check the name of the service and the description that your supervisor or PI recommended you to choose and click &ldquo;More information&rdquo;
Locate the correct service Click +Apply Step 3: Apply for USER role and provide details on your project and a reference then click &ldquo;Apply&rdquo;
Apply for USER role Step 4: Notification
Status PENDING Once your request was approved, you will get a notification
Notification Status updated to ACTIVE If your request was rejected, then reapply and provide further supporting information
Rejected: further info requested Click on the rejection notification. This will take you to the following page where you can &ldquo;Apply again&rdquo;
Request for further detail How to login &nbsp; The machine will not be accessible directly externally, so you need to access it via a JASMIN login machine: don&rsquo;t forget the -A (agent forwarding) option on your initial connection.
ssh -A user@login2.jasmin.ac.uk Access the VM using the IP address (not the hostname) of the virtual machine. Your manager should be able to provide you with this, since they created (provisioned) the virtual machine.
ssh -A user@&lt;IP-ADDRESS-OF-VM&gt; How to report issues &nbsp; Users should report issues to the ADMIN and/or MANAGER/DEPUTY of the tenancy based SCI VM initially, rather than the JASMIN team. If the issue cannot be resolved by the ADMIN and/or MANAGER, they should contact the JASMIN helpdesk. You can find the name of the current holders of the MANAGER/DEPUTY roles by going to the page which described the service on the accounts portal, as above.`}).add({id:205,tag:"en",href:"/docs/software-on-jasmin/jasmin-sci-software-environment/",title:'The "jasmin-sci" software environment',description:'The "jasmin-sci" software environment',content:`Introduction &nbsp; This article describes the jasmin-sci software environment on JASMIN. It covers the following topics:
Overview of the jasmin-sci software environment Activating and deactivating the jasmin-sci environment Using the jasmin-sci environment with Jaspy Overview of the &ldquo;jasmin-sci&rdquo; software environment &nbsp; The jasmin-sci software environment is intended as a supplement to Jaspy and contains extra software packages for use with scientific data analysis which, for various reasons, are not provided as part of Jaspy itself. These packages are generally installed on the same machines where Jaspy is available, for example, the sci machines (e.g. sci1.jasmin.ac.uk) and LOTUS nodes, but not the login machines. It is not intended for the jasmin-sci environment itself to provide a complete suite of analysis software.
The packages included in jasmin-sci are provided via RPMs. A list of explicitly included packages can be seen using the command rpm -qR jasmin-sci, although some additional packages may be installed to satisfy dependencies.
The packages fall into two categories:
Packages provided by standard RPM repositories (example &ldquo;gnuplot&rdquo;) - these are installed into ordinary system paths (such as /usr/bin/gnuplot for the gnuplot program) and require no special setup in order to run. So if you are on a relevant machine, you should just be able to type gnuplot. Packages which we have built locally for use on JASMIN (although most are third-party software). To avoid any potential later conflicts with standard packages, they are installed under the path /opt/rh/jasmin-sci/ rather than in system paths. Also, the RPM package names, as can be seen in the above rpm -qR jasmin-sci command, are prefixed with jasmin-sci-. So for example, the local build of nccmp (a program to compare netCDF files) is a package called jasmin-sci-nccmp, and the executable is at /opt/rh/jasmin-sci/root/usr/bin/nccmp. Before these packages can be conveniently used, it is necessary to &ldquo;activate&rdquo; the environment as described below, so that when you type e.g. &ldquo;nccmp&rdquo; the relevant files can be found. Unlike the Jaspy environments, jasmin-sci can only provide one version of each package at a time, so the versions are subject to change when updates are done. If we anticipate any important changes, then we will notify JASMIN users by email.
In a few cases, software packages are provided in jasmin-sci which are also provided in Jaspy. This is only done where other RPM packages depend on it. For example, the netcdf package is provided in Jaspy, but is also installed as an RPM because the nccmp package requires it. This means that copies of the netCDF libraries exist both in Jaspy (for the full path, type nc-config --libs after activating Jaspy) and also under /usr/lib64 (from the RPM). When linking code to the netCDF library, it is recommended to use the one in Jaspy because this will be version controlled. Also, although the jasmin-sci software might provide some software that happens to be implemented in Python, any such Python modules are not intended to be imported into your own code. For Python development, packages from Jaspy should be used.
The development for jasmin-sci takes place via the extra-sci-packages GitHub repository, and an associated issues page. The readme file on the repository has some package- specific documentation (including how to build the python bindings for Misr toolkit).
Activating and deactivating the &ldquo;jasmin-sci&rdquo; environment &nbsp; To activate the jasmin-sci environment, use the command:
module load jasmin-sci and to deactivate it, use the command:
module unload jasmin-sci (&ldquo;add&rdquo; and &ldquo;purge&rdquo; can also be used).
The module load command must be done in each session, or added to your $HOME/.bashrc file.
As mentioned above, this is only required for a subset of packages in jasmin- sci. The majority of packages do not require it, but for example, those which do include ferret, and the leafpad (notepad-like) editor.
Ferret users should note that it is still necessary to do &ldquo;source ferret_paths.sh&rdquo; after activating jasmin-sci, in order for ferret to find all its additional resource files.
Using the &ldquo;jasmin-sci&rdquo; environment with Jaspy &nbsp; To activate both jasmin-sci and Jaspy, it is best to activate them in the following order:
module load jasmin-sci module load jaspy This will ensure that in the unlikely event of an executable in Jaspy also existing under /opt/rh/jasmin-sci/, then one in Jaspy will take priority.
The corresponding module unload commands can be done in either order.`}).add({id:206,tag:"en",href:"/docs/getting-started/tips-for-new-users/",title:"tips-for-new-users",description:"Tips for new users",content:`These tips for new users are based on users&rsquo; queries encountered by our helpdesk. They are not exhaustive but may help solve some initial problems and set out best practice.
Sci machines LOTUS Xfer servers How to report an issue &ldquo;Sci&rdquo; machines usage guidelines &nbsp; Check the current load and number of users on the sci machines, as shown by the login servers, to select a less-used sci machine. The available Sci machines and their specifications are listed in the table of this help page The sci machines are not for running large, long-running tasks, or scripts that spawn multiple child processes. The batch processing cluster LOTUS is available for heavier processing. The sci machines are for development, testing, and light interactive use. Overloading these with processing seriously impairs performance for interactive use by others. Do not write to the temporary partition /tmpon sci machines. Use your home directory, a scratch volume or a Group Workspace . Any temporary data files can reside in a subdirectory of your group workspace instead of /tmp. To do this, please add the following lines (or similar) to your $HOME/.bashrc file: export TMPDIR=/group_workspaces/jasmin/&lt;your_project&gt;/&lt;your_username&gt;/tmp ## create the directory if needed [ -d $TMPDIR ] || mkdir -p $TMPDIR If a process hangs, do not simply close the terminal window. Please contact the helpdesk and alert the team so that the process can be shut down. Otherwise hung processes build up and contribute to machine overloading. Do not “hog” IDL development licenses. A limited number of these are available for development and compilation of IDL code which should then be run on LOTUS using IDL runtime licenses, of which there are many more. Do not use sci machines for data transfer: xfer hosts are provided for this purpose. LOTUS usage guidelines &nbsp; Do not use IDL development licences on LOTUS. There are many runtime licenses available, but the development licenses are for interactive use on the sci machines, where IDL code can be compiled, then run on LOTUS using a runtime license. Beware of inadvertently filling up /tmp on LOTUS nodes. This can take nodes out of action (perhaps for other users who still have jobs running on the same node) if /tmp fills up. Design your code to clean up as it goes along, and use environment variables to control where your applications write temporary data, ideally to storage which is not specific to a LOTUS node. If your job crashes, check which nodes were involved and clean up after yourself. Do not store data in scratch areas for long periods of time. Move data away to group workspaces once your processing has finished. Xfer servers guidelines &nbsp; Do not run a large number (&gt;16) of rsync or scp transfer processes in parallel. Do not run processing on xfer servers: they are provided for data transfer only For heavy/high-performance data transfers, avoid virtual machines jasmin-xfer1/cems-xfer1 and consider using high-performance servers or methods. How to report an issue &nbsp; When you do experience an issue, please;
Make it clear whether you are simply advising the helpdesk of a general issue (which will be noted, but not necessarily investigated for a specific response), or Provide FULL and SPECIFIC details of your problem so that it can be investigated. JASMIN is a complex infrastructure with many hundreds of hosts and storage volumes, so reporting that “JASMIN” or “Storage” is slow, is not sufficient. If you are experiencing difficulties accessing a particular storage volume from a particular sci machine, please state: the full path to the data you are trying to access: the full hostname of the machine (but please try the same access from at least one other machine to help establish whether it’s related to the machine or the storage) the date and time of the issue (for matching up with system reports/log files. Using the date and time of the email is not sufficient: please be specific in your report) Be patient and understand that, particularly at present (where nearly the entire CEDA and JASMIN teams are working remotely), queries will take longer to resolve. Some issues will only be resolved by strategic improvements which are planned as part of phased upgrades to JASMIN accompanied by capital procurements followed by integration work, all carried out by the same, small team.`}).add({id:207,tag:"en",href:"/tags/training/",title:"Training",description:"",content:""}).add({id:208,tag:"en",href:"/training/",title:"Training",description:"",content:""}).add({id:209,tag:"en",href:"/training/basic/training-exercises-coming-soon/",title:"Training exercises coming soon",description:"Exercises to help you get the most out of JASMIN",content:`Watch this space &nbsp; We&rsquo;ll be adding more content soon, as we reorganise the JASMIN help content further.
For now, please see JASMIN Training Workshop materials&nbsp; .`}).add({id:210,tag:"en",href:"/training/intermediate/training-exercises-coming-soon/",title:"Training exercises coming soon",description:"Exercises to help you get the most out of JASMIN",content:`Watch this space &nbsp; We&rsquo;ll be adding more content soon, as we reorganise the JASMIN help content further.
For now, please see JASMIN Training Workshop materials&nbsp; .`}).add({id:211,tag:"en",href:"/tags/transfer/",title:"Transfer",description:"",content:""}).add({id:212,tag:"en",href:"/docs/short-term-project-storage/xfc/",title:"Transfer Cache (XFC)",description:"Transfer Cache (XFC)",content:`What is the XFC? &nbsp; The Transfer Cache (XFC) provides a large area of temporary storage for users of JASMIN to store large files and/or a large volume of files on a short-term basis.
Users are granted a quota of space in their user area on the temporary storage. When users exceed their quota some of their files will be deleted automatically.
Users interact with the XFC in two ways:
to initialise their user area, and to get information about their quota, a command-line client is used. to move data in and out of their user area, the standard UNIX command-line tools (cp, mkdir, rm, mv, rsync, etc.) are used. Quotas &nbsp; XFC has two different types of quota. The first is the &ldquo;hard quota&rdquo; (HQ). This is the absolute maximum volume of data that can be stored in the user area. This is expressed in TB (terabytes).
The second type of quota is the &ldquo;temporal quota&rdquo; (TQ). This is expressed in units of TB day (terabyte days), and has a time component as well as a data volume component. For an individual file, the TQ for that file is the product of the size of the file and the number of days the file has been in the user area. As an example, if the user moves a 2TB file into their area, after 24 hours it will have used 2TB days of the TQ. After 48 hours it will have used 4TB days and after 1 week it will have used 14TB days.
Finally, any file in the XFC can have a maximum persistence of 365 days. i.e. if a file is in XFC for more than one year then it will be deleted by the automatic deletion.
The above figure shows an example of the quota system in use. The red line shows the temporal quota used (TQ) and the blue line shows the hard quota (HQ).
The user initialises their XFC. On day 5 , the user copies a 1 TB file into their XFC For the next 4 weeks (on days 12 , 19 , 26 and 31 ) the user copies in another 1 TB file The TQ steadily grows until on day 79 it has reached it&rsquo;s limit of 300TB days, the first 1TB file is deleted On day 98 another 1TB file is deleted On day 120 , the user copies 10TB into their XFC On days 122 , 130 and 140 the 1TB files that were copied in on days 19 , 26 and 31 are deleted. On day 151 , the 10TB file is deleted. Default Quota values: &nbsp; The default Hard Quota (HQ) is 10 TB
The default Time Quota (TQ) is 300 TB
So you could store 10TB of data for 30 days before risking the deletion of data.
Additionally, an overall time limit of 365 days is set for ALL data stored by a given user. You cannot store any data, no matter how small, for longer than 365 days.
Automatic deletion &nbsp; If users exceed either their temporal quota or hard quota, then files in their user area will be deleted automatically. The deletion process will delete as many files as necessary to bring the amount of HQ and TQ below the quotas allocated to the user. Files will be deleted on an age basis. Those files that were copied into the user area first will be deleted first, with newer files deleted after these.
The user can be notified which files will be deleted if they switch the option to be notified on and supply an email address in the XFC client. Files will be deleted 24 hours after the notification.
If a file is modified between the notification and the scheduled deletion (24 hours later) then the file will not be deleted. However, the automatic deletion is relentless and it will choose some other file to delete instead. XFC is not designed as permanent storage and the automatic deletion process has been designed to discourage long term storage of files on it.
Using XFC &nbsp; JASMIN provides access to XFC via a command-line client: xfc
Once installed into your $HOME directory (using one of the sci servers), the xfc client can be run on either the sci (sci[1-8].jasmin.ac.uk) or xfer (xfer[12].jasmin.ac.uk) servers, but should NOT be run on the high-performance transfer servers hpxfer[12].jasmin.ac.uk.
The client is used only for interacting with the service, but is not needed for accessing the storage it provides. The storage provided is mounted in most places across JASMIN: the path to your XFC volume is returned by the client in one of the steps shown below.
Users are expected to use the xfer servers or a high-performance data transfer service to do any data transfers either within or in/out of JASMIN. This reduces the load on the sci servers which are for general-purpose interactive computing.
The xfc client is used to initialise and then query the status (quota, scheduled deletions etc) of a user&rsquo;s XFC storage volume:
To see all the available options: xfc -h To initialise your user area: xfc init xfc init ** SUCCESS ** - user initiliazed with: username: username email: user.name@stfc.ac.uk quota: 300TB path: /work/xfc/vol1/user_cache/username The path is the path on the JASMIN system to the user area. Data can be copied here using standard UNIX command-line tools cp, mv, rsync. Subdirectories can be created using mkdir. Change read/write permissions on the directories and files using chmod, etc. The user area is just a standard POSIX directory and so any POSIX commands can be used on it.
To get the user area path again: xfc path /work/xfc/vol1/user_cache/username To set the user email for notifications: xfc email --email=user.name@stfc.ac.uk ** SUCCESS ** - user email updated to: user.name@stfc.ac.uk To query the email set for the user: xfc email xfc email user.name@stfc.ac.uk To switch deletion notifications on / off: xfc notify ** SUCCESS ** - user notifcations updated to: on To see remaining quota: xfc quota ------------------------ Quota for user: username ------------------------ Temporal Quota (TQ) Used : 1.7 TB Allocated : 300.0 TB Remaining : 298.3 TB ------------------------ Hard Quota (HQ) Used : 444.9 GB Allocated : 40.0 TB Remaining : 39.6 TB To see which files are scheduled for deletion: xfc schedule No files scheduled for deletion To list the files in your user area: xfc list user_cache/username/historical/.ftpaccess user_cache/username/historical/00README_catalogue_and_licence.txt user_cache/username/historical/day/atmos/day/r1i1p1/COPY_CURRENT_20150326.txt Pattern matching can be used to search for a file. This is just a simple substring search, e.g. r1i1p1_19500101-19541231.nc
xfc list -m r1i1p1_19500101-19541231.nc user_cache/username/historical/day/atmos/day/r1i1p1/v20120907/va/va_day_CMCC-CESM_historical_r1i1p1_19500101-19541231.nc user_cache/username/historical/day/atmos/day/r1i1p1/v20120907/rsds/rsds_day_CMCC-CESM_historical_r1i1p1_19500101-19541231.nc user_cache/username/historical/day/atmos/day/r1i1p1/v20120907/prc/prc_day_CMCC-CESM_historical_r1i1p1_19500101-19541231.nc File names are given relative to the user_cache/ directory. To list the full file path use the -f list option:
xfc list -f To predict when the files will be deleted, if no other files are added to the user area, and none of the current files are removed: xfc predict xfc predict Quota is predicted to be exceeded on 21 Aug 2019 14:58 by 252.1 GB Files predicted to be deleted user_cache/username/historical/.ftpaccess user_cache/username/historical/00README_catalogue_and_licence.txt user_cache/username/historical/day/atmos/day/r1i1p1/COPY_CURRENT_20150326.txt Example of initial use &nbsp; Below is a list of commands the user might use in their initial session with XFC.
initial setup &nbsp; xfc init xfc path xfc email --email=user.name@email.com xfc notify query the quota &nbsp; xfc quota xfc predict xfc schedule`}).add({id:213,tag:"en",href:"/docs/interactive-computing/transfer-servers/",title:"Transfer servers",description:"Transfer servers",content:`This article lists the JASMIN data transfer servers and provides links to how they can be used.
JASMIN provides specific servers for managing data transfers. These are:
Server Purpose Access requirements Further information xfer1.jasmin.ac.uk Virtual machine for general purpose data transfers. jasmin-login Visible on optical network connections from k9.leeds.ac.uk and some Met Office hosts. xfer2.jasmin.ac.uk Virtual machine for general purpose data transfers. jasmin-login xfer3.jasmin.ac.uk As per xfer[12], but with config like login2for enabling access from IP addresses without fwd/rev DNS lookup. jasmin-login AND xfer-sp Apply for additional access role access here. See below for further specifics. hpxfer1.jasmin.ac.uk Physical machine for high-performance data transfers. jasmin-login AND hpxfer IP address of client Tuned for UK &amp; European network paths. Apply for additional access role accesshere hpxfer2.jasmin.ac.uk Physical machine for high-performance data transfers. jasmin-login AND hpxfer. IP address of client Tuned for long (intercontinental) network paths (e.g. UK - Australia). Apply for additional access role access here gridftp1.jasmin.ac.uk Physical machine for high-performance GridFTP transfers. jasmin-login AND hpxfer IP address of client No SSH login access. Apply for additional access role access here Acts as Globus Online endpoint &quot; JASMIN GridFTP Server&quot; Please see further articles in the Data Transfer category for details on managing your data transfers.
The standard transfer servers provide a basic and functional service for moving small amounts of data over relatively short distances. However, the high-performance data transfer servers shown above are also available for those with particular requirements. Users with login accounts can apply for access to use the high-performance servers.
&nbsp; Please make sure you use the dedicated transfer servers and not the scientific analysis or login servers for any significant data transfers. The transfer servers have been configured to achieve the best transfer rates and will perform significantly better than other servers on jasmin, while maintaining the performance of analysis servers for interactive use by other users. Special transfer machine xfer3.jasmin.ac.uk &nbsp; This machine has been set up to cater for those whose network configuration does not enable them to connect to xfer1 and xfer2 (for example because of a lack of fwd/rev DNS lookup). A different set of access rules apply, which enables users to access this machine but a side effect of these additional rules is that repeated attempts to access the machine via SSH-based processes can result in being &ldquo;locked out&rdquo;. This may happen when attempting the transfer of several small files in quick succession with separate SSH connections for each. The &ldquo;xfer-sp&rdquo; access group is therefore a way of ensuring that the users accessing this machine know to be aware of this issue and can have their access to this machine denied if found to be causing a problem for the machine&rsquo;s operation for other users.
&nbsp; Users are not permitted to execute commands which require administrative privileges. This applies to all hosts in the managed part of JASMIN where users have SSH login access (for example login, nx-login, sci, xfer and hpxfer machines). In other words, the use ofsu or sudo is not permitted. Please be careful when typing commands, particularly if you have multiple terminal windows open on your own computer, that you do not accidentally attempt sudoon a JASMIN machine: expect some follow-up from the JASMIN team if you do!`}).add({id:214,tag:"en",href:"/docs/data-transfer/transfers-from-archer2/",title:"Transfers from ARCHER2",description:"Transfers from ARCHER2",content:`This article explains how to transfer data between ARCHER2 and JASMIN. It covers:
The choice of available tools / routes Example of how to use the currently-recommended method Choice of available Tools/Routes &nbsp; See Data Transfer Tools for general details.
Users transferring data between ARCHER2 and JASMIN are often transferring relatively large sets of data, so it is important to choose the most appropriate route, method and tools to ensure you get the most efficient and reliable transfer experience. This can vary depending on system and network conditions.
If you want to try all the options available, you will need:
hpxfer (high-performance data transfer) access role on JASMIN, in addition to the jasmin-login role. a login account at ARCHER2 (only for certificate-based GridFTP) to have registered the subject of your JASMIN-issued short-term credential with ARCHER2 support. Check the examples in the linked documentation articles and ensure that you use them between the hosts used in the examples. Not all services connect over all routes to/from all hosts!
NOTE:
Enquiries about access to or use of ARCHER2 should be directed to ARCHER2 support (support@archer2.ac.uk) Enquiries about access to or use of JASMIN should be directed to JASMIN support (use beacon, below-right or support@jasmin.ac.uk) Available transfer methods &nbsp; Basic SSH transfer &nbsp; scp/rsync/sftp: Simple transfers using easy method, pushing data to general purpose xfer nodes. Convenient, but limited performance.
source dest notes login.archer2.ac.uk xfer1.jasmin.ac.uk over 10G JANET, but to virtual machine at JASMIN end login.archer2.ac.uk xfer2.jasmin.ac.uk same GridFTP over SSH &nbsp; GridFTP over SSH: GridFTP performance with convenience of SSH. Requires persistent ssh agent on local machine where you have your JASMIN key. 2nd choice method
source dest notes login.archer2.ac.uk hpxfer1.jasmin.ac.uk over 10G JANET login.archer2.ac.uk hpxfer2.jasmin.ac.uk over 10G JANET
hpxfer2 is configured for longer distances but can be useful if hpxfer1 is busy GridFTP using certificate auth &nbsp; GridFTP using certificate auth: Fully-featured GridFTP. Suitable for person-not-present transfers &amp; long- running ARCHER2 workflows. 1st choice method
source dest notes login.archer2.ac.uk gridftp1.jasmin.ac.uk over 10G JANET.
Dedicated GridFTP server.
No need for persistent SSH agent at ARCHER2 end 1st choice method: example &nbsp; The currently-recommended method for transfers between ARCHER2 and JASMIN is using globus-url-copy with the concurrency option, as described below, but using certificate-based authentication rather than SSH. This will work for person- not-present transfers, so is suitable for long-running processes on ARCHER2 which need to spawn a transfer to JASMIN at intervals up to a month from initiation.
1. Load your SSH key for ARCHER2 on your local machine, then log in to ARCHER2.
This method does not require you to use your JASMIN SSH key. It involves:
obtaining tools to communicate with JASMIN&rsquo;s short-lived credentials service using the service to obtain a credential (it should last for 30 days, but a new one can be obtained at any time) using the credential to initiate a transfer (this what you would need to repeat for each transfer) A fuller explanation of the process is given in this document:
Data Transfer Tools: GridFTP (certificate-based authentication) Once you have done these steps, you should be able to obtain a short-term credential as follows (do this command at the ARCHER2 end, after having downloaded the onlineca script as described in the document mentioned above):
./onlineca-get-cert-wget.sh -U https://slcs.jasmin.ac.uk/certificate/ -l USERNAME -o ./cred.jasmin chmod 600 cred.jasmin Note that the path ./ is used for the script onlineca-get-cert-wget.sh, but you should use the path to wherever you saved it. Alternatively, if you make yourself a bin directory and add that to your PATH, then you don&rsquo;t need to specify the path.
2. Load the gct module (to make the current globus-url-copy command available in your path on ARCHER2).
Once loaded, check with which to see that you have the globus-url-copy command available to you.
module load gct which globus-url-copy /work/y07/shared/gct/v6.2.20201212/bin/globus-url-copy 3. Transfer a single file to your home directory on JASMIN (limited space, but to check things work)
globus-url-copy -vb -cred cred.jasmin SRC/FILE gsiftp://gridftp1.jasmin.ac.uk/DEST/FILE Note that we specify the credentials file cred.jasmin and use the protocol gsiftp:// with no need to specify the username in the connection string (we&rsquo;ve used the path /~/ to signify &ldquo;my home directory&rdquo; as the destination path). Note also that the hostname in this case, gridftp1.jasmin.ac.uk is a host that you can ONLY connect to directly using gsiftp: it does not permit SSH connections.
In all other aspects, the transfer is the same as for the SSH method (see &ldquo;2nd choice method&rdquo; below), so the commands below are very similar: we&rsquo;re just using the gsiftp method instead of sshftp (both are ways of using the gridftp transfer protocol)
4. Recursively transfer a directory of files, using the concurrency option for multiple parallel transfers
globus-url-copy -vb -cd -r -cc 4 -cred cred.jasmin SRC/DATA/ gsiftp://gridftp1.jasmin.ac.uk/DEST/DATA/ NOTE: The -cc option initiates the parallel transfer of several files at a time, which achieves good overall transfer rates for recursive directory transfers. This is different from using the -p N -fast options which use parallel network streams to parallelism the transfer of each file.
The -p N -fast options (for parallel-streamed transfers) are not currently working to all JASMIN storage locations, so use at your own risk until further notice. The transfer should work OK out of ARCHER2 (check by writing a single file to /dev/null at the JASMIN end) but currently will not work properly when writing to the SOF storage (/gws/nopw/j04 or /gws/nopw/j07, or /work/xfc/vol[1-3], though other paths should work OK). This is a known issue at the JASMIN end, thought to be related to network configuration, which is still under investigation. Single-stream transfers (omitting the -p N -fast options) should work fine.
Here, the options used are (see man globus-url-copy for full details):
-vb | -verbose-perf During the transfer, display the number of bytes transferred and the transfer rate per second. Show urls being transferred -concurrency | -cc Number of concurrent ftp connections to use for multiple transfers. -cd | -create-dest Create destination directory if needed -r | -recurse Copy files in subdirectoriesExperiment with different concurrency options (4 is a good start, more than 16 would start to &ldquo;hog&rdquo; resources so please consider
5. Use the sync option to synchronise 2 directories between source and target file systems:
globus-url-copy -vb -cd -r -cc 4 -sync -cred cred.jasmin SRC/DATA/ gsiftp://gridftp1.jasmin.ac.uk/DEST/DATA/ where SRC/DATA/ and /DEST/DATA/ are source and destination paths, respectively (include trailing slash).
Options are as before but with:
-sync Only transfer files where the destination does not exist or differs from the source. -sync-level controls how to determine if files differNote that the default sync level is 2, see level descriptions below, which only compares time stamps. If you want to include a file integrity check using checksums, you need to use-sync-level 3 but there may be a performance cost.
-sync-level Choose criteria for determining if files differ when performing a sync transfer. Level 0 will only transfer if the destination does not exist. Level 1 will transfer if the size of the destination does not match the size of the source. Level 2 will transfer if the timestamp of the destination is older than the timestamp of the source, or the sizes do not match. Level 3 will perform a checksum of the source and destination and transfer if the checksums do not match, or the sizes do not match. The default sync level is 2.So a full sync including comparison of checksums would be:
globus-url-copy -vb -cd -r -cc 4 -sync -sync-level 3 -cred cred.jasmin src/data/ gsiftp://gridftp1.jasmin.ac.uk/path/dest/data/ 2nd choice method: example &nbsp; The next-best method for transfers between ARCHER2 and JASMIN is using globus- url-copy with SSH authentication, as described below:
1. Load your SSH keys for both JASMIN and ARCHER2 on your local machine, then log in to ARCHER2.
You will need to have loaded into your SSH agent:
The SSH key associated with your JASMIN account The SSH key associated with your ARCHER2 account, if you have one (it is recommended to use a different one than for JASMIN, if so) You also need to ensure that you connect with the -A option for agent forwarding, to enable the JASMIN key to be available for the onward authentication with the JASMIN server.
Note that you do not (and should not) copy your JASMIN private key to ARCHER2. It should stay on your local machine. This does mean that you need an ssh- agent running on your local machine, so this method may not work for long- running continuous processes that need to spawn transfers.
ssh-add &lt;jasmin ssh key&gt; (path to your JASMIN ssh key file on your local machine) ssh-add &lt;archer2 ssh key&gt; (path to your ARCHER2 ssh key if you have one, on on your local machine) ssh-add -l check both keys are loaded (are both key signatures listed in the output?) ssh -A &lt;archer2-username&gt;@login.archer2.ac.uk #(ARCHER2 now uses multi-factor auth at this stage) 2. Load the gct module (to make the current globus-url-copy command available in the path)
module load gct which globus-url-copy /work/y07/shared/gct/v6.2.20201212/bin/globus-url-copy 3. Transfer a single file to your home directory on JASMIN (limited space, but to check things work)
globus-url-copy -vb &lt;file&gt; sshftp://&lt;jasmin-username&gt;@hpxfer1.jasmin.ac.uk/~/&lt;file&gt; Obviously, replace &lt;file&gt; with the path to the file you want to transfer.
From here on, the commands are the same as described above in the &ldquo;1st choice method&rdquo; but simply replace
-cred cred.jasmin gsiftp://gridftp1.jasmin.ac.ukwith
sshftp://&lt;jasmin-username&gt;@hpxfer1.jasmin.ac.uk`}).add({id:215,tag:"en",href:"/docs/uncategorized/",title:"Uncategorized",description:"Articles that we should probably recategorize...",content:""}).add({id:216,tag:"en",href:"/docs/getting-started/understanding-new-jasmin-storage/",title:"Understanding new JASMIN storage",description:"Understanding new JASMIN storage",content:`&nbsp; This article was originally written in 2018/19 to introdice new forms of storage which were brought into produciton at that stage. Some of the information and terminology is now out of date, pending further review of JASMIN documentation. Introduction &nbsp; JASMIN continues to grow as a unique collaborative analysis environment for an expanding community of scientists. Some of the big challenges we attempted to address with Phase 4 were the ever-growing demand for storage space and the increasing diversity of scientific workflows. However, we’re aware that some aspects of the changes introduced in Phase 4 have presented some challenges in themselves. Here, we outline the reasons for the changes and try to summarise some of the challenges and what can be done to help deal with them.
Background &nbsp; (skip this if you just want to go straight to the advice):
With phase 4 we knew we had to both replace existing storage that had become uneconomic to maintain, and add significantly more volume! However, we also knew that most of the data stored on JASMIN disk is not touched for months on end, but that some data is heavily used. We also knew that the traditional way of building disk systems was no longer suitable for the scales (volumes of data) we needed to handle, being supplanted by new technologies, and that at some point our community would have to get used to these new technologies too. The solution we chose for JASMIN is the same solution being deployed at most large HPC sites: deploying tiered storage, that is more types of storage, and requiring you, the user, to use the right kind of storage in the right place in your workflow!
Understanding the four types of JASMIN disk: &nbsp; We have settled on four kinds of disk storage - quite an increase from the one we had previously! Each is best for one kind of workflow, although each “can do” most things, although not always well. We will see below that there is one kind of activity that we now need to be much more careful about, because doing it not only causes problems for individuals, but also for everyone else. We could stop allowing this to happen, but it would be at a performance penalty which would occur all the time: we have gone for “better with occasional really slow” in preference to “always predictably slow” performance. What we need you to do is learn how to avoid creating the “occasionally really slow” times!
The four types are:
Solid state fast but not parallel disk (SSD), really suitable for small files. This is what is used for your /home/users directories, so is good for things you really don’t want to lose, because this area is backed up. The same type of storage is also used for the scratch area /work/scratch-nopw, although this is NOT for persistent storage and is NOT backed up. SSD is great for compiling and storing millions of small files, but is the most expensive storage, so we don’t have a lot of it. Fast parallel disk (PFS) , great for jobs that read and write the same file from many different processes. This is what we had before. It’s not so great for lots of small files. This is still pretty expensive, which is one of the reasons why we haven’t simply stayed with it. Some GWS still use this, but most are migrating to the next category - scale-out file storage. Scale Out File Storage (SOF). This is what most of our Group Workspaces (GWS) will use. This is great for large volumes of data with regular use (consider near-line tape storage if you don’t need access for a significant period). SOF is not so great for small files, so if you have lots of small files, best to either aggregate them or tar them up. This is terrible for parallel write access to files, and you must avoid that. More details on that below, but the key point is you might find you need to use the fast parallel scratch (currently /work/scratch) in your workflows as an intermediary between persisting your data and your Lotus batch jobs. High Performance Object Storage (HPOS). This is a new type of storage, and it’s best if you are working with the cloud. It’s going to be a bit tricky to get the hang of, so pay attention to the various things we’re going to be saying over the next few months about how to use it. It is the future though&hellip; What type of storage am I using? &nbsp; Storage Type Parallel-write Good for small files? Backed up? /home/users SSD no yes e.g. Installing Conda yes /gws/pw/j07/* PFS yes no no /gws/nopw/j04/* SOF no no no /gws/smf/j04/* SSD no yes yes /work/scratch-pw[23] PFS yes no no /work/scratch-nopw2 SSD no yes no /work/xfc/volX SOF no no no Automounted SOF storage: GWS storage volumes /gws/nopw/j04/* are automounted. This means that a particular GWS volume is not mounted by a particular host until the moment it is first accessed. If the volume you are expecting to see is not listed at the top level ( /gws/nopw/j04/) you should use the full path of the volume to access it, and after a very short delay, the volume should appear.
See also here to see where these are mounted throughout JASMIN.
The BIG issue: why you need to be careful about parallel file access &nbsp; (even if you don’t think you are doing it):
Traditional disk systems try and do cunning things when different processes are writing to the same file; they can lock the file so only one process can have a turn at a time, or they can try and stack up the updates and do them one after another (and hope they don’t interfere), but at scale, all those tricks come with a performance cost. That cost gets paid in many ways: raw I/O speed, how many extra copies of blocks get written, how long it takes to rebuild if things go wrong, how big any part of the storage can be… and, how much kit and software the vendors need to deliver to make it work. All that cost is worth it if your workflow needs it (and can’t avoid it), but in the JASMIN environment, not many workflows actually need it.
Our fast parallel disk is fine for those workflows, but none of the others support it well, and in particular for our scale-out file storage, as used by most GWSs, the way it works means that if we turn on the support for parallel write, it will become much slower and write many more copies of some data blocks, meaning it will do I/O slower, and it will store less! Not what we want. The parallel read is fine! However, avoiding parallel writes has turned out to be harder than we anticipated, your workflows have many more ways of doing it than we thought! Sadly, when you do parallel writes, the file system can get “stuck” and that’s when everything goes really slow, for everyone on that host …
One way around this is for us to apply “global write locking” to a GWS volume (your GWS manager would need to request this). This solves the problem by preventing parallel writes altogether, but at a significant cost in performance.
FAQs, issues and solutions &nbsp; Please read our collection of FAQs and known issues (and solutions!) which we&rsquo;ve put together HERE.`}).add({id:217,tag:"en",href:"/docs/getting-started/update-a-jasmin-account/",title:"Update a JASMIN account",description:"Update a JASMIN account",content:`This article shows you how to update an active JASMIN account on the JASMIN accounts portal.
Update info &nbsp; Step 1 : On your profile page&nbsp; , select &ldquo;Update info&rdquo;.
Update detils Step 2 : Once the discipline and degree are updated, click &ldquo;Update profile&rdquo;
Update details Step 3 : The updated details are displayed.
Updated profile Update SSH public key &nbsp; To update your SSH public key, first you need to generate a new SSH key pair as described here: Generate an SSH key pair. This should be done on your local machine (e.g. Windows / Linux / Mac). You MUST protect your key with a strong passphrase. Then follow step 1 to step 5 to update your SSH public key. You will be asked for a verification token during this process. The system will reject any key that it recognises has been used before (across all users) so you must generate a fresh key each time: you cannot recycle an old key.
Step 1 : On the profile page, select &ldquo;Update key&rdquo;
Update key Step 3 On the profile page shown above select &ldquo;Update key&rdquo;. Within a few seconds, you should receive a validation token to your registered email address.
Step 4: Enter the validation token, delete the old SSH public key , and paste the new SSH public key. Click &ldquo;Update SSH key&rdquo;.
Confirmation Step 5: Confirmation is displayed. Please allow 15 minutes before attempting to log in again, while the new key becomes active on the JASMIN system.
If you get the message &ldquo;not a valid ssh public key&rdquo; please check that you have copied the text from the .pub file and that no newline characters are included: the public key should be a single line of text. It can be difficult to see this as the text automatically wraps itself to fit in the text box.
Key updated Change password &nbsp; Step 1 : Go to your username in the top-right corner of the navigation bar. Select &ldquo;Change password&rdquo; from the drop-down menu.
Select change password from menu Step 2 : Enter the new password which must conform to the rules stated. You should ideally generate a strongly random string in an encrypted password manager and store it securely. Make sure it is NOT the same as your SSH key passphrase. Re-enter the new password to confirm, then click &ldquo;Change password&rdquo;
Submit new password Link CEDA account &nbsp; Linking your CEDA account to your JASMIN account allows you filesystem access to data on CEDA Archive. If you need to access data on the CEDA Archive and you do not have an account, you will need to apply for a CEDA account.
Step 1 : On the profile page, select &ldquo;Link now&rdquo; which is opposite to the field &ldquo;Linked CEDA Account&rdquo;. This will take you to the CEDA accounts portal page where you need to login.
Login to your CEDA account Step 2 : You will be directed to the page below to authorise JASMIN accounts portal to link your CEDA account and read CEDA profile information.
Allow access Step 3 : Your &ldquo;Linked CEDA Account&rdquo; field on your JASMIN account profile page will be updated with &ldquo;Linked with &lt;JASMIN username&gt;&rdquo; as shown below
Updated JASMIN account`}).add({id:218,tag:"en",href:"/docs/workflow-management/using-cron/",title:"Using Cron",description:"Using Cron",content:`Cron is a very common job scheduler for linux. It allows users to run the same command or shell script periodically. Typically it is used to automate tasks, for example, every Monday run my script to plot last week&rsquo;s data. There are many guides to using cron and crontab (the command for loading the cron job table).
Cron on JASMIN &nbsp; Generally cron is disabled on the JASMIN general access machines such as sci1.jasmin.ac.uk. This is to avoid people killing the machine by setting up lots of processing jobs when better alternatives, e.g. Lotus, are available. However, there are times when it is appropriate to use cron and so a generic cron service machine is provided. cron.jasmin.ac.uk is configured like sci*.jasmin.ac.uk, except cron is enabled. Anyone who can log into sci* should also be able to login to cron.jasmin.ac.uk. (the actual hostname of the machine is cron1.ceda.ac.uk but please refer to it as cron.jasmin.ac.uk wherever possible).
An additional transfer server xfer3.jasmin.ac.uk is equipped with cron for scheduling transfers only (no processing), although other methods for scheduling/automating transfers are available.
There are a few rules of the road to using this service:
Avoid process pile up : If a job has not finished before the cron starts the next instance of the same job then competition for resources probably means that job will also not finish. Eventually a mass of unfinished jobs will overwhelm the whole machine and it will crash. To avoid this jobs should test to see if the previous job is still running by using a lock file, or making sure the jobs timeout. The crontamer wrapper script, documented below, is available to help you implement this. Expect it to break occasionally : Regardless of any measure introduced by users to stop process pile up, you can expect it to go rouge at some point. We will reboot the machine when this happens, probably without warning. We may remove offending jobs from the cron table but persistent offenders may be barred from using the service. Don&rsquo;t do heavy processing or data transfers on the cron machine itself. You can submit jobs to lotus (sbatch is on cron1.ceda.ac.uk) to offload the processing resource. Common Cron Gotchas &nbsp; The bash shell environment when cron launches scripts is not identical to the one when working interactively. Annoyingly the path to common tools, like sbatch, may not have been setup so that you get an error message from cron when it works perfectly well interactively. A way to get round this is to source the .bash_profile in the crontab file so that the interactive environment is used by cron.
24 * * * * . $HOME/.bash_profile; sbatch -W 12:0 mycmd.sh Crontamer &nbsp; Crontamer is a wrapper script to implement lock file and time out checking for cron jobs to avoid issues of ‘’’runaway’’’ jobs causing problems for everyone (e.g. where new jobs start before old ones finish, which can cause a snowball effect).
You can download the crontamer script from https://github.com/cedadev/crontamer. It is already installed on cron1.ceda.ac.uk
Use cron as normal, but include the crontamer command before the users own script and arguments.
crontab -l ## e.g. cron file entry to run job every day at 4am: 0 4 * * * crontamer -t 2h &#39;/home/users/jblogs/bin/my_repeat_script.sh -opt1 arg1 arg2&#39; Note: Crontamer has a number of options which can be conflated with the options for the wrapped script. Use single quotes to make sure the script runs with the right options.
The flow of the crontamer script is like this:
Check for existing lock file to indicate if the script is already running. If the lockfile is there and it can see the matching process still running then it exits silently. If the lock file is not there or it can&rsquo;t see the matching process on the system then it starts the wrapped script. Periodically check the wrapped script is running. If the script fails, with a non-zero exit return code, then it can email you. If the script has been running longer than specified timeout (default 12hr) then it will be killed. Unless a named lock file is given the lock files are created in the /tmp directory as
/tmp/crontamer.unique_idThese files should be cleaned up automatically, but users may need occasional checks or find them helpful for identifying problems running their scripts. The unique_id is based on a combination of the username, passed script and arguments, enabling multiple calls of a script with different arguments to be handled separately.
All the principles above apply whether using cron on:
the cron server cron.jasmin.ac.uk (for initiating processing workflows) the transfer server xfer3.jasmin.ac.uk (for initiating automated transfers)`}).add({id:219,tag:"en",href:"/docs/software-on-jasmin/matplotlib/",title:"Using Matplotlib for visualisation on JASMIN",description:"Using Matplotlib for visualisation on JASMIN",content:`This article provides a basic example of using Matplotlib on JASMIN to generate a plot. It also gives an important tip that may stop your code failing when run on the LOTUS cluster.
Matplotlib - a basic example &nbsp; Matplotlib is a very well documented plotting library for Python. Here is a brief example of generating a line graph on a PNG file using matplotlib.
Load the Jaspy Python 3 environment, and start a Python session:
module load jaspy python In python, set some x-values, y-values, axis labels and a title, and plot:
import matplotlib matplotlib.use(&#39;agg&#39;) import matplotlib.pyplot as plt x_values = [1, 5, 3, 9, 14] y_values = [2000, 2005, 2010, 2015, 2020] x_label = &#39;Temperature (degC)&#39; y_label = &#39;Year&#39; title = &#39;Average temperature of garden shed (2000-2020)&#39; plt.plot(y_values, x_values, &#39;g--&#39;) plt.ylabel(y_label) plt.xlabel(x_label) plt.title(title) plt.savefig(&#39;output.png&#39;) Plotting with matplotlib on LOTUS &nbsp; When using matplotlib on LOTUS hosts please make sure that you are setting the rendering backend to a setting that will definitely work. This must be done before importing matplotlib.pyplot.
On JASMIN it is safe to use:
import matplotlib matplotlib.use(&#39;agg&#39;) import matplotlib.pyplot as pltor alternatively, the MPLBACKEND environment variable can be set in the job script before invoking python:
export MPLBACKEND=aggIf you do not set this option or you choose an alternative backend then you may see failures which include very large dump (error) files being written (up to 56GB per file!). Please remove these files if you accidentally create them, and switch over to selecting an appropriate rendering backend as indicated above.
Note that if you see the following error message, this results from attempting to use the default GTK backend on LOTUS (as GTK is only available in an interactive X-windows environment). The solution is to use agg, as described above.
ValueError: Namespace Gtk not available for version 3.0 For more information please see the matplotlib back-ends page.`}).add({id:220,tag:"en",href:"/docs/short-term-project-storage/using-the-jasmin-object-store/",title:"Using the JASMIN Object Store",description:"Using the JASMIN Object Store",content:`This article describes how to use the JASMIN high-performance object storage.
What is object storage? &nbsp; An object store is a data storage system that manages data as objects referenced by a globally unique identifier, with attached metadata. This is a fundamental change from traditional file systems that you may be used to, as there is no directory hierarchy - the objects exist in a single flat domain. These semantics allow the object store to scale out much more easily than a traditional shared file system.
The other fundamental change is that the data is no longer accessed by mounting a file system onto a host and referencing a file path (where authentication is &ldquo;can I log in to the host&rdquo;). Instead, the data is accessed over HTTP, with authentication using HTTP headers. This has many benefits, the biggest of which is that we can make the object store available outside of the JASMIN firewall, for example to the JASMIN External Cloud. Data can be read and written in the same way, using the same tools, from inside and outside JASMIN. Contrast this with Group Workspaces, where you must be logged in to a JASMIN host in order to write data using the file system, and data is only accessible externally in a readonly way using HTTP or OPeNDAP or via data transfer methods.
Object stores are seen as the most efficient (and cheapest!) way to store and access data from the cloud, and all the major cloud providers support some variant of object store. The JASMIN object store is S3 compatible - S3 is the object store for Amazon Web Services (AWS), and has become a de- facto standard interface for object stores. This means that all the same tools that work with AWS S3 will also work with the JASMIN object store.
Accessing the object store &nbsp; The JASMIN object store is organised into tenancies. These are shared areas of the object store, similar in concept to Group Workspaces, and are requested by users, usually Group Workspace Managers. Several users can have access to a tenancy, and so they can be used collaboratively.
To join an existing object store tenancy, navigate to the &ldquo;Services&rdquo; section in the JASMIN Accounts Portal and select the &ldquo;Object store&rdquo; category. Select a tenancy and submit a request to join. This request will then be considered by the manager of the tenancy and either accepted or rejected.
For details on how to request and manage an object store tenancy, please see the help article &ldquo;JASMIN Object Store for Managers&rdquo; (forthcoming).
Default access policies &nbsp; As of Jan 2024, we have changed the default access policy for newly created tenancies to provide a more sensible and flexible set of access policies.
The old policy allowed any members of the tenancy access to any bucket created in the tenancy by default. The new policy allow Users (USER only in the JASMIN Accounts Portal) of the tenancy only access to buckets they own by default. This can be effectively changed to the old policy by setting the policy of the bucket to the LDAP group for the tenancy members (-members, e.g. cedadev-o-members) - this can be done using the JASMIN Object Store portal (below) or the Swarm portal. Specific JASMIN users or groups can also be given permission to buckets (group access is controlled by LDAP groups, and only existing LDAP group will work - you may need to ask for one to be created).
The new policy also gives admin access for tenancy MANAGER and DEPUTY roles, who have access to all the buckets in the tenancy.
Creating an access key and secret &nbsp; Authentication with the object store uses an access key and secret that are separate to your JASMIN username and password. You can generate keys and manage bucket permissions through the JASMIN Object Store Portal.&nbsp; JASMIN sbject store portal You can log in with your JASMIN username and password. You can then click on the &ldquo;Object Stores&rdquo; button on the right. This will present you with the list of object store tenancies that you have access to. If you don&rsquo;t see an object store tenancy that you expect to, please check you have access in the JASMIN Accounts Portal&nbsp; . If you have access in the Accounts Portal, but not in the Object Store Portal then please email the helpdesk.
List of object store tenancies The URL for the object store tenancy is also presented here for convenience. You can click on the &ldquo;Manage Object Store&rdquo; button to manage you keys and buckets. This will ask you to confirm your JASMIN password.
Prompt for password You will then be presented with the following page.
existing keys From this page you can view your existing keys, and delete them if you require. You can also use the &ldquo;Create Key&rdquo; tab on the left.
Create access key You need to name the key and enter an expiry date for it. This will then present you with a pop-up with details on your access key and secret key. This is the only time your secret key will visible, so save it immediately in a secure password manager.
Managing bucket permissions &nbsp; You can also manage the permissions on buckets using the &ldquo;Buckets&rdquo; tab from this page. This allows you to manage the access policies for your buckets without using the S3 API or the Swarm portal.
Bucket permissions Click on the &ldquo;Manage permissions&rdquo; button for a bucket to add or change access policies for that bucket.
Granting access By default this lets you grant access to specific JASMIN Users and/or groups (these are LDAP groups and you might need to request that one is created for you if you require a subgroup for your tenancy). The advanced tab gives you the same options as available through the Swarm portal - including making buckets publicly accessible. Once done, hit the save to add the policy to the bucket. You can edit or delete permissions from that bucket through the &ldquo;View Bucket Policies&rdquo; tab.
Legacy method for key creation &nbsp; This is the old way of creating keys which still works, but the new way above is accessible outside JASMIN on the public internet.
You can generate an access key and secret using the Caringo portal.
Authentication with the object store uses an access key and secret that are separate to your JASMIN username and password. You can generate an access key and secret using the Caringo portal. This portal is not currently available outside of JASMIN - you will need to use a graphical session on JASMIN to access a Firefox browser running on a JASMIN system.
The recommended way to do this is using the NX Graphical Desktop service. You can start Firefox from the &ldquo;Activities&rdquo; menu once you have logged in to your graphical desktop on one of the nx-login* servers (so no need to make an onward connection to a sci server).
An alternative option is to using X11 Forwarding on your SSH connection:
ssh -AY &lt;user&gt;@sciX.jasmin.ac.uk firefoxOnce you have Firefox open, navigate to
http://my-os-tenancy-o.s3.jc.rl.ac.uk:81/_admin/portalbut replace my-os-tenancy-o with your tenancy name.
You will see a login screen where you should enter your JASMIN username and password:
If you receive a &ldquo;HTTP ERROR 500 java&hellip;&rdquo; error, it is likely that you haven&rsquo;t added the port (81) to the address.
Upon successfully entering the username and password of a user who belongs to the tenancy, you will see a dashboard. To create an access key and secret, click on the cog icon and select &ldquo;Tokens&rdquo;:
On the tokens page, click &ldquo;Add&rdquo;:
In the dialogue that pops up, enter a description for the token and set an expiration date. Make sure to click &ldquo;S3 Secret Key&rdquo; - this will expose an additional field containing the secret key. Make sure you copy this and store it somewhere safe - you will not be able to see it again! This value will be used whenever the &ldquo;S3 secret key&rdquo; is required.
Once the token is created, it will appear in the list. The &ldquo;Token&rdquo; should be used whenever the &ldquo;S3 access key&rdquo; is required:
Accessing data in the object store &nbsp; URLs for internal and external access &nbsp; Although the data is exactly the same in both cases, a slightly different URL must be used depending on whether you are accessing the object store from the JASMIN managed cloud servers or from the JASMIN External Cloud.
From inside JASMIN, including LOTUS and the Scientific Analysis servers, my-os-tenancy-o.s3.jc.rl.ac.uk should be used, with the \`http://\`\` prefix.
From the JASMIN External Cloud, and from locations external to JASMIN, my-os-tenancy-o.s3-ext.jc.rl.ac.uk should be used - note the https:// prefix and additional -ext.
(Where my-os-tenancy-o needs to be replaced with your tenancy name)
Using s3cmd &nbsp; s3cmd is a command line tool provided by Amazon to work with S3 compatible Object Storage. It is installed on JASMIN, both on the sci-machines and on LOTUS. It is a little more complicated to use than the MinIO client, but is more powerful and flexible. For full details on s3cmd, see the s3tools.org website.
To configure s3cmd to use the JASMIN object store, you need to create and edit a ~/.s3cfg file. To access the my-os-tenancy-o tenancy (where &ldquo;my-os- tenancy-o&rdquo; needs to be replaced with your tenancy name), the following should be in the ~/.s3cfg file:
access_key = &lt;access key generated above&gt; host_base = my-os-tenancy-o.s3.jc.rl.ac.uk host_bucket = my-os-tenancy-o.s3.jc.rl.ac.uk secret_key = &lt;secret key generated above&gt; use_https = False signature_v2 = Falseor, from an external tenancy or locations outside of JASMIN:
access_key = &lt;access key generated above&gt; host_base = my-os-tenancy-o.s3-ext.jc.rl.ac.uk host_bucket = my-os-tenancy-o.s3-ext.jc.rl.ac.uk secret_key = &lt;secret key generated above&gt; use_https = True signature_v2 = FalseTo see which commands can be used with s3cmd, type:
s3cmd -hTo list a tenancy&rsquo;s buckets:
s3cmd lsTo list the contents of a bucket:
s3cmd ls s3://&lt;bucket_name&gt;Make a new bucket:
s3cmd mb s3://&lt;bucket_name&gt;s3cmd uses PUT and GET nomenclature for copying files to and from the object store.
To copy a file to a bucket in the object store:
s3cmd put &lt;file name&gt; s3://&lt;bucket_name&gt;To copy a file from a bucket in the object store to the file system:
s3cmd get s3://&lt;bucket_name&gt;/&lt;object_name&gt; &lt;file_name&gt;For more commands and ways of using s3cmd, see the s3tools website.
Using the MinIO client &nbsp; The MinIO Client is a command line tool to connect to object stores (among other types of file storage) and interface with it as you would with a UNIX filesystem. As such, many of the UNIX file management commands found in standard installations of the OS are found within this client ( ls, cat, cp, rm for example).
There are a number of ways to install this client as shown in the quickstart guide. Methods include: docker, Homebrew for macOS, wget for Linux and instructions for Windows. Follow these steps to get the client installed on the relevant system.
MinIO Client is not installed on JASMIN, but users can download and install it to their own user space, following the instructions for &ldquo;64-bit Intel&rdquo; (linux- amd64) in the MinIO quickstart guide. Below is an example to install it into the bin directory in your user space
mkdir ~/bin wget https://dl.min.io/client/mc/release/linux-amd64/mc ~/bin chmod u+x ~/bin/mcYou can then add the ~/bin directory to the PATH environment variable in your ~/.bashrc file to allow mc to be accessed from anywhere on JASMIN.
# User specific aliases and functions PATH=$PATH:$HOME/binTo configure the client with the JASMIN object store, create an access key and secret as documented above and insert them into the command:
mc config host add [ALIAS] [S3-ENDPOINT] [TOKEN] [S3 SECRET KEY]The ALIAS is the name you&rsquo;ll reference the object store when using the client. To demonstrate, if the alias was set to &ldquo;jasmin-store&rdquo;, displaying a specific bucket in the object store would be done in the following way:
mc ls jasmin-store/my-bucketThe commands available in the client are documented in the quickstart guide (linked above). Copying an object from one place to another is very similar to a UNIX filesystem:
mc cp jasmin-store/my-bucket/object-1 jasmin-store/different-bucket/ From Python &nbsp; One method of accessing the object store from Python is using s3fs. This library builds on botocore but abstracts a lot of the complexities away. There are three main types of object in this library: S3FileSystem, S3File and S3Map. The filesystem object is used to configure a connection to the object store. Note: it&rsquo;s strongly recommended to store the endpoint, token and secret outside of the Python file, either using environment variables or an external file. This object can be used for lots of the operations which can be done MinIO:
with open(&#39;jasmin_object_store_credentials.json&#39;) as f: jasmin_store_credentials = json.load(f) jasmin_s3 = s3fs.S3FileSystem( anon=False, secret=jasmin_store_credentials[&#39;secret&#39;], key=jasmin_store_credentials[&#39;token&#39;], client_kwargs=&#39;endpoint_url&#39;: jasmin_store_credentials[&#39;endpoint_url&#39;] ) my_object_size = jasmin_s3.du(&#39;my-bucket/object-1&#39;)Please note in the example above, the jasmin_object_store_credentials.json file would look along the lines of:
 &#34;token&#34;: &#34;&lt;access key generated above&gt;&#34;, &#34;secret&#34;: &#34;&lt;secret key generated above&gt;&#34;, &#34;endpoint_url&#34;: &#34;http://my-os-tenancy-o.s3.jc.rl.ac.uk&#34; or, from an external tenancy or locations outside of JASMIN:
 &#34;token&#34;: &#34;&lt;access key generated above&gt;&#34;, &#34;secret&#34;: &#34;&lt;secret key generated above&gt;&#34;, &#34;endpoint_url&#34;: &#34;https://my-os-tenancy-o.s3-ext.jc.rl.ac.uk&#34; S3File is used for dealing with individual files on the object store within Python. These objects can read and written to and from the store:
file_object = s3fs.S3File(jasmin_s3, &#39;my-bucket/object-1&#39;, mode=&#39;rb&#39;) # refresh can be set to True to disable metadata caching file_metadata = file_object.metadata(refresh=False) # Writing data to variable in Python file_object.write(data) # Data will only be written to the object store if flush() is used. This can be executed in S3FS source code if the buffer &gt;= the blocksize file_object.flush()S3Map is very useful when using xarray to open a number of data files (netCDF4 for example), and turn them into the zarr format ready to be stored as objects on the store. The function for this can store a .zarr file in a POSIX filesystem, or can be streamed directly to an object store. These datasets can then be opened back into Python:
xarray.open_mfdataset(filepath_list, engine=netcdf4) s3_store = s3fs.S3Map(&#39;my-bucket/zarr-data&#39;, s3=jasmin_s3) dataset.to_zarr(store=s3_store, mode=&#39;w&#39;) # Reopening the dataset from object store using xarray xarray.open_zarr(s3_store, consolidated=True)`}).add({id:221,tag:"en",href:"/docs/short-term-project-storage/introduction-to-group-workspaces/",title:"What is a Group Workspace?",description:"What is a Group Workspace?",content:`Introduction &nbsp; This article describes the way that storage is usually provided to projects on JASMIN: the Group Workspace (GWS).
What is a GWS? &nbsp; GWSs are portions of disk allocated for particular projects to manage themselves, enabling collaborating scientists to share network accessible storage on JASMIN. Users can pull data from external sites to a common cache, process and analyse their data, and where allowed, exploit data available from other GWSs and from the CEDA archive.
It is important to understand that these workspaces are not the same as the CEDA archive. Data in a GWS can be earmarked for ingestion into the CEDA archive, but this process should be discussed directly with the CEDA Archive team (via the CEDA Helpdesk), it is not automatic and will not happen without prior arrangement.
Data within GWSs are the responsibility of the designated GWS manager and are not backed up by the JASMIN team (see below).
Accessing a GWS &nbsp; Where are GWSs available? &nbsp; Each GWS volume is found in a directory mounted under a pattern of paths which refers to the capabilities of the storage, ie.
Path Type Capability /gws/nopw/j04/* SOF no parallel write (nopw) /gws/pw/j07/* PFS parallel write capable (pw) /gws/smf/j04/* SSD small-files optimised (smf) A project may have several GWS volumes, perhaps of different types, for example:
/gws/nopw/j04/jules SOF volume for the jules project GWSs are available on:
Transfer servers including xfer*, hpxfer*, gridftp* and the JASMIN Default Collection Globus endpoint. The general scientific analysis servers sci* All nodes in the LOTUS and ORCHID clusters Some application-specific servers (by arrangement) They are NOT available on login or nx-login servers.
Requesting access to a GWS &nbsp; There is a Unix group associated with each GWS to provide convenient access control. Any JASMIN user can apply for access to a given GWS by following the links provided in the list of available GWSs on the JASMIN Accounts Portal. Important: The GWS Manager (not the JASMIN team) will need to authorise the request before you are granted access.
Once you have been granted the relevant access role, then the relevant Unix group will be added to your account. If you are not sure of the group name for your GWS you can find this by entering the command groups to see the names of the groups you belong to. The group name normally has the prefix “gws_&quot;.
&nbsp; All data in a GWS should belong to this group gws_&lt;name&gt;, so that group read/write permissions apply to this group rather than the default group, users. GWS management &nbsp; Each GWS has a designated manager. See the article on managing a GWS.
Backup &nbsp; Please note that data in GWSs are only backed up if the GWS Manager has put tasks in place to do this. The Elastic Tape service is available to enable to make a secondary near-line copy of data. Please discuss the details with your GWS Manager.
Recommended directory structure for a GWS &nbsp; We recommend that a sensible directory structure is set up within your GWS in order to conventions are used within your GWS:
&lt;your_gws&gt;/ users/ &lt;userid&gt;/ # each user can create their own directory here public/ # required if you want to share data via HTTP data/ internal/ # internal/intermediate data incoming/ # third-party data brought to the GWS output/ # output data generated by projectSee the GWS etiquette article for more details about GWSs and the GWS data sharing via HTTP article for information about the use of the public directory.`}).add({id:222,tag:"en",href:"/tags/winscp/",title:"Winscp",description:"",content:""}).add({id:223,tag:"en",href:"/docs/workflow-management/",title:"Workflow management",description:"How to manage chains of processing tasks more efficiently",content:""}).add({id:224,tag:"en",href:"/docs/workflow-management/rose-cylc-on-jasmin/",title:"Workflow Management with rose/cylc",description:"Workflow Management with rose/cylc",content:`This page provides is an overview of Met Office tools (Rose, Cylc and FCM) that are installed on JASMIN for running and managing suites on the LOTUS cluster.
IMPORTANT : Users of the JULES land surface model are advised to log into the Cylc server in order to launch the JULES suite.
About rose/cylc &nbsp; Rose and Cylc are very useful workflow management tools. You can:
Configure a Rose suite to work with the LOTUS batch cluster on JASMIN. Run a Rose suite and monitor its progress using the Cylc GUI. Find out more
Rose: https://metomi.github.io/rose/doc/html/ Cylc: https://cylc.github.io/doc/built-sphinx/ Getting started with rose/cylc
The tools are installed under the following common directory which is visible on all LOTUS nodes and the dedicated cylc server:
Add the location of the rose/cylc executables to $PATH &nbsp; export PATH=/apps/jasmin/metomi/bin:$PATHJobs must be scheduled from the JASMIN server: cylc.jasmin.ac.uk
All users with a JASMIN login account can log in to this server.
Access to the Met Office Science Repository Service has also been set up. For information about authentication to the repositories see: https://code.metoffice.gov.uk/trac/home/wiki/AuthenticationCaching#JASMIN
Following these instructions will give you access to FCM.
If you would like to run the cylc GUI then please login through the NoMachine servers.
Example rose/cylc suite &nbsp; Please see the JASMIN Workshop tutorial for a worked example of setting up a rose/cylc suite and run it on LOTUS.
Setting up the &ldquo;suite.rc&rdquo; file for use with LOTUS &nbsp; For use on JASMIN, you will need to configure the suite.rc to run on LOTUS (using the Slurm scheduling tool):
[[job submission]] method = slurm execution time limit = PT15M [[directives]] -q = short-serial -W = 05:00 -n = 1`}).add({id:225,tag:"en",href:"/docs/uncategorized/working-with-many-linux-groups/",title:"Working with many Linux groups",description:"working with many Linux groups",content:`The number-of-groups limitation - and how to work around it
Description &nbsp; On JASMIN, users are added to Linux groups for access to the group workspaces and CEDA datasets which they have registered to use, in addition to a couple of standard groups granted for all users.
Type the id command to see which groups you are a member of. The first one (shown with gid=) is your primary group, and the list starting groups= contains your supplementary groups.
Although the Linux operating system allows the group list to contain a large number of supplementary groups, certain types of filesystem are subject to a maximum number that is supported. When such filesystems are accessed, a truncated copy of the group list may be used while deciding whether to grant read or write access to a given file or directory. This can mean that although a user is a member of the group which is needed, a permissions error still occurs, because the relevant group is being ignored. The groups which are ignored are those with the higher numerical group IDs.
The most significant limitation affecting JASMIN users is for filesystems which are mounted as type NFS, because this only supports 16 groups. In particular, this applies to the group workspaces that are optimised for small files (under path /gws/smf). It also applies to the home directories and /apps software directories, and although with these directories it is not normally necessary to restrict access via Linux groups, the restriction can affect for example access to the NAG library licence file for NERC users. The panfs filesystem type (Panasas group workspaces under /group_workspaces) is also affected in principle, but it has a limit of 32 groups, which is less likely to affect users.
Workarounds &nbsp; newgrp &nbsp; The newgrp program is available on all machines, and can be used to choose a particular group. For example, typing:
newgrp ukmo_climwill start a session (sub-shell) in which the primary group ID of the process is ukmo_clim (provided that you are already a member of that group). This will ensure that, in that session, you have access to any files which require that group. Note that it will also mean that any files and directories you create in that session will be owned by the group which you selected (although they can subsequently be changed with the chgrp command). When you exit from the sub-shell, you will be returned to the original session with your normal group list.
The main limitations of newgrp are that:
It only works interactively, so it is not possible to use it in LOTUS jobs. It only affects the primary group ID, so cannot be used to guarantee access to more than one group simultaneously, because some groups on the supplementary group list might still be ignored for filesystem accesses. Note that if newgrp prompts for a password, it is because you are trying to use it to access a group that you are not a member of (and then there is no password that you can usefully type).
withgroups &nbsp; On the JASMIN scientific analysis machines running CentOS7, including the LOTUS nodes in the centos7 queue, a utility (written locally by CEDA) has been added, which overcomes the above mentioned limitations of the newgrp program. It is not available on the machines running RHEL6.
To use withgroups, you first need the following command (in your interactive session or shell script):
module load jasmin-sciOnce you have done this, you can run any individual command with the syntax withgroups &lt;group&gt; &lt;command&gt; followed by any commands arguments, for example:
withgroups ukmo_clim ls /badc/ukmo-mslp/You can also use a comma-separated list of groups if a command requires more than one group, for example if you wanted to copy a file between group workspaces:
withgroups gws_foo,gws_bar cp /gws/smf/foo/myfile /gws/smf/bar/In these cases, the group list consists only of the specified groups. So if you specify a few additional groups, these should be safe from being ignored during filesystem access, because they are no longer part of a long list.
Note that the group list in the calling session does not get modified. You will see this if for example you type:
module load jasmin-sci # a reminder of the setup command id # &#34;id&#34; reports your whole list of groups withgroups ukmo_clim id # &#34;id&#34; only reports the &#34;ukmo_clim&#34; group id # again, &#34;id&#34; will show you the whole group listThis means that you should use withgroups on every command for which it is needed. If you prefer to use a subshell in which every command will have this group(s) list (for similar behaviour to newgrp) you could start it by doing something like:
withgroups ukmo_clim bash(You might see from the help message that the withgroups command includes a -a option to include all the original groups in the group list, just with the specified ones at the front. However, this option is not recommended for this purpose, because it turns out that filesystem access will ignore the ordering and still truncate the list in numerical order.)
Use of workarounds with python (and other) programs &nbsp; Note that there is no python module equivalent of either newgrp or withgroups. In most cases, it is sufficient to run your whole python script either inside a newgrp session or via withgroups, for example:
withgroups ukmo_clim python my_script.pyIn the unlikely event that your Python program needs access to a large number of groups, you will have to lauch external commands (using os.system or the subprocess package) that start with the relevant withgroups prefix.
Similar considerations apply to code written in other programming languages.`}).add({id:226,tag:"en",href:"/tags/workshop/",title:"Workshop",description:"",content:""}).add({id:227,tag:"en",href:"/tags/workspace/",title:"Workspace",description:"",content:""}).add({id:228,tag:"en",href:"/tags/x11/",title:"X11",description:"",content:""}).add({id:229,tag:"en",href:"/tags/xfer-sp/",title:"Xfer-Sp",description:"",content:""}),search.addEventListener("input",showResults,!0)}function hideSuggestions(e){var t=suggestions.contains(e.target);t||(suggestions.classList.add("d-none"),background!==null&&background.style.setProperty("--image-opacity","0.1"))}function inputFocus(e){e.ctrlKey&&e.key==="/"&&(e.preventDefault(),search.focus()),e.key==="Escape"&&(search.blur(),suggestions.classList.add("d-none"))}function suggestionFocus(e){const s=suggestions.classList.contains("d-none");if(s)return;const t=[...suggestions.querySelectorAll("a")];if(t.length===0)return;const n=t.indexOf(document.activeElement);if(e.key==="ArrowUp"){e.preventDefault();const s=n>0?n-1:0;t[s].focus()}else if(e.key==="ArrowDown"){e.preventDefault();const s=n+1<t.length?n+1:n;t[s].focus()}}function showResults(){const s=5;var t,e=this.value;const o=document.documentElement.lang;t=null,e?(t=index.search(e,{index:["title","description","content"],limit:s,tag:o,enrich:!0}),background!==null&&background.style.setProperty("--image-opacity","0")):background!==null&&background.style.setProperty("--image-opacity","0.1");const n=new Map;if(t!==null)for(const e of t.flatMap(e=>e.result)){if(n.has(e.doc.href))continue;n.set(e.doc.href,e.doc)}if(suggestions.innerHTML="",suggestions.classList.remove("d-none"),n.size===0&&e){const n=suggestions.dataset.noResults,t=document.createElement("div");t.innerHTML=`${n} "<strong>${e}</strong>"`,t.classList.add("suggestion__no-results"),suggestions.appendChild(t);return}for(const[r,a]of n){const o=document.createElement("div");suggestions.appendChild(o);const e=document.createElement("a");e.href=r,o.appendChild(e);const t=document.createElement("span");t.classList.add("text-start"),t.textContent=a.title,t.classList.add("suggestion__title"),e.appendChild(t);const i=document.createElement("span");if(i.textContent=a.description,i.classList.add("suggestion__description"),e.appendChild(i),suggestions.appendChild(o),suggestions.childElementCount==s)break}}search!==null&&suggestions!==null&&(document.addEventListener("keydown",inputFocus),document.addEventListener("keydown",suggestionFocus),document.addEventListener("click",hideSuggestions),initIndex());const searchModal=document.getElementById("search-modal");searchModal!==null&&searchModal.addEventListener("shown.bs.modal",function(){const e=document.getElementById("search-input-modal");e!==null&&e.focus({focusVisible:!0})}),document.querySelectorAll(".dynamic-svg").forEach(e=>{e.onload=function(){const t=e.parentElement,s=e.contentDocument,o=e.getAttribute("data-class"),n=e.getAttribute("data-style");if(t!==null&&s!==null){const e=s.querySelector("svg");e!==null&&(e.setAttribute("class","svg-inline--fa "+(o||"")),e.setAttribute("fill","currentcolor"),e.setAttribute("aria-hidden","true"),e.setAttribute("role","img"),n!==null&&n!==""&&e.setAttribute("style",n),e.removeAttribute("height"),e.removeAttribute("width"),t.innerHTML="",t.appendChild(e))}}});const navbar=document.querySelector(".navbar"),togglers=document.querySelectorAll(".main-nav-toggler"),modeSelectors=document.querySelectorAll(".switch-mode-collapsed"),colorsBG=["body","secondary","tertiary"];function updateNavbar(){if(window.scrollY>75){navbar.classList.add("nav-active");const e=localStorage.getItem("theme");navbar.setAttribute("data-bs-theme",e)}else{navbar.classList.remove("nav-active");const e=navbar.getAttribute("data-bs-overlay");navbar.setAttribute("data-bs-theme",e)}}if(navbar!==null&&window.performance.getEntriesByType&&window.performance.getEntriesByType("navigation")[0].type==="reload"&&updateNavbar(),navbar!==null&&togglers!==null){const t=document.querySelector("html"),n={attributes:!0,attributeFilter:["data-bs-theme"]},s=new MutationObserver(e=>{updateNavbar()});s.observe(t,n);const e=navbar.getAttribute("data-navbar-color")||"body",o=colorsBG.includes(e)?`var(--bs-${e}-bg)`:`var(--bs-navbar-color-${e})`;navbar.style.setProperty("--bs-navbar-expanded-color",o),window.onscroll=()=>{updateNavbar()};for(let e=0;e<togglers.length;++e)togglers[e].onclick=()=>{navbar.classList.toggle("navbar-expanded")};for(let e=0;e<modeSelectors.length;++e)modeSelectors[e].onclick=()=>{for(let e=0;e<togglers.length;++e){const t=togglers[e];t.getAttribute("aria-expanded")==="true"&&t.click()}}}const popoverTriggerList=document.querySelectorAll('[data-bs-toggle="popover"]'),popoverList=[...popoverTriggerList].map(e=>new bootstrap.Popover(e));function webShareAPI(e,t,n){navigator.share({title:e,text:t,url:n}).then(()=>console.log("Successful share")).catch(e=>console.log("Error sharing",e))}const shareBtn=document.getElementById("btn-webshare");if(shareBtn!==null)if(navigator.share){const e=shareBtn.getAttribute("data-sharing-title"),t=shareBtn.getAttribute("data-sharing-description"),n=shareBtn.getAttribute("data-sharing-url");shareBtn.style.display="block",shareBtn.addEventListener("click",()=>webShareAPI(e,t,n))}else shareBtn.style.display="none";const container=document.getElementById("toast-container");container!==null&&document.querySelectorAll("[data-toast-target]").forEach(e=>{const t=document.getElementById(e.getAttribute("data-toast-target"));if(t!==null){container.appendChild(t);const n=bootstrap.Toast.getOrCreateInstance(t);n!==null&&e.addEventListener("click",()=>{n.show()})}});const tooltipTriggerList=document.querySelectorAll('[data-bs-toggle="tooltip"]'),tooltipList=[...tooltipTriggerList].map(e=>new bootstrap.Tooltip(e))